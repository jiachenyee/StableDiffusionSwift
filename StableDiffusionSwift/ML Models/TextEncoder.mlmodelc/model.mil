program(1.0)
[buildInfo = dict<tensor<string, []>, tensor<string, []>>({{"coremlc-component-MIL", "4.28.4"}, {"coremlc-version", "1429.0.0"}, {"coremltools-component-torch", "1.13.1"}, {"coremltools-version", "6.1"}})]
{
    func main<ios16>(tensor<fp32, [1, 77]> input_ids) {
            tensor<int32, []> var_5 = const()[name = tensor<string, []>("op_5"), val = tensor<int32, []>(-1)];
            tensor<bool, []> var_6 = const()[name = tensor<string, []>("op_6"), val = tensor<bool, []>(false)];
            tensor<string, []> cast_1_dtype_0 = const()[name = tensor<string, []>("cast_1_dtype_0"), val = tensor<string, []>("int32")];
            tensor<int32, []> inputs_embeds_axis_0 = const()[name = tensor<string, []>("inputs_embeds_axis_0"), val = tensor<int32, []>(0)];
            tensor<int32, []> inputs_embeds_batch_dims_0 = const()[name = tensor<string, []>("inputs_embeds_batch_dims_0"), val = tensor<int32, []>(0)];
            tensor<fp16, [49408, 1024]> text_encoder_text_model_embeddings_token_embedding_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_embeddings_token_embedding_weight_to_fp16"), val = tensor<fp16, [49408, 1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(64)))];
            tensor<int32, [1, 77]> cast_954 = cast(dtype = cast_1_dtype_0, x = input_ids);
            tensor<fp16, [1, 77, 1024]> inputs_embeds_cast = gather(axis = inputs_embeds_axis_0, batch_dims = inputs_embeds_batch_dims_0, indices = cast_954, x = text_encoder_text_model_embeddings_token_embedding_weight_to_fp16);
            tensor<fp16, [1, 77, 1024]> position_embeddings_to_fp16 = const()[name = tensor<string, []>("position_embeddings_to_fp16"), val = tensor<fp16, [1, 77, 1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(101187712)))];
            tensor<fp16, [1, 77, 1024]> input_3_cast = add(x = inputs_embeds_cast, y = position_embeddings_to_fp16);
            tensor<int32, []> band_part_0_lower_0 = const()[name = tensor<string, []>("band_part_0_lower_0"), val = tensor<int32, []>(-1)];
            tensor<int32, []> band_part_0_upper_0 = const()[name = tensor<string, []>("band_part_0_upper_0"), val = tensor<int32, []>(0)];
            tensor<fp16, [1, 77, 77]> mask_1_to_fp16 = const()[name = tensor<string, []>("mask_1_to_fp16"), val = tensor<fp16, [1, 77, 77]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(101345472)))];
            tensor<fp16, [1, 77, 77]> band_part_0_cast = band_part(lower = band_part_0_lower_0, upper = band_part_0_upper_0, x = mask_1_to_fp16);
            tensor<fp16, [1, 77, 77]> mask_cast = sub(x = mask_1_to_fp16, y = band_part_0_cast);
            tensor<int32, [1]> var_44_axes_0 = const()[name = tensor<string, []>("op_44_axes_0"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 77, 77]> var_44_cast = expand_dims(axes = var_44_axes_0, x = mask_cast);
            tensor<int32, [1]> hidden_states_1_axes_0 = const()[name = tensor<string, []>("hidden_states_1_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_0_layer_norm1_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_0_layer_norm1_weight_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(101357440)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_0_layer_norm1_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_0_layer_norm1_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(101359552)))];
            tensor<fp16, []> var_12_to_fp16 = const()[name = tensor<string, []>("op_12_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 77, 1024]> hidden_states_1_cast = layer_norm(axes = hidden_states_1_axes_0, beta = text_encoder_text_model_encoder_layers_0_layer_norm1_bias_to_fp16, epsilon = var_12_to_fp16, gamma = text_encoder_text_model_encoder_layers_0_layer_norm1_weight_to_fp16, x = input_3_cast);
            tensor<fp16, [1024, 1024]> text_encoder_text_model_encoder_layers_0_self_attn_q_proj_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_0_self_attn_q_proj_weight_to_fp16"), val = tensor<fp16, [1024, 1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(101361664)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_0_self_attn_q_proj_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_0_self_attn_q_proj_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(103458880)))];
            tensor<fp16, [1, 77, 1024]> var_110_cast = linear(bias = text_encoder_text_model_encoder_layers_0_self_attn_q_proj_bias_to_fp16, weight = text_encoder_text_model_encoder_layers_0_self_attn_q_proj_weight_to_fp16, x = hidden_states_1_cast);
            tensor<fp16, []> var_111_to_fp16 = const()[name = tensor<string, []>("op_111_to_fp16"), val = tensor<fp16, []>(0x1p-3)];
            tensor<fp16, [1, 77, 1024]> tensor_5_cast = mul(x = var_110_cast, y = var_111_to_fp16);
            tensor<fp16, [1024, 1024]> text_encoder_text_model_encoder_layers_0_self_attn_k_proj_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_0_self_attn_k_proj_weight_to_fp16"), val = tensor<fp16, [1024, 1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(103460992)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_0_self_attn_k_proj_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_0_self_attn_k_proj_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(105558208)))];
            tensor<fp16, [1, 77, 1024]> tensor_1_cast = linear(bias = text_encoder_text_model_encoder_layers_0_self_attn_k_proj_bias_to_fp16, weight = text_encoder_text_model_encoder_layers_0_self_attn_k_proj_weight_to_fp16, x = hidden_states_1_cast);
            tensor<int32, [4]> var_116 = const()[name = tensor<string, []>("op_116"), val = tensor<int32, [4]>([1, -1, 16, 64])];
            tensor<fp16, [1, 77, 16, 64]> var_117_cast = reshape(shape = var_116, x = tensor_1_cast);
            tensor<int32, [4]> var_118_perm_0 = const()[name = tensor<string, []>("op_118_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<fp16, [1024, 1024]> text_encoder_text_model_encoder_layers_0_self_attn_v_proj_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_0_self_attn_v_proj_weight_to_fp16"), val = tensor<fp16, [1024, 1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(105560320)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_0_self_attn_v_proj_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_0_self_attn_v_proj_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(107657536)))];
            tensor<fp16, [1, 77, 1024]> tensor_3_cast = linear(bias = text_encoder_text_model_encoder_layers_0_self_attn_v_proj_bias_to_fp16, weight = text_encoder_text_model_encoder_layers_0_self_attn_v_proj_weight_to_fp16, x = hidden_states_1_cast);
            tensor<int32, [4]> var_123 = const()[name = tensor<string, []>("op_123"), val = tensor<int32, [4]>([1, -1, 16, 64])];
            tensor<fp16, [1, 77, 16, 64]> var_124_cast = reshape(shape = var_123, x = tensor_3_cast);
            tensor<int32, [4]> var_125_perm_0 = const()[name = tensor<string, []>("op_125_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<int32, [4]> var_132 = const()[name = tensor<string, []>("op_132"), val = tensor<int32, [4]>([1, 77, 16, 64])];
            tensor<fp16, [1, 77, 16, 64]> var_133_cast = reshape(shape = var_132, x = tensor_5_cast);
            tensor<int32, [4]> var_134_perm_0 = const()[name = tensor<string, []>("op_134_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<int32, [3]> var_136 = const()[name = tensor<string, []>("op_136"), val = tensor<int32, [3]>([16, -1, 64])];
            tensor<fp16, [1, 16, 77, 64]> transpose_113 = transpose(perm = var_134_perm_0, x = var_133_cast);
            tensor<fp16, [16, 77, 64]> query_states_1_cast = reshape(shape = var_136, x = transpose_113);
            tensor<int32, [3]> var_138 = const()[name = tensor<string, []>("op_138"), val = tensor<int32, [3]>([16, -1, 64])];
            tensor<fp16, [1, 16, 77, 64]> transpose_115 = transpose(perm = var_118_perm_0, x = var_117_cast);
            tensor<fp16, [16, 77, 64]> key_states_3_cast = reshape(shape = var_138, x = transpose_115);
            tensor<int32, [3]> var_140 = const()[name = tensor<string, []>("op_140"), val = tensor<int32, [3]>([16, -1, 64])];
            tensor<fp16, [1, 16, 77, 64]> transpose_114 = transpose(perm = var_125_perm_0, x = var_124_cast);
            tensor<fp16, [16, 77, 64]> value_states_3_cast = reshape(shape = var_140, x = transpose_114);
            tensor<int32, [3]> var_143_perm_0 = const()[name = tensor<string, []>("op_143_perm_0"), val = tensor<int32, [3]>([0, 2, 1])];
            tensor<bool, []> attn_weights_1_transpose_x_0 = const()[name = tensor<string, []>("attn_weights_1_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> attn_weights_1_transpose_y_0 = const()[name = tensor<string, []>("attn_weights_1_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [16, 64, 77]> transpose_112 = transpose(perm = var_143_perm_0, x = key_states_3_cast);
            tensor<fp16, [16, 77, 77]> attn_weights_1_cast = matmul(transpose_x = attn_weights_1_transpose_x_0, transpose_y = attn_weights_1_transpose_y_0, x = query_states_1_cast, y = transpose_112);
            tensor<int32, [4]> var_145 = const()[name = tensor<string, []>("op_145"), val = tensor<int32, [4]>([1, 16, 77, 77])];
            tensor<fp16, [1, 16, 77, 77]> var_146_cast = reshape(shape = var_145, x = attn_weights_1_cast);
            tensor<fp16, [1, 16, 77, 77]> attn_weights_3_cast = add(x = var_146_cast, y = var_44_cast);
            tensor<int32, [3]> var_151 = const()[name = tensor<string, []>("op_151"), val = tensor<int32, [3]>([16, 77, 77])];
            tensor<fp16, [16, 77, 77]> input_5_cast = reshape(shape = var_151, x = attn_weights_3_cast);
            tensor<fp16, [16, 77, 77]> input_7_cast = softmax(axis = var_5, x = input_5_cast);
            tensor<bool, []> attn_output_1_transpose_x_0 = const()[name = tensor<string, []>("attn_output_1_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> attn_output_1_transpose_y_0 = const()[name = tensor<string, []>("attn_output_1_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [16, 77, 64]> attn_output_1_cast = matmul(transpose_x = attn_output_1_transpose_x_0, transpose_y = attn_output_1_transpose_y_0, x = input_7_cast, y = value_states_3_cast);
            tensor<int32, [4]> var_156 = const()[name = tensor<string, []>("op_156"), val = tensor<int32, [4]>([1, 16, 77, 64])];
            tensor<fp16, [1, 16, 77, 64]> attn_output_3_cast = reshape(shape = var_156, x = attn_output_1_cast);
            tensor<int32, [4]> attn_output_5_perm_0 = const()[name = tensor<string, []>("attn_output_5_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<int32, [3]> var_159 = const()[name = tensor<string, []>("op_159"), val = tensor<int32, [3]>([1, 77, 1024])];
            tensor<fp16, [1, 77, 16, 64]> transpose_111 = transpose(perm = attn_output_5_perm_0, x = attn_output_3_cast);
            tensor<fp16, [1, 77, 1024]> input_9_cast = reshape(shape = var_159, x = transpose_111);
            tensor<fp16, [1024, 1024]> text_encoder_text_model_encoder_layers_0_self_attn_out_proj_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_0_self_attn_out_proj_weight_to_fp16"), val = tensor<fp16, [1024, 1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(107659648)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_0_self_attn_out_proj_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_0_self_attn_out_proj_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(109756864)))];
            tensor<fp16, [1, 77, 1024]> hidden_states_3_cast = linear(bias = text_encoder_text_model_encoder_layers_0_self_attn_out_proj_bias_to_fp16, weight = text_encoder_text_model_encoder_layers_0_self_attn_out_proj_weight_to_fp16, x = input_9_cast);
            tensor<fp16, [1, 77, 1024]> input_11_cast = add(x = input_3_cast, y = hidden_states_3_cast);
            tensor<int32, [1]> input_13_axes_0 = const()[name = tensor<string, []>("input_13_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_0_layer_norm2_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_0_layer_norm2_weight_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(109758976)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_0_layer_norm2_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_0_layer_norm2_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(109761088)))];
            tensor<fp16, [1, 77, 1024]> input_13_cast = layer_norm(axes = input_13_axes_0, beta = text_encoder_text_model_encoder_layers_0_layer_norm2_bias_to_fp16, epsilon = var_12_to_fp16, gamma = text_encoder_text_model_encoder_layers_0_layer_norm2_weight_to_fp16, x = input_11_cast);
            tensor<fp16, [4096, 1024]> text_encoder_text_model_encoder_layers_0_mlp_fc1_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_0_mlp_fc1_weight_to_fp16"), val = tensor<fp16, [4096, 1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(109763200)))];
            tensor<fp16, [4096]> text_encoder_text_model_encoder_layers_0_mlp_fc1_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_0_mlp_fc1_bias_to_fp16"), val = tensor<fp16, [4096]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(118151872)))];
            tensor<fp16, [1, 77, 4096]> input_15_cast = linear(bias = text_encoder_text_model_encoder_layers_0_mlp_fc1_bias_to_fp16, weight = text_encoder_text_model_encoder_layers_0_mlp_fc1_weight_to_fp16, x = input_13_cast);
            tensor<string, []> input_17_mode_0 = const()[name = tensor<string, []>("input_17_mode_0"), val = tensor<string, []>("EXACT")];
            tensor<fp16, [1, 77, 4096]> input_17_cast = gelu(mode = input_17_mode_0, x = input_15_cast);
            tensor<fp16, [1024, 4096]> text_encoder_text_model_encoder_layers_0_mlp_fc2_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_0_mlp_fc2_weight_to_fp16"), val = tensor<fp16, [1024, 4096]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(118160128)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_0_mlp_fc2_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_0_mlp_fc2_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(126548800)))];
            tensor<fp16, [1, 77, 1024]> hidden_states_5_cast = linear(bias = text_encoder_text_model_encoder_layers_0_mlp_fc2_bias_to_fp16, weight = text_encoder_text_model_encoder_layers_0_mlp_fc2_weight_to_fp16, x = input_17_cast);
            tensor<fp16, [1, 77, 1024]> input_19_cast = add(x = input_11_cast, y = hidden_states_5_cast);
            tensor<int32, [1]> hidden_states_7_axes_0 = const()[name = tensor<string, []>("hidden_states_7_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_1_layer_norm1_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_1_layer_norm1_weight_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(126550912)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_1_layer_norm1_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_1_layer_norm1_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(126553024)))];
            tensor<fp16, [1, 77, 1024]> hidden_states_7_cast = layer_norm(axes = hidden_states_7_axes_0, beta = text_encoder_text_model_encoder_layers_1_layer_norm1_bias_to_fp16, epsilon = var_12_to_fp16, gamma = text_encoder_text_model_encoder_layers_1_layer_norm1_weight_to_fp16, x = input_19_cast);
            tensor<fp16, [1024, 1024]> text_encoder_text_model_encoder_layers_1_self_attn_q_proj_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_1_self_attn_q_proj_weight_to_fp16"), val = tensor<fp16, [1024, 1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(126555136)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_1_self_attn_q_proj_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_1_self_attn_q_proj_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(128652352)))];
            tensor<fp16, [1, 77, 1024]> var_197_cast = linear(bias = text_encoder_text_model_encoder_layers_1_self_attn_q_proj_bias_to_fp16, weight = text_encoder_text_model_encoder_layers_1_self_attn_q_proj_weight_to_fp16, x = hidden_states_7_cast);
            tensor<fp16, []> var_198_to_fp16 = const()[name = tensor<string, []>("op_198_to_fp16"), val = tensor<fp16, []>(0x1p-3)];
            tensor<fp16, [1, 77, 1024]> tensor_11_cast = mul(x = var_197_cast, y = var_198_to_fp16);
            tensor<fp16, [1024, 1024]> text_encoder_text_model_encoder_layers_1_self_attn_k_proj_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_1_self_attn_k_proj_weight_to_fp16"), val = tensor<fp16, [1024, 1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(128654464)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_1_self_attn_k_proj_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_1_self_attn_k_proj_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(130751680)))];
            tensor<fp16, [1, 77, 1024]> tensor_7_cast = linear(bias = text_encoder_text_model_encoder_layers_1_self_attn_k_proj_bias_to_fp16, weight = text_encoder_text_model_encoder_layers_1_self_attn_k_proj_weight_to_fp16, x = hidden_states_7_cast);
            tensor<int32, [4]> var_203 = const()[name = tensor<string, []>("op_203"), val = tensor<int32, [4]>([1, -1, 16, 64])];
            tensor<fp16, [1, 77, 16, 64]> var_204_cast = reshape(shape = var_203, x = tensor_7_cast);
            tensor<int32, [4]> var_205_perm_0 = const()[name = tensor<string, []>("op_205_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<fp16, [1024, 1024]> text_encoder_text_model_encoder_layers_1_self_attn_v_proj_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_1_self_attn_v_proj_weight_to_fp16"), val = tensor<fp16, [1024, 1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(130753792)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_1_self_attn_v_proj_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_1_self_attn_v_proj_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(132851008)))];
            tensor<fp16, [1, 77, 1024]> tensor_9_cast = linear(bias = text_encoder_text_model_encoder_layers_1_self_attn_v_proj_bias_to_fp16, weight = text_encoder_text_model_encoder_layers_1_self_attn_v_proj_weight_to_fp16, x = hidden_states_7_cast);
            tensor<int32, [4]> var_210 = const()[name = tensor<string, []>("op_210"), val = tensor<int32, [4]>([1, -1, 16, 64])];
            tensor<fp16, [1, 77, 16, 64]> var_211_cast = reshape(shape = var_210, x = tensor_9_cast);
            tensor<int32, [4]> var_212_perm_0 = const()[name = tensor<string, []>("op_212_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<int32, [4]> var_219 = const()[name = tensor<string, []>("op_219"), val = tensor<int32, [4]>([1, 77, 16, 64])];
            tensor<fp16, [1, 77, 16, 64]> var_220_cast = reshape(shape = var_219, x = tensor_11_cast);
            tensor<int32, [4]> var_221_perm_0 = const()[name = tensor<string, []>("op_221_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<int32, [3]> var_223 = const()[name = tensor<string, []>("op_223"), val = tensor<int32, [3]>([16, -1, 64])];
            tensor<fp16, [1, 16, 77, 64]> transpose_108 = transpose(perm = var_221_perm_0, x = var_220_cast);
            tensor<fp16, [16, 77, 64]> query_states_3_cast = reshape(shape = var_223, x = transpose_108);
            tensor<int32, [3]> var_225 = const()[name = tensor<string, []>("op_225"), val = tensor<int32, [3]>([16, -1, 64])];
            tensor<fp16, [1, 16, 77, 64]> transpose_110 = transpose(perm = var_205_perm_0, x = var_204_cast);
            tensor<fp16, [16, 77, 64]> key_states_7_cast = reshape(shape = var_225, x = transpose_110);
            tensor<int32, [3]> var_227 = const()[name = tensor<string, []>("op_227"), val = tensor<int32, [3]>([16, -1, 64])];
            tensor<fp16, [1, 16, 77, 64]> transpose_109 = transpose(perm = var_212_perm_0, x = var_211_cast);
            tensor<fp16, [16, 77, 64]> value_states_7_cast = reshape(shape = var_227, x = transpose_109);
            tensor<int32, [3]> var_230_perm_0 = const()[name = tensor<string, []>("op_230_perm_0"), val = tensor<int32, [3]>([0, 2, 1])];
            tensor<bool, []> attn_weights_7_transpose_x_0 = const()[name = tensor<string, []>("attn_weights_7_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> attn_weights_7_transpose_y_0 = const()[name = tensor<string, []>("attn_weights_7_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [16, 64, 77]> transpose_107 = transpose(perm = var_230_perm_0, x = key_states_7_cast);
            tensor<fp16, [16, 77, 77]> attn_weights_7_cast = matmul(transpose_x = attn_weights_7_transpose_x_0, transpose_y = attn_weights_7_transpose_y_0, x = query_states_3_cast, y = transpose_107);
            tensor<int32, [4]> var_232 = const()[name = tensor<string, []>("op_232"), val = tensor<int32, [4]>([1, 16, 77, 77])];
            tensor<fp16, [1, 16, 77, 77]> var_233_cast = reshape(shape = var_232, x = attn_weights_7_cast);
            tensor<fp16, [1, 16, 77, 77]> attn_weights_9_cast = add(x = var_233_cast, y = var_44_cast);
            tensor<int32, [3]> var_238 = const()[name = tensor<string, []>("op_238"), val = tensor<int32, [3]>([16, 77, 77])];
            tensor<fp16, [16, 77, 77]> input_21_cast = reshape(shape = var_238, x = attn_weights_9_cast);
            tensor<fp16, [16, 77, 77]> input_23_cast = softmax(axis = var_5, x = input_21_cast);
            tensor<bool, []> attn_output_7_transpose_x_0 = const()[name = tensor<string, []>("attn_output_7_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> attn_output_7_transpose_y_0 = const()[name = tensor<string, []>("attn_output_7_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [16, 77, 64]> attn_output_7_cast = matmul(transpose_x = attn_output_7_transpose_x_0, transpose_y = attn_output_7_transpose_y_0, x = input_23_cast, y = value_states_7_cast);
            tensor<int32, [4]> var_243 = const()[name = tensor<string, []>("op_243"), val = tensor<int32, [4]>([1, 16, 77, 64])];
            tensor<fp16, [1, 16, 77, 64]> attn_output_9_cast = reshape(shape = var_243, x = attn_output_7_cast);
            tensor<int32, [4]> attn_output_11_perm_0 = const()[name = tensor<string, []>("attn_output_11_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<int32, [3]> var_246 = const()[name = tensor<string, []>("op_246"), val = tensor<int32, [3]>([1, 77, 1024])];
            tensor<fp16, [1, 77, 16, 64]> transpose_106 = transpose(perm = attn_output_11_perm_0, x = attn_output_9_cast);
            tensor<fp16, [1, 77, 1024]> input_25_cast = reshape(shape = var_246, x = transpose_106);
            tensor<fp16, [1024, 1024]> text_encoder_text_model_encoder_layers_1_self_attn_out_proj_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_1_self_attn_out_proj_weight_to_fp16"), val = tensor<fp16, [1024, 1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(132853120)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_1_self_attn_out_proj_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_1_self_attn_out_proj_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(134950336)))];
            tensor<fp16, [1, 77, 1024]> hidden_states_9_cast = linear(bias = text_encoder_text_model_encoder_layers_1_self_attn_out_proj_bias_to_fp16, weight = text_encoder_text_model_encoder_layers_1_self_attn_out_proj_weight_to_fp16, x = input_25_cast);
            tensor<fp16, [1, 77, 1024]> input_27_cast = add(x = input_19_cast, y = hidden_states_9_cast);
            tensor<int32, [1]> input_29_axes_0 = const()[name = tensor<string, []>("input_29_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_1_layer_norm2_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_1_layer_norm2_weight_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(134952448)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_1_layer_norm2_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_1_layer_norm2_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(134954560)))];
            tensor<fp16, [1, 77, 1024]> input_29_cast = layer_norm(axes = input_29_axes_0, beta = text_encoder_text_model_encoder_layers_1_layer_norm2_bias_to_fp16, epsilon = var_12_to_fp16, gamma = text_encoder_text_model_encoder_layers_1_layer_norm2_weight_to_fp16, x = input_27_cast);
            tensor<fp16, [4096, 1024]> text_encoder_text_model_encoder_layers_1_mlp_fc1_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_1_mlp_fc1_weight_to_fp16"), val = tensor<fp16, [4096, 1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(134956672)))];
            tensor<fp16, [4096]> text_encoder_text_model_encoder_layers_1_mlp_fc1_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_1_mlp_fc1_bias_to_fp16"), val = tensor<fp16, [4096]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(143345344)))];
            tensor<fp16, [1, 77, 4096]> input_31_cast = linear(bias = text_encoder_text_model_encoder_layers_1_mlp_fc1_bias_to_fp16, weight = text_encoder_text_model_encoder_layers_1_mlp_fc1_weight_to_fp16, x = input_29_cast);
            tensor<string, []> input_33_mode_0 = const()[name = tensor<string, []>("input_33_mode_0"), val = tensor<string, []>("EXACT")];
            tensor<fp16, [1, 77, 4096]> input_33_cast = gelu(mode = input_33_mode_0, x = input_31_cast);
            tensor<fp16, [1024, 4096]> text_encoder_text_model_encoder_layers_1_mlp_fc2_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_1_mlp_fc2_weight_to_fp16"), val = tensor<fp16, [1024, 4096]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(143353600)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_1_mlp_fc2_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_1_mlp_fc2_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(151742272)))];
            tensor<fp16, [1, 77, 1024]> hidden_states_11_cast = linear(bias = text_encoder_text_model_encoder_layers_1_mlp_fc2_bias_to_fp16, weight = text_encoder_text_model_encoder_layers_1_mlp_fc2_weight_to_fp16, x = input_33_cast);
            tensor<fp16, [1, 77, 1024]> input_35_cast = add(x = input_27_cast, y = hidden_states_11_cast);
            tensor<int32, [1]> hidden_states_13_axes_0 = const()[name = tensor<string, []>("hidden_states_13_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_2_layer_norm1_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_2_layer_norm1_weight_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(151744384)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_2_layer_norm1_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_2_layer_norm1_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(151746496)))];
            tensor<fp16, [1, 77, 1024]> hidden_states_13_cast = layer_norm(axes = hidden_states_13_axes_0, beta = text_encoder_text_model_encoder_layers_2_layer_norm1_bias_to_fp16, epsilon = var_12_to_fp16, gamma = text_encoder_text_model_encoder_layers_2_layer_norm1_weight_to_fp16, x = input_35_cast);
            tensor<fp16, [1024, 1024]> text_encoder_text_model_encoder_layers_2_self_attn_q_proj_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_2_self_attn_q_proj_weight_to_fp16"), val = tensor<fp16, [1024, 1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(151748608)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_2_self_attn_q_proj_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_2_self_attn_q_proj_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(153845824)))];
            tensor<fp16, [1, 77, 1024]> var_284_cast = linear(bias = text_encoder_text_model_encoder_layers_2_self_attn_q_proj_bias_to_fp16, weight = text_encoder_text_model_encoder_layers_2_self_attn_q_proj_weight_to_fp16, x = hidden_states_13_cast);
            tensor<fp16, []> var_285_to_fp16 = const()[name = tensor<string, []>("op_285_to_fp16"), val = tensor<fp16, []>(0x1p-3)];
            tensor<fp16, [1, 77, 1024]> tensor_17_cast = mul(x = var_284_cast, y = var_285_to_fp16);
            tensor<fp16, [1024, 1024]> text_encoder_text_model_encoder_layers_2_self_attn_k_proj_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_2_self_attn_k_proj_weight_to_fp16"), val = tensor<fp16, [1024, 1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(153847936)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_2_self_attn_k_proj_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_2_self_attn_k_proj_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(155945152)))];
            tensor<fp16, [1, 77, 1024]> tensor_13_cast = linear(bias = text_encoder_text_model_encoder_layers_2_self_attn_k_proj_bias_to_fp16, weight = text_encoder_text_model_encoder_layers_2_self_attn_k_proj_weight_to_fp16, x = hidden_states_13_cast);
            tensor<int32, [4]> var_290 = const()[name = tensor<string, []>("op_290"), val = tensor<int32, [4]>([1, -1, 16, 64])];
            tensor<fp16, [1, 77, 16, 64]> var_291_cast = reshape(shape = var_290, x = tensor_13_cast);
            tensor<int32, [4]> var_292_perm_0 = const()[name = tensor<string, []>("op_292_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<fp16, [1024, 1024]> text_encoder_text_model_encoder_layers_2_self_attn_v_proj_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_2_self_attn_v_proj_weight_to_fp16"), val = tensor<fp16, [1024, 1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(155947264)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_2_self_attn_v_proj_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_2_self_attn_v_proj_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(158044480)))];
            tensor<fp16, [1, 77, 1024]> tensor_15_cast = linear(bias = text_encoder_text_model_encoder_layers_2_self_attn_v_proj_bias_to_fp16, weight = text_encoder_text_model_encoder_layers_2_self_attn_v_proj_weight_to_fp16, x = hidden_states_13_cast);
            tensor<int32, [4]> var_297 = const()[name = tensor<string, []>("op_297"), val = tensor<int32, [4]>([1, -1, 16, 64])];
            tensor<fp16, [1, 77, 16, 64]> var_298_cast = reshape(shape = var_297, x = tensor_15_cast);
            tensor<int32, [4]> var_299_perm_0 = const()[name = tensor<string, []>("op_299_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<int32, [4]> var_306 = const()[name = tensor<string, []>("op_306"), val = tensor<int32, [4]>([1, 77, 16, 64])];
            tensor<fp16, [1, 77, 16, 64]> var_307_cast = reshape(shape = var_306, x = tensor_17_cast);
            tensor<int32, [4]> var_308_perm_0 = const()[name = tensor<string, []>("op_308_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<int32, [3]> var_310 = const()[name = tensor<string, []>("op_310"), val = tensor<int32, [3]>([16, -1, 64])];
            tensor<fp16, [1, 16, 77, 64]> transpose_103 = transpose(perm = var_308_perm_0, x = var_307_cast);
            tensor<fp16, [16, 77, 64]> query_states_5_cast = reshape(shape = var_310, x = transpose_103);
            tensor<int32, [3]> var_312 = const()[name = tensor<string, []>("op_312"), val = tensor<int32, [3]>([16, -1, 64])];
            tensor<fp16, [1, 16, 77, 64]> transpose_105 = transpose(perm = var_292_perm_0, x = var_291_cast);
            tensor<fp16, [16, 77, 64]> key_states_11_cast = reshape(shape = var_312, x = transpose_105);
            tensor<int32, [3]> var_314 = const()[name = tensor<string, []>("op_314"), val = tensor<int32, [3]>([16, -1, 64])];
            tensor<fp16, [1, 16, 77, 64]> transpose_104 = transpose(perm = var_299_perm_0, x = var_298_cast);
            tensor<fp16, [16, 77, 64]> value_states_11_cast = reshape(shape = var_314, x = transpose_104);
            tensor<int32, [3]> var_317_perm_0 = const()[name = tensor<string, []>("op_317_perm_0"), val = tensor<int32, [3]>([0, 2, 1])];
            tensor<bool, []> attn_weights_13_transpose_x_0 = const()[name = tensor<string, []>("attn_weights_13_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> attn_weights_13_transpose_y_0 = const()[name = tensor<string, []>("attn_weights_13_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [16, 64, 77]> transpose_102 = transpose(perm = var_317_perm_0, x = key_states_11_cast);
            tensor<fp16, [16, 77, 77]> attn_weights_13_cast = matmul(transpose_x = attn_weights_13_transpose_x_0, transpose_y = attn_weights_13_transpose_y_0, x = query_states_5_cast, y = transpose_102);
            tensor<int32, [4]> var_319 = const()[name = tensor<string, []>("op_319"), val = tensor<int32, [4]>([1, 16, 77, 77])];
            tensor<fp16, [1, 16, 77, 77]> var_320_cast = reshape(shape = var_319, x = attn_weights_13_cast);
            tensor<fp16, [1, 16, 77, 77]> attn_weights_15_cast = add(x = var_320_cast, y = var_44_cast);
            tensor<int32, [3]> var_325 = const()[name = tensor<string, []>("op_325"), val = tensor<int32, [3]>([16, 77, 77])];
            tensor<fp16, [16, 77, 77]> input_37_cast = reshape(shape = var_325, x = attn_weights_15_cast);
            tensor<fp16, [16, 77, 77]> input_39_cast = softmax(axis = var_5, x = input_37_cast);
            tensor<bool, []> attn_output_13_transpose_x_0 = const()[name = tensor<string, []>("attn_output_13_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> attn_output_13_transpose_y_0 = const()[name = tensor<string, []>("attn_output_13_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [16, 77, 64]> attn_output_13_cast = matmul(transpose_x = attn_output_13_transpose_x_0, transpose_y = attn_output_13_transpose_y_0, x = input_39_cast, y = value_states_11_cast);
            tensor<int32, [4]> var_330 = const()[name = tensor<string, []>("op_330"), val = tensor<int32, [4]>([1, 16, 77, 64])];
            tensor<fp16, [1, 16, 77, 64]> attn_output_15_cast = reshape(shape = var_330, x = attn_output_13_cast);
            tensor<int32, [4]> attn_output_17_perm_0 = const()[name = tensor<string, []>("attn_output_17_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<int32, [3]> var_333 = const()[name = tensor<string, []>("op_333"), val = tensor<int32, [3]>([1, 77, 1024])];
            tensor<fp16, [1, 77, 16, 64]> transpose_101 = transpose(perm = attn_output_17_perm_0, x = attn_output_15_cast);
            tensor<fp16, [1, 77, 1024]> input_41_cast = reshape(shape = var_333, x = transpose_101);
            tensor<fp16, [1024, 1024]> text_encoder_text_model_encoder_layers_2_self_attn_out_proj_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_2_self_attn_out_proj_weight_to_fp16"), val = tensor<fp16, [1024, 1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(158046592)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_2_self_attn_out_proj_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_2_self_attn_out_proj_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(160143808)))];
            tensor<fp16, [1, 77, 1024]> hidden_states_15_cast = linear(bias = text_encoder_text_model_encoder_layers_2_self_attn_out_proj_bias_to_fp16, weight = text_encoder_text_model_encoder_layers_2_self_attn_out_proj_weight_to_fp16, x = input_41_cast);
            tensor<fp16, [1, 77, 1024]> input_43_cast = add(x = input_35_cast, y = hidden_states_15_cast);
            tensor<int32, [1]> input_45_axes_0 = const()[name = tensor<string, []>("input_45_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_2_layer_norm2_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_2_layer_norm2_weight_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(160145920)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_2_layer_norm2_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_2_layer_norm2_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(160148032)))];
            tensor<fp16, [1, 77, 1024]> input_45_cast = layer_norm(axes = input_45_axes_0, beta = text_encoder_text_model_encoder_layers_2_layer_norm2_bias_to_fp16, epsilon = var_12_to_fp16, gamma = text_encoder_text_model_encoder_layers_2_layer_norm2_weight_to_fp16, x = input_43_cast);
            tensor<fp16, [4096, 1024]> text_encoder_text_model_encoder_layers_2_mlp_fc1_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_2_mlp_fc1_weight_to_fp16"), val = tensor<fp16, [4096, 1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(160150144)))];
            tensor<fp16, [4096]> text_encoder_text_model_encoder_layers_2_mlp_fc1_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_2_mlp_fc1_bias_to_fp16"), val = tensor<fp16, [4096]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(168538816)))];
            tensor<fp16, [1, 77, 4096]> input_47_cast = linear(bias = text_encoder_text_model_encoder_layers_2_mlp_fc1_bias_to_fp16, weight = text_encoder_text_model_encoder_layers_2_mlp_fc1_weight_to_fp16, x = input_45_cast);
            tensor<string, []> input_49_mode_0 = const()[name = tensor<string, []>("input_49_mode_0"), val = tensor<string, []>("EXACT")];
            tensor<fp16, [1, 77, 4096]> input_49_cast = gelu(mode = input_49_mode_0, x = input_47_cast);
            tensor<fp16, [1024, 4096]> text_encoder_text_model_encoder_layers_2_mlp_fc2_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_2_mlp_fc2_weight_to_fp16"), val = tensor<fp16, [1024, 4096]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(168547072)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_2_mlp_fc2_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_2_mlp_fc2_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(176935744)))];
            tensor<fp16, [1, 77, 1024]> hidden_states_17_cast = linear(bias = text_encoder_text_model_encoder_layers_2_mlp_fc2_bias_to_fp16, weight = text_encoder_text_model_encoder_layers_2_mlp_fc2_weight_to_fp16, x = input_49_cast);
            tensor<fp16, [1, 77, 1024]> input_51_cast = add(x = input_43_cast, y = hidden_states_17_cast);
            tensor<int32, [1]> hidden_states_19_axes_0 = const()[name = tensor<string, []>("hidden_states_19_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_3_layer_norm1_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_3_layer_norm1_weight_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(176937856)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_3_layer_norm1_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_3_layer_norm1_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(176939968)))];
            tensor<fp16, [1, 77, 1024]> hidden_states_19_cast = layer_norm(axes = hidden_states_19_axes_0, beta = text_encoder_text_model_encoder_layers_3_layer_norm1_bias_to_fp16, epsilon = var_12_to_fp16, gamma = text_encoder_text_model_encoder_layers_3_layer_norm1_weight_to_fp16, x = input_51_cast);
            tensor<fp16, [1024, 1024]> text_encoder_text_model_encoder_layers_3_self_attn_q_proj_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_3_self_attn_q_proj_weight_to_fp16"), val = tensor<fp16, [1024, 1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(176942080)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_3_self_attn_q_proj_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_3_self_attn_q_proj_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(179039296)))];
            tensor<fp16, [1, 77, 1024]> var_371_cast = linear(bias = text_encoder_text_model_encoder_layers_3_self_attn_q_proj_bias_to_fp16, weight = text_encoder_text_model_encoder_layers_3_self_attn_q_proj_weight_to_fp16, x = hidden_states_19_cast);
            tensor<fp16, []> var_372_to_fp16 = const()[name = tensor<string, []>("op_372_to_fp16"), val = tensor<fp16, []>(0x1p-3)];
            tensor<fp16, [1, 77, 1024]> tensor_23_cast = mul(x = var_371_cast, y = var_372_to_fp16);
            tensor<fp16, [1024, 1024]> text_encoder_text_model_encoder_layers_3_self_attn_k_proj_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_3_self_attn_k_proj_weight_to_fp16"), val = tensor<fp16, [1024, 1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(179041408)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_3_self_attn_k_proj_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_3_self_attn_k_proj_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(181138624)))];
            tensor<fp16, [1, 77, 1024]> tensor_19_cast = linear(bias = text_encoder_text_model_encoder_layers_3_self_attn_k_proj_bias_to_fp16, weight = text_encoder_text_model_encoder_layers_3_self_attn_k_proj_weight_to_fp16, x = hidden_states_19_cast);
            tensor<int32, [4]> var_377 = const()[name = tensor<string, []>("op_377"), val = tensor<int32, [4]>([1, -1, 16, 64])];
            tensor<fp16, [1, 77, 16, 64]> var_378_cast = reshape(shape = var_377, x = tensor_19_cast);
            tensor<int32, [4]> var_379_perm_0 = const()[name = tensor<string, []>("op_379_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<fp16, [1024, 1024]> text_encoder_text_model_encoder_layers_3_self_attn_v_proj_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_3_self_attn_v_proj_weight_to_fp16"), val = tensor<fp16, [1024, 1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(181140736)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_3_self_attn_v_proj_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_3_self_attn_v_proj_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(183237952)))];
            tensor<fp16, [1, 77, 1024]> tensor_21_cast = linear(bias = text_encoder_text_model_encoder_layers_3_self_attn_v_proj_bias_to_fp16, weight = text_encoder_text_model_encoder_layers_3_self_attn_v_proj_weight_to_fp16, x = hidden_states_19_cast);
            tensor<int32, [4]> var_384 = const()[name = tensor<string, []>("op_384"), val = tensor<int32, [4]>([1, -1, 16, 64])];
            tensor<fp16, [1, 77, 16, 64]> var_385_cast = reshape(shape = var_384, x = tensor_21_cast);
            tensor<int32, [4]> var_386_perm_0 = const()[name = tensor<string, []>("op_386_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<int32, [4]> var_393 = const()[name = tensor<string, []>("op_393"), val = tensor<int32, [4]>([1, 77, 16, 64])];
            tensor<fp16, [1, 77, 16, 64]> var_394_cast = reshape(shape = var_393, x = tensor_23_cast);
            tensor<int32, [4]> var_395_perm_0 = const()[name = tensor<string, []>("op_395_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<int32, [3]> var_397 = const()[name = tensor<string, []>("op_397"), val = tensor<int32, [3]>([16, -1, 64])];
            tensor<fp16, [1, 16, 77, 64]> transpose_98 = transpose(perm = var_395_perm_0, x = var_394_cast);
            tensor<fp16, [16, 77, 64]> query_states_7_cast = reshape(shape = var_397, x = transpose_98);
            tensor<int32, [3]> var_399 = const()[name = tensor<string, []>("op_399"), val = tensor<int32, [3]>([16, -1, 64])];
            tensor<fp16, [1, 16, 77, 64]> transpose_100 = transpose(perm = var_379_perm_0, x = var_378_cast);
            tensor<fp16, [16, 77, 64]> key_states_15_cast = reshape(shape = var_399, x = transpose_100);
            tensor<int32, [3]> var_401 = const()[name = tensor<string, []>("op_401"), val = tensor<int32, [3]>([16, -1, 64])];
            tensor<fp16, [1, 16, 77, 64]> transpose_99 = transpose(perm = var_386_perm_0, x = var_385_cast);
            tensor<fp16, [16, 77, 64]> value_states_15_cast = reshape(shape = var_401, x = transpose_99);
            tensor<int32, [3]> var_404_perm_0 = const()[name = tensor<string, []>("op_404_perm_0"), val = tensor<int32, [3]>([0, 2, 1])];
            tensor<bool, []> attn_weights_19_transpose_x_0 = const()[name = tensor<string, []>("attn_weights_19_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> attn_weights_19_transpose_y_0 = const()[name = tensor<string, []>("attn_weights_19_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [16, 64, 77]> transpose_97 = transpose(perm = var_404_perm_0, x = key_states_15_cast);
            tensor<fp16, [16, 77, 77]> attn_weights_19_cast = matmul(transpose_x = attn_weights_19_transpose_x_0, transpose_y = attn_weights_19_transpose_y_0, x = query_states_7_cast, y = transpose_97);
            tensor<int32, [4]> var_406 = const()[name = tensor<string, []>("op_406"), val = tensor<int32, [4]>([1, 16, 77, 77])];
            tensor<fp16, [1, 16, 77, 77]> var_407_cast = reshape(shape = var_406, x = attn_weights_19_cast);
            tensor<fp16, [1, 16, 77, 77]> attn_weights_21_cast = add(x = var_407_cast, y = var_44_cast);
            tensor<int32, [3]> var_412 = const()[name = tensor<string, []>("op_412"), val = tensor<int32, [3]>([16, 77, 77])];
            tensor<fp16, [16, 77, 77]> input_53_cast = reshape(shape = var_412, x = attn_weights_21_cast);
            tensor<fp16, [16, 77, 77]> input_55_cast = softmax(axis = var_5, x = input_53_cast);
            tensor<bool, []> attn_output_19_transpose_x_0 = const()[name = tensor<string, []>("attn_output_19_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> attn_output_19_transpose_y_0 = const()[name = tensor<string, []>("attn_output_19_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [16, 77, 64]> attn_output_19_cast = matmul(transpose_x = attn_output_19_transpose_x_0, transpose_y = attn_output_19_transpose_y_0, x = input_55_cast, y = value_states_15_cast);
            tensor<int32, [4]> var_417 = const()[name = tensor<string, []>("op_417"), val = tensor<int32, [4]>([1, 16, 77, 64])];
            tensor<fp16, [1, 16, 77, 64]> attn_output_21_cast = reshape(shape = var_417, x = attn_output_19_cast);
            tensor<int32, [4]> attn_output_23_perm_0 = const()[name = tensor<string, []>("attn_output_23_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<int32, [3]> var_420 = const()[name = tensor<string, []>("op_420"), val = tensor<int32, [3]>([1, 77, 1024])];
            tensor<fp16, [1, 77, 16, 64]> transpose_96 = transpose(perm = attn_output_23_perm_0, x = attn_output_21_cast);
            tensor<fp16, [1, 77, 1024]> input_57_cast = reshape(shape = var_420, x = transpose_96);
            tensor<fp16, [1024, 1024]> text_encoder_text_model_encoder_layers_3_self_attn_out_proj_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_3_self_attn_out_proj_weight_to_fp16"), val = tensor<fp16, [1024, 1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(183240064)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_3_self_attn_out_proj_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_3_self_attn_out_proj_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(185337280)))];
            tensor<fp16, [1, 77, 1024]> hidden_states_21_cast = linear(bias = text_encoder_text_model_encoder_layers_3_self_attn_out_proj_bias_to_fp16, weight = text_encoder_text_model_encoder_layers_3_self_attn_out_proj_weight_to_fp16, x = input_57_cast);
            tensor<fp16, [1, 77, 1024]> input_59_cast = add(x = input_51_cast, y = hidden_states_21_cast);
            tensor<int32, [1]> input_61_axes_0 = const()[name = tensor<string, []>("input_61_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_3_layer_norm2_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_3_layer_norm2_weight_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(185339392)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_3_layer_norm2_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_3_layer_norm2_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(185341504)))];
            tensor<fp16, [1, 77, 1024]> input_61_cast = layer_norm(axes = input_61_axes_0, beta = text_encoder_text_model_encoder_layers_3_layer_norm2_bias_to_fp16, epsilon = var_12_to_fp16, gamma = text_encoder_text_model_encoder_layers_3_layer_norm2_weight_to_fp16, x = input_59_cast);
            tensor<fp16, [4096, 1024]> text_encoder_text_model_encoder_layers_3_mlp_fc1_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_3_mlp_fc1_weight_to_fp16"), val = tensor<fp16, [4096, 1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(185343616)))];
            tensor<fp16, [4096]> text_encoder_text_model_encoder_layers_3_mlp_fc1_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_3_mlp_fc1_bias_to_fp16"), val = tensor<fp16, [4096]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(193732288)))];
            tensor<fp16, [1, 77, 4096]> input_63_cast = linear(bias = text_encoder_text_model_encoder_layers_3_mlp_fc1_bias_to_fp16, weight = text_encoder_text_model_encoder_layers_3_mlp_fc1_weight_to_fp16, x = input_61_cast);
            tensor<string, []> input_65_mode_0 = const()[name = tensor<string, []>("input_65_mode_0"), val = tensor<string, []>("EXACT")];
            tensor<fp16, [1, 77, 4096]> input_65_cast = gelu(mode = input_65_mode_0, x = input_63_cast);
            tensor<fp16, [1024, 4096]> text_encoder_text_model_encoder_layers_3_mlp_fc2_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_3_mlp_fc2_weight_to_fp16"), val = tensor<fp16, [1024, 4096]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(193740544)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_3_mlp_fc2_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_3_mlp_fc2_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(202129216)))];
            tensor<fp16, [1, 77, 1024]> hidden_states_23_cast = linear(bias = text_encoder_text_model_encoder_layers_3_mlp_fc2_bias_to_fp16, weight = text_encoder_text_model_encoder_layers_3_mlp_fc2_weight_to_fp16, x = input_65_cast);
            tensor<fp16, [1, 77, 1024]> input_67_cast = add(x = input_59_cast, y = hidden_states_23_cast);
            tensor<int32, [1]> hidden_states_25_axes_0 = const()[name = tensor<string, []>("hidden_states_25_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_4_layer_norm1_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_4_layer_norm1_weight_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(202131328)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_4_layer_norm1_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_4_layer_norm1_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(202133440)))];
            tensor<fp16, [1, 77, 1024]> hidden_states_25_cast = layer_norm(axes = hidden_states_25_axes_0, beta = text_encoder_text_model_encoder_layers_4_layer_norm1_bias_to_fp16, epsilon = var_12_to_fp16, gamma = text_encoder_text_model_encoder_layers_4_layer_norm1_weight_to_fp16, x = input_67_cast);
            tensor<fp16, [1024, 1024]> text_encoder_text_model_encoder_layers_4_self_attn_q_proj_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_4_self_attn_q_proj_weight_to_fp16"), val = tensor<fp16, [1024, 1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(202135552)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_4_self_attn_q_proj_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_4_self_attn_q_proj_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(204232768)))];
            tensor<fp16, [1, 77, 1024]> var_458_cast = linear(bias = text_encoder_text_model_encoder_layers_4_self_attn_q_proj_bias_to_fp16, weight = text_encoder_text_model_encoder_layers_4_self_attn_q_proj_weight_to_fp16, x = hidden_states_25_cast);
            tensor<fp16, []> var_459_to_fp16 = const()[name = tensor<string, []>("op_459_to_fp16"), val = tensor<fp16, []>(0x1p-3)];
            tensor<fp16, [1, 77, 1024]> tensor_29_cast = mul(x = var_458_cast, y = var_459_to_fp16);
            tensor<fp16, [1024, 1024]> text_encoder_text_model_encoder_layers_4_self_attn_k_proj_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_4_self_attn_k_proj_weight_to_fp16"), val = tensor<fp16, [1024, 1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(204234880)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_4_self_attn_k_proj_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_4_self_attn_k_proj_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(206332096)))];
            tensor<fp16, [1, 77, 1024]> tensor_25_cast = linear(bias = text_encoder_text_model_encoder_layers_4_self_attn_k_proj_bias_to_fp16, weight = text_encoder_text_model_encoder_layers_4_self_attn_k_proj_weight_to_fp16, x = hidden_states_25_cast);
            tensor<int32, [4]> var_464 = const()[name = tensor<string, []>("op_464"), val = tensor<int32, [4]>([1, -1, 16, 64])];
            tensor<fp16, [1, 77, 16, 64]> var_465_cast = reshape(shape = var_464, x = tensor_25_cast);
            tensor<int32, [4]> var_466_perm_0 = const()[name = tensor<string, []>("op_466_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<fp16, [1024, 1024]> text_encoder_text_model_encoder_layers_4_self_attn_v_proj_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_4_self_attn_v_proj_weight_to_fp16"), val = tensor<fp16, [1024, 1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(206334208)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_4_self_attn_v_proj_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_4_self_attn_v_proj_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(208431424)))];
            tensor<fp16, [1, 77, 1024]> tensor_27_cast = linear(bias = text_encoder_text_model_encoder_layers_4_self_attn_v_proj_bias_to_fp16, weight = text_encoder_text_model_encoder_layers_4_self_attn_v_proj_weight_to_fp16, x = hidden_states_25_cast);
            tensor<int32, [4]> var_471 = const()[name = tensor<string, []>("op_471"), val = tensor<int32, [4]>([1, -1, 16, 64])];
            tensor<fp16, [1, 77, 16, 64]> var_472_cast = reshape(shape = var_471, x = tensor_27_cast);
            tensor<int32, [4]> var_473_perm_0 = const()[name = tensor<string, []>("op_473_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<int32, [4]> var_480 = const()[name = tensor<string, []>("op_480"), val = tensor<int32, [4]>([1, 77, 16, 64])];
            tensor<fp16, [1, 77, 16, 64]> var_481_cast = reshape(shape = var_480, x = tensor_29_cast);
            tensor<int32, [4]> var_482_perm_0 = const()[name = tensor<string, []>("op_482_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<int32, [3]> var_484 = const()[name = tensor<string, []>("op_484"), val = tensor<int32, [3]>([16, -1, 64])];
            tensor<fp16, [1, 16, 77, 64]> transpose_93 = transpose(perm = var_482_perm_0, x = var_481_cast);
            tensor<fp16, [16, 77, 64]> query_states_9_cast = reshape(shape = var_484, x = transpose_93);
            tensor<int32, [3]> var_486 = const()[name = tensor<string, []>("op_486"), val = tensor<int32, [3]>([16, -1, 64])];
            tensor<fp16, [1, 16, 77, 64]> transpose_95 = transpose(perm = var_466_perm_0, x = var_465_cast);
            tensor<fp16, [16, 77, 64]> key_states_19_cast = reshape(shape = var_486, x = transpose_95);
            tensor<int32, [3]> var_488 = const()[name = tensor<string, []>("op_488"), val = tensor<int32, [3]>([16, -1, 64])];
            tensor<fp16, [1, 16, 77, 64]> transpose_94 = transpose(perm = var_473_perm_0, x = var_472_cast);
            tensor<fp16, [16, 77, 64]> value_states_19_cast = reshape(shape = var_488, x = transpose_94);
            tensor<int32, [3]> var_491_perm_0 = const()[name = tensor<string, []>("op_491_perm_0"), val = tensor<int32, [3]>([0, 2, 1])];
            tensor<bool, []> attn_weights_25_transpose_x_0 = const()[name = tensor<string, []>("attn_weights_25_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> attn_weights_25_transpose_y_0 = const()[name = tensor<string, []>("attn_weights_25_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [16, 64, 77]> transpose_92 = transpose(perm = var_491_perm_0, x = key_states_19_cast);
            tensor<fp16, [16, 77, 77]> attn_weights_25_cast = matmul(transpose_x = attn_weights_25_transpose_x_0, transpose_y = attn_weights_25_transpose_y_0, x = query_states_9_cast, y = transpose_92);
            tensor<int32, [4]> var_493 = const()[name = tensor<string, []>("op_493"), val = tensor<int32, [4]>([1, 16, 77, 77])];
            tensor<fp16, [1, 16, 77, 77]> var_494_cast = reshape(shape = var_493, x = attn_weights_25_cast);
            tensor<fp16, [1, 16, 77, 77]> attn_weights_27_cast = add(x = var_494_cast, y = var_44_cast);
            tensor<int32, [3]> var_499 = const()[name = tensor<string, []>("op_499"), val = tensor<int32, [3]>([16, 77, 77])];
            tensor<fp16, [16, 77, 77]> input_69_cast = reshape(shape = var_499, x = attn_weights_27_cast);
            tensor<fp16, [16, 77, 77]> input_71_cast = softmax(axis = var_5, x = input_69_cast);
            tensor<bool, []> attn_output_25_transpose_x_0 = const()[name = tensor<string, []>("attn_output_25_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> attn_output_25_transpose_y_0 = const()[name = tensor<string, []>("attn_output_25_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [16, 77, 64]> attn_output_25_cast = matmul(transpose_x = attn_output_25_transpose_x_0, transpose_y = attn_output_25_transpose_y_0, x = input_71_cast, y = value_states_19_cast);
            tensor<int32, [4]> var_504 = const()[name = tensor<string, []>("op_504"), val = tensor<int32, [4]>([1, 16, 77, 64])];
            tensor<fp16, [1, 16, 77, 64]> attn_output_27_cast = reshape(shape = var_504, x = attn_output_25_cast);
            tensor<int32, [4]> attn_output_29_perm_0 = const()[name = tensor<string, []>("attn_output_29_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<int32, [3]> var_507 = const()[name = tensor<string, []>("op_507"), val = tensor<int32, [3]>([1, 77, 1024])];
            tensor<fp16, [1, 77, 16, 64]> transpose_91 = transpose(perm = attn_output_29_perm_0, x = attn_output_27_cast);
            tensor<fp16, [1, 77, 1024]> input_73_cast = reshape(shape = var_507, x = transpose_91);
            tensor<fp16, [1024, 1024]> text_encoder_text_model_encoder_layers_4_self_attn_out_proj_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_4_self_attn_out_proj_weight_to_fp16"), val = tensor<fp16, [1024, 1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(208433536)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_4_self_attn_out_proj_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_4_self_attn_out_proj_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(210530752)))];
            tensor<fp16, [1, 77, 1024]> hidden_states_27_cast = linear(bias = text_encoder_text_model_encoder_layers_4_self_attn_out_proj_bias_to_fp16, weight = text_encoder_text_model_encoder_layers_4_self_attn_out_proj_weight_to_fp16, x = input_73_cast);
            tensor<fp16, [1, 77, 1024]> input_75_cast = add(x = input_67_cast, y = hidden_states_27_cast);
            tensor<int32, [1]> input_77_axes_0 = const()[name = tensor<string, []>("input_77_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_4_layer_norm2_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_4_layer_norm2_weight_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(210532864)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_4_layer_norm2_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_4_layer_norm2_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(210534976)))];
            tensor<fp16, [1, 77, 1024]> input_77_cast = layer_norm(axes = input_77_axes_0, beta = text_encoder_text_model_encoder_layers_4_layer_norm2_bias_to_fp16, epsilon = var_12_to_fp16, gamma = text_encoder_text_model_encoder_layers_4_layer_norm2_weight_to_fp16, x = input_75_cast);
            tensor<fp16, [4096, 1024]> text_encoder_text_model_encoder_layers_4_mlp_fc1_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_4_mlp_fc1_weight_to_fp16"), val = tensor<fp16, [4096, 1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(210537088)))];
            tensor<fp16, [4096]> text_encoder_text_model_encoder_layers_4_mlp_fc1_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_4_mlp_fc1_bias_to_fp16"), val = tensor<fp16, [4096]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(218925760)))];
            tensor<fp16, [1, 77, 4096]> input_79_cast = linear(bias = text_encoder_text_model_encoder_layers_4_mlp_fc1_bias_to_fp16, weight = text_encoder_text_model_encoder_layers_4_mlp_fc1_weight_to_fp16, x = input_77_cast);
            tensor<string, []> input_81_mode_0 = const()[name = tensor<string, []>("input_81_mode_0"), val = tensor<string, []>("EXACT")];
            tensor<fp16, [1, 77, 4096]> input_81_cast = gelu(mode = input_81_mode_0, x = input_79_cast);
            tensor<fp16, [1024, 4096]> text_encoder_text_model_encoder_layers_4_mlp_fc2_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_4_mlp_fc2_weight_to_fp16"), val = tensor<fp16, [1024, 4096]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(218934016)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_4_mlp_fc2_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_4_mlp_fc2_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(227322688)))];
            tensor<fp16, [1, 77, 1024]> hidden_states_29_cast = linear(bias = text_encoder_text_model_encoder_layers_4_mlp_fc2_bias_to_fp16, weight = text_encoder_text_model_encoder_layers_4_mlp_fc2_weight_to_fp16, x = input_81_cast);
            tensor<fp16, [1, 77, 1024]> input_83_cast = add(x = input_75_cast, y = hidden_states_29_cast);
            tensor<int32, [1]> hidden_states_31_axes_0 = const()[name = tensor<string, []>("hidden_states_31_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_5_layer_norm1_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_5_layer_norm1_weight_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(227324800)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_5_layer_norm1_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_5_layer_norm1_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(227326912)))];
            tensor<fp16, [1, 77, 1024]> hidden_states_31_cast = layer_norm(axes = hidden_states_31_axes_0, beta = text_encoder_text_model_encoder_layers_5_layer_norm1_bias_to_fp16, epsilon = var_12_to_fp16, gamma = text_encoder_text_model_encoder_layers_5_layer_norm1_weight_to_fp16, x = input_83_cast);
            tensor<fp16, [1024, 1024]> text_encoder_text_model_encoder_layers_5_self_attn_q_proj_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_5_self_attn_q_proj_weight_to_fp16"), val = tensor<fp16, [1024, 1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(227329024)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_5_self_attn_q_proj_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_5_self_attn_q_proj_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(229426240)))];
            tensor<fp16, [1, 77, 1024]> var_545_cast = linear(bias = text_encoder_text_model_encoder_layers_5_self_attn_q_proj_bias_to_fp16, weight = text_encoder_text_model_encoder_layers_5_self_attn_q_proj_weight_to_fp16, x = hidden_states_31_cast);
            tensor<fp16, []> var_546_to_fp16 = const()[name = tensor<string, []>("op_546_to_fp16"), val = tensor<fp16, []>(0x1p-3)];
            tensor<fp16, [1, 77, 1024]> tensor_35_cast = mul(x = var_545_cast, y = var_546_to_fp16);
            tensor<fp16, [1024, 1024]> text_encoder_text_model_encoder_layers_5_self_attn_k_proj_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_5_self_attn_k_proj_weight_to_fp16"), val = tensor<fp16, [1024, 1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(229428352)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_5_self_attn_k_proj_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_5_self_attn_k_proj_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(231525568)))];
            tensor<fp16, [1, 77, 1024]> tensor_31_cast = linear(bias = text_encoder_text_model_encoder_layers_5_self_attn_k_proj_bias_to_fp16, weight = text_encoder_text_model_encoder_layers_5_self_attn_k_proj_weight_to_fp16, x = hidden_states_31_cast);
            tensor<int32, [4]> var_551 = const()[name = tensor<string, []>("op_551"), val = tensor<int32, [4]>([1, -1, 16, 64])];
            tensor<fp16, [1, 77, 16, 64]> var_552_cast = reshape(shape = var_551, x = tensor_31_cast);
            tensor<int32, [4]> var_553_perm_0 = const()[name = tensor<string, []>("op_553_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<fp16, [1024, 1024]> text_encoder_text_model_encoder_layers_5_self_attn_v_proj_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_5_self_attn_v_proj_weight_to_fp16"), val = tensor<fp16, [1024, 1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(231527680)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_5_self_attn_v_proj_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_5_self_attn_v_proj_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(233624896)))];
            tensor<fp16, [1, 77, 1024]> tensor_33_cast = linear(bias = text_encoder_text_model_encoder_layers_5_self_attn_v_proj_bias_to_fp16, weight = text_encoder_text_model_encoder_layers_5_self_attn_v_proj_weight_to_fp16, x = hidden_states_31_cast);
            tensor<int32, [4]> var_558 = const()[name = tensor<string, []>("op_558"), val = tensor<int32, [4]>([1, -1, 16, 64])];
            tensor<fp16, [1, 77, 16, 64]> var_559_cast = reshape(shape = var_558, x = tensor_33_cast);
            tensor<int32, [4]> var_560_perm_0 = const()[name = tensor<string, []>("op_560_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<int32, [4]> var_567 = const()[name = tensor<string, []>("op_567"), val = tensor<int32, [4]>([1, 77, 16, 64])];
            tensor<fp16, [1, 77, 16, 64]> var_568_cast = reshape(shape = var_567, x = tensor_35_cast);
            tensor<int32, [4]> var_569_perm_0 = const()[name = tensor<string, []>("op_569_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<int32, [3]> var_571 = const()[name = tensor<string, []>("op_571"), val = tensor<int32, [3]>([16, -1, 64])];
            tensor<fp16, [1, 16, 77, 64]> transpose_88 = transpose(perm = var_569_perm_0, x = var_568_cast);
            tensor<fp16, [16, 77, 64]> query_states_11_cast = reshape(shape = var_571, x = transpose_88);
            tensor<int32, [3]> var_573 = const()[name = tensor<string, []>("op_573"), val = tensor<int32, [3]>([16, -1, 64])];
            tensor<fp16, [1, 16, 77, 64]> transpose_90 = transpose(perm = var_553_perm_0, x = var_552_cast);
            tensor<fp16, [16, 77, 64]> key_states_23_cast = reshape(shape = var_573, x = transpose_90);
            tensor<int32, [3]> var_575 = const()[name = tensor<string, []>("op_575"), val = tensor<int32, [3]>([16, -1, 64])];
            tensor<fp16, [1, 16, 77, 64]> transpose_89 = transpose(perm = var_560_perm_0, x = var_559_cast);
            tensor<fp16, [16, 77, 64]> value_states_23_cast = reshape(shape = var_575, x = transpose_89);
            tensor<int32, [3]> var_578_perm_0 = const()[name = tensor<string, []>("op_578_perm_0"), val = tensor<int32, [3]>([0, 2, 1])];
            tensor<bool, []> attn_weights_31_transpose_x_0 = const()[name = tensor<string, []>("attn_weights_31_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> attn_weights_31_transpose_y_0 = const()[name = tensor<string, []>("attn_weights_31_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [16, 64, 77]> transpose_87 = transpose(perm = var_578_perm_0, x = key_states_23_cast);
            tensor<fp16, [16, 77, 77]> attn_weights_31_cast = matmul(transpose_x = attn_weights_31_transpose_x_0, transpose_y = attn_weights_31_transpose_y_0, x = query_states_11_cast, y = transpose_87);
            tensor<int32, [4]> var_580 = const()[name = tensor<string, []>("op_580"), val = tensor<int32, [4]>([1, 16, 77, 77])];
            tensor<fp16, [1, 16, 77, 77]> var_581_cast = reshape(shape = var_580, x = attn_weights_31_cast);
            tensor<fp16, [1, 16, 77, 77]> attn_weights_33_cast = add(x = var_581_cast, y = var_44_cast);
            tensor<int32, [3]> var_586 = const()[name = tensor<string, []>("op_586"), val = tensor<int32, [3]>([16, 77, 77])];
            tensor<fp16, [16, 77, 77]> input_85_cast = reshape(shape = var_586, x = attn_weights_33_cast);
            tensor<fp16, [16, 77, 77]> input_87_cast = softmax(axis = var_5, x = input_85_cast);
            tensor<bool, []> attn_output_31_transpose_x_0 = const()[name = tensor<string, []>("attn_output_31_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> attn_output_31_transpose_y_0 = const()[name = tensor<string, []>("attn_output_31_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [16, 77, 64]> attn_output_31_cast = matmul(transpose_x = attn_output_31_transpose_x_0, transpose_y = attn_output_31_transpose_y_0, x = input_87_cast, y = value_states_23_cast);
            tensor<int32, [4]> var_591 = const()[name = tensor<string, []>("op_591"), val = tensor<int32, [4]>([1, 16, 77, 64])];
            tensor<fp16, [1, 16, 77, 64]> attn_output_33_cast = reshape(shape = var_591, x = attn_output_31_cast);
            tensor<int32, [4]> attn_output_35_perm_0 = const()[name = tensor<string, []>("attn_output_35_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<int32, [3]> var_594 = const()[name = tensor<string, []>("op_594"), val = tensor<int32, [3]>([1, 77, 1024])];
            tensor<fp16, [1, 77, 16, 64]> transpose_86 = transpose(perm = attn_output_35_perm_0, x = attn_output_33_cast);
            tensor<fp16, [1, 77, 1024]> input_89_cast = reshape(shape = var_594, x = transpose_86);
            tensor<fp16, [1024, 1024]> text_encoder_text_model_encoder_layers_5_self_attn_out_proj_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_5_self_attn_out_proj_weight_to_fp16"), val = tensor<fp16, [1024, 1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(233627008)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_5_self_attn_out_proj_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_5_self_attn_out_proj_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(235724224)))];
            tensor<fp16, [1, 77, 1024]> hidden_states_33_cast = linear(bias = text_encoder_text_model_encoder_layers_5_self_attn_out_proj_bias_to_fp16, weight = text_encoder_text_model_encoder_layers_5_self_attn_out_proj_weight_to_fp16, x = input_89_cast);
            tensor<fp16, [1, 77, 1024]> input_91_cast = add(x = input_83_cast, y = hidden_states_33_cast);
            tensor<int32, [1]> input_93_axes_0 = const()[name = tensor<string, []>("input_93_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_5_layer_norm2_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_5_layer_norm2_weight_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(235726336)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_5_layer_norm2_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_5_layer_norm2_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(235728448)))];
            tensor<fp16, [1, 77, 1024]> input_93_cast = layer_norm(axes = input_93_axes_0, beta = text_encoder_text_model_encoder_layers_5_layer_norm2_bias_to_fp16, epsilon = var_12_to_fp16, gamma = text_encoder_text_model_encoder_layers_5_layer_norm2_weight_to_fp16, x = input_91_cast);
            tensor<fp16, [4096, 1024]> text_encoder_text_model_encoder_layers_5_mlp_fc1_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_5_mlp_fc1_weight_to_fp16"), val = tensor<fp16, [4096, 1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(235730560)))];
            tensor<fp16, [4096]> text_encoder_text_model_encoder_layers_5_mlp_fc1_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_5_mlp_fc1_bias_to_fp16"), val = tensor<fp16, [4096]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(244119232)))];
            tensor<fp16, [1, 77, 4096]> input_95_cast = linear(bias = text_encoder_text_model_encoder_layers_5_mlp_fc1_bias_to_fp16, weight = text_encoder_text_model_encoder_layers_5_mlp_fc1_weight_to_fp16, x = input_93_cast);
            tensor<string, []> input_97_mode_0 = const()[name = tensor<string, []>("input_97_mode_0"), val = tensor<string, []>("EXACT")];
            tensor<fp16, [1, 77, 4096]> input_97_cast = gelu(mode = input_97_mode_0, x = input_95_cast);
            tensor<fp16, [1024, 4096]> text_encoder_text_model_encoder_layers_5_mlp_fc2_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_5_mlp_fc2_weight_to_fp16"), val = tensor<fp16, [1024, 4096]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(244127488)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_5_mlp_fc2_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_5_mlp_fc2_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(252516160)))];
            tensor<fp16, [1, 77, 1024]> hidden_states_35_cast = linear(bias = text_encoder_text_model_encoder_layers_5_mlp_fc2_bias_to_fp16, weight = text_encoder_text_model_encoder_layers_5_mlp_fc2_weight_to_fp16, x = input_97_cast);
            tensor<fp16, [1, 77, 1024]> input_99_cast = add(x = input_91_cast, y = hidden_states_35_cast);
            tensor<int32, [1]> hidden_states_37_axes_0 = const()[name = tensor<string, []>("hidden_states_37_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_6_layer_norm1_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_6_layer_norm1_weight_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(252518272)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_6_layer_norm1_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_6_layer_norm1_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(252520384)))];
            tensor<fp16, [1, 77, 1024]> hidden_states_37_cast = layer_norm(axes = hidden_states_37_axes_0, beta = text_encoder_text_model_encoder_layers_6_layer_norm1_bias_to_fp16, epsilon = var_12_to_fp16, gamma = text_encoder_text_model_encoder_layers_6_layer_norm1_weight_to_fp16, x = input_99_cast);
            tensor<fp16, [1024, 1024]> text_encoder_text_model_encoder_layers_6_self_attn_q_proj_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_6_self_attn_q_proj_weight_to_fp16"), val = tensor<fp16, [1024, 1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(252522496)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_6_self_attn_q_proj_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_6_self_attn_q_proj_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(254619712)))];
            tensor<fp16, [1, 77, 1024]> var_632_cast = linear(bias = text_encoder_text_model_encoder_layers_6_self_attn_q_proj_bias_to_fp16, weight = text_encoder_text_model_encoder_layers_6_self_attn_q_proj_weight_to_fp16, x = hidden_states_37_cast);
            tensor<fp16, []> var_633_to_fp16 = const()[name = tensor<string, []>("op_633_to_fp16"), val = tensor<fp16, []>(0x1p-3)];
            tensor<fp16, [1, 77, 1024]> tensor_41_cast = mul(x = var_632_cast, y = var_633_to_fp16);
            tensor<fp16, [1024, 1024]> text_encoder_text_model_encoder_layers_6_self_attn_k_proj_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_6_self_attn_k_proj_weight_to_fp16"), val = tensor<fp16, [1024, 1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(254621824)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_6_self_attn_k_proj_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_6_self_attn_k_proj_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(256719040)))];
            tensor<fp16, [1, 77, 1024]> tensor_37_cast = linear(bias = text_encoder_text_model_encoder_layers_6_self_attn_k_proj_bias_to_fp16, weight = text_encoder_text_model_encoder_layers_6_self_attn_k_proj_weight_to_fp16, x = hidden_states_37_cast);
            tensor<int32, [4]> var_638 = const()[name = tensor<string, []>("op_638"), val = tensor<int32, [4]>([1, -1, 16, 64])];
            tensor<fp16, [1, 77, 16, 64]> var_639_cast = reshape(shape = var_638, x = tensor_37_cast);
            tensor<int32, [4]> var_640_perm_0 = const()[name = tensor<string, []>("op_640_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<fp16, [1024, 1024]> text_encoder_text_model_encoder_layers_6_self_attn_v_proj_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_6_self_attn_v_proj_weight_to_fp16"), val = tensor<fp16, [1024, 1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(256721152)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_6_self_attn_v_proj_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_6_self_attn_v_proj_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(258818368)))];
            tensor<fp16, [1, 77, 1024]> tensor_39_cast = linear(bias = text_encoder_text_model_encoder_layers_6_self_attn_v_proj_bias_to_fp16, weight = text_encoder_text_model_encoder_layers_6_self_attn_v_proj_weight_to_fp16, x = hidden_states_37_cast);
            tensor<int32, [4]> var_645 = const()[name = tensor<string, []>("op_645"), val = tensor<int32, [4]>([1, -1, 16, 64])];
            tensor<fp16, [1, 77, 16, 64]> var_646_cast = reshape(shape = var_645, x = tensor_39_cast);
            tensor<int32, [4]> var_647_perm_0 = const()[name = tensor<string, []>("op_647_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<int32, [4]> var_654 = const()[name = tensor<string, []>("op_654"), val = tensor<int32, [4]>([1, 77, 16, 64])];
            tensor<fp16, [1, 77, 16, 64]> var_655_cast = reshape(shape = var_654, x = tensor_41_cast);
            tensor<int32, [4]> var_656_perm_0 = const()[name = tensor<string, []>("op_656_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<int32, [3]> var_658 = const()[name = tensor<string, []>("op_658"), val = tensor<int32, [3]>([16, -1, 64])];
            tensor<fp16, [1, 16, 77, 64]> transpose_83 = transpose(perm = var_656_perm_0, x = var_655_cast);
            tensor<fp16, [16, 77, 64]> query_states_13_cast = reshape(shape = var_658, x = transpose_83);
            tensor<int32, [3]> var_660 = const()[name = tensor<string, []>("op_660"), val = tensor<int32, [3]>([16, -1, 64])];
            tensor<fp16, [1, 16, 77, 64]> transpose_85 = transpose(perm = var_640_perm_0, x = var_639_cast);
            tensor<fp16, [16, 77, 64]> key_states_27_cast = reshape(shape = var_660, x = transpose_85);
            tensor<int32, [3]> var_662 = const()[name = tensor<string, []>("op_662"), val = tensor<int32, [3]>([16, -1, 64])];
            tensor<fp16, [1, 16, 77, 64]> transpose_84 = transpose(perm = var_647_perm_0, x = var_646_cast);
            tensor<fp16, [16, 77, 64]> value_states_27_cast = reshape(shape = var_662, x = transpose_84);
            tensor<int32, [3]> var_665_perm_0 = const()[name = tensor<string, []>("op_665_perm_0"), val = tensor<int32, [3]>([0, 2, 1])];
            tensor<bool, []> attn_weights_37_transpose_x_0 = const()[name = tensor<string, []>("attn_weights_37_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> attn_weights_37_transpose_y_0 = const()[name = tensor<string, []>("attn_weights_37_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [16, 64, 77]> transpose_82 = transpose(perm = var_665_perm_0, x = key_states_27_cast);
            tensor<fp16, [16, 77, 77]> attn_weights_37_cast = matmul(transpose_x = attn_weights_37_transpose_x_0, transpose_y = attn_weights_37_transpose_y_0, x = query_states_13_cast, y = transpose_82);
            tensor<int32, [4]> var_667 = const()[name = tensor<string, []>("op_667"), val = tensor<int32, [4]>([1, 16, 77, 77])];
            tensor<fp16, [1, 16, 77, 77]> var_668_cast = reshape(shape = var_667, x = attn_weights_37_cast);
            tensor<fp16, [1, 16, 77, 77]> attn_weights_39_cast = add(x = var_668_cast, y = var_44_cast);
            tensor<int32, [3]> var_673 = const()[name = tensor<string, []>("op_673"), val = tensor<int32, [3]>([16, 77, 77])];
            tensor<fp16, [16, 77, 77]> input_101_cast = reshape(shape = var_673, x = attn_weights_39_cast);
            tensor<fp16, [16, 77, 77]> input_103_cast = softmax(axis = var_5, x = input_101_cast);
            tensor<bool, []> attn_output_37_transpose_x_0 = const()[name = tensor<string, []>("attn_output_37_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> attn_output_37_transpose_y_0 = const()[name = tensor<string, []>("attn_output_37_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [16, 77, 64]> attn_output_37_cast = matmul(transpose_x = attn_output_37_transpose_x_0, transpose_y = attn_output_37_transpose_y_0, x = input_103_cast, y = value_states_27_cast);
            tensor<int32, [4]> var_678 = const()[name = tensor<string, []>("op_678"), val = tensor<int32, [4]>([1, 16, 77, 64])];
            tensor<fp16, [1, 16, 77, 64]> attn_output_39_cast = reshape(shape = var_678, x = attn_output_37_cast);
            tensor<int32, [4]> attn_output_41_perm_0 = const()[name = tensor<string, []>("attn_output_41_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<int32, [3]> var_681 = const()[name = tensor<string, []>("op_681"), val = tensor<int32, [3]>([1, 77, 1024])];
            tensor<fp16, [1, 77, 16, 64]> transpose_81 = transpose(perm = attn_output_41_perm_0, x = attn_output_39_cast);
            tensor<fp16, [1, 77, 1024]> input_105_cast = reshape(shape = var_681, x = transpose_81);
            tensor<fp16, [1024, 1024]> text_encoder_text_model_encoder_layers_6_self_attn_out_proj_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_6_self_attn_out_proj_weight_to_fp16"), val = tensor<fp16, [1024, 1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(258820480)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_6_self_attn_out_proj_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_6_self_attn_out_proj_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(260917696)))];
            tensor<fp16, [1, 77, 1024]> hidden_states_39_cast = linear(bias = text_encoder_text_model_encoder_layers_6_self_attn_out_proj_bias_to_fp16, weight = text_encoder_text_model_encoder_layers_6_self_attn_out_proj_weight_to_fp16, x = input_105_cast);
            tensor<fp16, [1, 77, 1024]> input_107_cast = add(x = input_99_cast, y = hidden_states_39_cast);
            tensor<int32, [1]> input_109_axes_0 = const()[name = tensor<string, []>("input_109_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_6_layer_norm2_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_6_layer_norm2_weight_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(260919808)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_6_layer_norm2_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_6_layer_norm2_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(260921920)))];
            tensor<fp16, [1, 77, 1024]> input_109_cast = layer_norm(axes = input_109_axes_0, beta = text_encoder_text_model_encoder_layers_6_layer_norm2_bias_to_fp16, epsilon = var_12_to_fp16, gamma = text_encoder_text_model_encoder_layers_6_layer_norm2_weight_to_fp16, x = input_107_cast);
            tensor<fp16, [4096, 1024]> text_encoder_text_model_encoder_layers_6_mlp_fc1_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_6_mlp_fc1_weight_to_fp16"), val = tensor<fp16, [4096, 1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(260924032)))];
            tensor<fp16, [4096]> text_encoder_text_model_encoder_layers_6_mlp_fc1_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_6_mlp_fc1_bias_to_fp16"), val = tensor<fp16, [4096]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(269312704)))];
            tensor<fp16, [1, 77, 4096]> input_111_cast = linear(bias = text_encoder_text_model_encoder_layers_6_mlp_fc1_bias_to_fp16, weight = text_encoder_text_model_encoder_layers_6_mlp_fc1_weight_to_fp16, x = input_109_cast);
            tensor<string, []> input_113_mode_0 = const()[name = tensor<string, []>("input_113_mode_0"), val = tensor<string, []>("EXACT")];
            tensor<fp16, [1, 77, 4096]> input_113_cast = gelu(mode = input_113_mode_0, x = input_111_cast);
            tensor<fp16, [1024, 4096]> text_encoder_text_model_encoder_layers_6_mlp_fc2_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_6_mlp_fc2_weight_to_fp16"), val = tensor<fp16, [1024, 4096]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(269320960)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_6_mlp_fc2_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_6_mlp_fc2_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(277709632)))];
            tensor<fp16, [1, 77, 1024]> hidden_states_41_cast = linear(bias = text_encoder_text_model_encoder_layers_6_mlp_fc2_bias_to_fp16, weight = text_encoder_text_model_encoder_layers_6_mlp_fc2_weight_to_fp16, x = input_113_cast);
            tensor<fp16, [1, 77, 1024]> input_115_cast = add(x = input_107_cast, y = hidden_states_41_cast);
            tensor<int32, [1]> hidden_states_43_axes_0 = const()[name = tensor<string, []>("hidden_states_43_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_7_layer_norm1_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_7_layer_norm1_weight_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(277711744)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_7_layer_norm1_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_7_layer_norm1_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(277713856)))];
            tensor<fp16, [1, 77, 1024]> hidden_states_43_cast = layer_norm(axes = hidden_states_43_axes_0, beta = text_encoder_text_model_encoder_layers_7_layer_norm1_bias_to_fp16, epsilon = var_12_to_fp16, gamma = text_encoder_text_model_encoder_layers_7_layer_norm1_weight_to_fp16, x = input_115_cast);
            tensor<fp16, [1024, 1024]> text_encoder_text_model_encoder_layers_7_self_attn_q_proj_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_7_self_attn_q_proj_weight_to_fp16"), val = tensor<fp16, [1024, 1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(277715968)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_7_self_attn_q_proj_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_7_self_attn_q_proj_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(279813184)))];
            tensor<fp16, [1, 77, 1024]> var_719_cast = linear(bias = text_encoder_text_model_encoder_layers_7_self_attn_q_proj_bias_to_fp16, weight = text_encoder_text_model_encoder_layers_7_self_attn_q_proj_weight_to_fp16, x = hidden_states_43_cast);
            tensor<fp16, []> var_720_to_fp16 = const()[name = tensor<string, []>("op_720_to_fp16"), val = tensor<fp16, []>(0x1p-3)];
            tensor<fp16, [1, 77, 1024]> tensor_47_cast = mul(x = var_719_cast, y = var_720_to_fp16);
            tensor<fp16, [1024, 1024]> text_encoder_text_model_encoder_layers_7_self_attn_k_proj_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_7_self_attn_k_proj_weight_to_fp16"), val = tensor<fp16, [1024, 1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(279815296)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_7_self_attn_k_proj_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_7_self_attn_k_proj_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(281912512)))];
            tensor<fp16, [1, 77, 1024]> tensor_43_cast = linear(bias = text_encoder_text_model_encoder_layers_7_self_attn_k_proj_bias_to_fp16, weight = text_encoder_text_model_encoder_layers_7_self_attn_k_proj_weight_to_fp16, x = hidden_states_43_cast);
            tensor<int32, [4]> var_725 = const()[name = tensor<string, []>("op_725"), val = tensor<int32, [4]>([1, -1, 16, 64])];
            tensor<fp16, [1, 77, 16, 64]> var_726_cast = reshape(shape = var_725, x = tensor_43_cast);
            tensor<int32, [4]> var_727_perm_0 = const()[name = tensor<string, []>("op_727_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<fp16, [1024, 1024]> text_encoder_text_model_encoder_layers_7_self_attn_v_proj_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_7_self_attn_v_proj_weight_to_fp16"), val = tensor<fp16, [1024, 1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(281914624)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_7_self_attn_v_proj_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_7_self_attn_v_proj_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(284011840)))];
            tensor<fp16, [1, 77, 1024]> tensor_45_cast = linear(bias = text_encoder_text_model_encoder_layers_7_self_attn_v_proj_bias_to_fp16, weight = text_encoder_text_model_encoder_layers_7_self_attn_v_proj_weight_to_fp16, x = hidden_states_43_cast);
            tensor<int32, [4]> var_732 = const()[name = tensor<string, []>("op_732"), val = tensor<int32, [4]>([1, -1, 16, 64])];
            tensor<fp16, [1, 77, 16, 64]> var_733_cast = reshape(shape = var_732, x = tensor_45_cast);
            tensor<int32, [4]> var_734_perm_0 = const()[name = tensor<string, []>("op_734_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<int32, [4]> var_741 = const()[name = tensor<string, []>("op_741"), val = tensor<int32, [4]>([1, 77, 16, 64])];
            tensor<fp16, [1, 77, 16, 64]> var_742_cast = reshape(shape = var_741, x = tensor_47_cast);
            tensor<int32, [4]> var_743_perm_0 = const()[name = tensor<string, []>("op_743_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<int32, [3]> var_745 = const()[name = tensor<string, []>("op_745"), val = tensor<int32, [3]>([16, -1, 64])];
            tensor<fp16, [1, 16, 77, 64]> transpose_78 = transpose(perm = var_743_perm_0, x = var_742_cast);
            tensor<fp16, [16, 77, 64]> query_states_15_cast = reshape(shape = var_745, x = transpose_78);
            tensor<int32, [3]> var_747 = const()[name = tensor<string, []>("op_747"), val = tensor<int32, [3]>([16, -1, 64])];
            tensor<fp16, [1, 16, 77, 64]> transpose_80 = transpose(perm = var_727_perm_0, x = var_726_cast);
            tensor<fp16, [16, 77, 64]> key_states_31_cast = reshape(shape = var_747, x = transpose_80);
            tensor<int32, [3]> var_749 = const()[name = tensor<string, []>("op_749"), val = tensor<int32, [3]>([16, -1, 64])];
            tensor<fp16, [1, 16, 77, 64]> transpose_79 = transpose(perm = var_734_perm_0, x = var_733_cast);
            tensor<fp16, [16, 77, 64]> value_states_31_cast = reshape(shape = var_749, x = transpose_79);
            tensor<int32, [3]> var_752_perm_0 = const()[name = tensor<string, []>("op_752_perm_0"), val = tensor<int32, [3]>([0, 2, 1])];
            tensor<bool, []> attn_weights_43_transpose_x_0 = const()[name = tensor<string, []>("attn_weights_43_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> attn_weights_43_transpose_y_0 = const()[name = tensor<string, []>("attn_weights_43_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [16, 64, 77]> transpose_77 = transpose(perm = var_752_perm_0, x = key_states_31_cast);
            tensor<fp16, [16, 77, 77]> attn_weights_43_cast = matmul(transpose_x = attn_weights_43_transpose_x_0, transpose_y = attn_weights_43_transpose_y_0, x = query_states_15_cast, y = transpose_77);
            tensor<int32, [4]> var_754 = const()[name = tensor<string, []>("op_754"), val = tensor<int32, [4]>([1, 16, 77, 77])];
            tensor<fp16, [1, 16, 77, 77]> var_755_cast = reshape(shape = var_754, x = attn_weights_43_cast);
            tensor<fp16, [1, 16, 77, 77]> attn_weights_45_cast = add(x = var_755_cast, y = var_44_cast);
            tensor<int32, [3]> var_760 = const()[name = tensor<string, []>("op_760"), val = tensor<int32, [3]>([16, 77, 77])];
            tensor<fp16, [16, 77, 77]> input_117_cast = reshape(shape = var_760, x = attn_weights_45_cast);
            tensor<fp16, [16, 77, 77]> input_119_cast = softmax(axis = var_5, x = input_117_cast);
            tensor<bool, []> attn_output_43_transpose_x_0 = const()[name = tensor<string, []>("attn_output_43_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> attn_output_43_transpose_y_0 = const()[name = tensor<string, []>("attn_output_43_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [16, 77, 64]> attn_output_43_cast = matmul(transpose_x = attn_output_43_transpose_x_0, transpose_y = attn_output_43_transpose_y_0, x = input_119_cast, y = value_states_31_cast);
            tensor<int32, [4]> var_765 = const()[name = tensor<string, []>("op_765"), val = tensor<int32, [4]>([1, 16, 77, 64])];
            tensor<fp16, [1, 16, 77, 64]> attn_output_45_cast = reshape(shape = var_765, x = attn_output_43_cast);
            tensor<int32, [4]> attn_output_47_perm_0 = const()[name = tensor<string, []>("attn_output_47_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<int32, [3]> var_768 = const()[name = tensor<string, []>("op_768"), val = tensor<int32, [3]>([1, 77, 1024])];
            tensor<fp16, [1, 77, 16, 64]> transpose_76 = transpose(perm = attn_output_47_perm_0, x = attn_output_45_cast);
            tensor<fp16, [1, 77, 1024]> input_121_cast = reshape(shape = var_768, x = transpose_76);
            tensor<fp16, [1024, 1024]> text_encoder_text_model_encoder_layers_7_self_attn_out_proj_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_7_self_attn_out_proj_weight_to_fp16"), val = tensor<fp16, [1024, 1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(284013952)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_7_self_attn_out_proj_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_7_self_attn_out_proj_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(286111168)))];
            tensor<fp16, [1, 77, 1024]> hidden_states_45_cast = linear(bias = text_encoder_text_model_encoder_layers_7_self_attn_out_proj_bias_to_fp16, weight = text_encoder_text_model_encoder_layers_7_self_attn_out_proj_weight_to_fp16, x = input_121_cast);
            tensor<fp16, [1, 77, 1024]> input_123_cast = add(x = input_115_cast, y = hidden_states_45_cast);
            tensor<int32, [1]> input_125_axes_0 = const()[name = tensor<string, []>("input_125_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_7_layer_norm2_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_7_layer_norm2_weight_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(286113280)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_7_layer_norm2_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_7_layer_norm2_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(286115392)))];
            tensor<fp16, [1, 77, 1024]> input_125_cast = layer_norm(axes = input_125_axes_0, beta = text_encoder_text_model_encoder_layers_7_layer_norm2_bias_to_fp16, epsilon = var_12_to_fp16, gamma = text_encoder_text_model_encoder_layers_7_layer_norm2_weight_to_fp16, x = input_123_cast);
            tensor<fp16, [4096, 1024]> text_encoder_text_model_encoder_layers_7_mlp_fc1_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_7_mlp_fc1_weight_to_fp16"), val = tensor<fp16, [4096, 1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(286117504)))];
            tensor<fp16, [4096]> text_encoder_text_model_encoder_layers_7_mlp_fc1_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_7_mlp_fc1_bias_to_fp16"), val = tensor<fp16, [4096]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(294506176)))];
            tensor<fp16, [1, 77, 4096]> input_127_cast = linear(bias = text_encoder_text_model_encoder_layers_7_mlp_fc1_bias_to_fp16, weight = text_encoder_text_model_encoder_layers_7_mlp_fc1_weight_to_fp16, x = input_125_cast);
            tensor<string, []> input_129_mode_0 = const()[name = tensor<string, []>("input_129_mode_0"), val = tensor<string, []>("EXACT")];
            tensor<fp16, [1, 77, 4096]> input_129_cast = gelu(mode = input_129_mode_0, x = input_127_cast);
            tensor<fp16, [1024, 4096]> text_encoder_text_model_encoder_layers_7_mlp_fc2_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_7_mlp_fc2_weight_to_fp16"), val = tensor<fp16, [1024, 4096]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(294514432)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_7_mlp_fc2_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_7_mlp_fc2_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(302903104)))];
            tensor<fp16, [1, 77, 1024]> hidden_states_47_cast = linear(bias = text_encoder_text_model_encoder_layers_7_mlp_fc2_bias_to_fp16, weight = text_encoder_text_model_encoder_layers_7_mlp_fc2_weight_to_fp16, x = input_129_cast);
            tensor<fp16, [1, 77, 1024]> input_131_cast = add(x = input_123_cast, y = hidden_states_47_cast);
            tensor<int32, [1]> hidden_states_49_axes_0 = const()[name = tensor<string, []>("hidden_states_49_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_8_layer_norm1_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_8_layer_norm1_weight_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(302905216)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_8_layer_norm1_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_8_layer_norm1_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(302907328)))];
            tensor<fp16, [1, 77, 1024]> hidden_states_49_cast = layer_norm(axes = hidden_states_49_axes_0, beta = text_encoder_text_model_encoder_layers_8_layer_norm1_bias_to_fp16, epsilon = var_12_to_fp16, gamma = text_encoder_text_model_encoder_layers_8_layer_norm1_weight_to_fp16, x = input_131_cast);
            tensor<fp16, [1024, 1024]> text_encoder_text_model_encoder_layers_8_self_attn_q_proj_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_8_self_attn_q_proj_weight_to_fp16"), val = tensor<fp16, [1024, 1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(302909440)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_8_self_attn_q_proj_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_8_self_attn_q_proj_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(305006656)))];
            tensor<fp16, [1, 77, 1024]> var_806_cast = linear(bias = text_encoder_text_model_encoder_layers_8_self_attn_q_proj_bias_to_fp16, weight = text_encoder_text_model_encoder_layers_8_self_attn_q_proj_weight_to_fp16, x = hidden_states_49_cast);
            tensor<fp16, []> var_807_to_fp16 = const()[name = tensor<string, []>("op_807_to_fp16"), val = tensor<fp16, []>(0x1p-3)];
            tensor<fp16, [1, 77, 1024]> tensor_53_cast = mul(x = var_806_cast, y = var_807_to_fp16);
            tensor<fp16, [1024, 1024]> text_encoder_text_model_encoder_layers_8_self_attn_k_proj_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_8_self_attn_k_proj_weight_to_fp16"), val = tensor<fp16, [1024, 1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(305008768)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_8_self_attn_k_proj_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_8_self_attn_k_proj_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(307105984)))];
            tensor<fp16, [1, 77, 1024]> tensor_49_cast = linear(bias = text_encoder_text_model_encoder_layers_8_self_attn_k_proj_bias_to_fp16, weight = text_encoder_text_model_encoder_layers_8_self_attn_k_proj_weight_to_fp16, x = hidden_states_49_cast);
            tensor<int32, [4]> var_812 = const()[name = tensor<string, []>("op_812"), val = tensor<int32, [4]>([1, -1, 16, 64])];
            tensor<fp16, [1, 77, 16, 64]> var_813_cast = reshape(shape = var_812, x = tensor_49_cast);
            tensor<int32, [4]> var_814_perm_0 = const()[name = tensor<string, []>("op_814_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<fp16, [1024, 1024]> text_encoder_text_model_encoder_layers_8_self_attn_v_proj_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_8_self_attn_v_proj_weight_to_fp16"), val = tensor<fp16, [1024, 1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(307108096)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_8_self_attn_v_proj_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_8_self_attn_v_proj_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(309205312)))];
            tensor<fp16, [1, 77, 1024]> tensor_51_cast = linear(bias = text_encoder_text_model_encoder_layers_8_self_attn_v_proj_bias_to_fp16, weight = text_encoder_text_model_encoder_layers_8_self_attn_v_proj_weight_to_fp16, x = hidden_states_49_cast);
            tensor<int32, [4]> var_819 = const()[name = tensor<string, []>("op_819"), val = tensor<int32, [4]>([1, -1, 16, 64])];
            tensor<fp16, [1, 77, 16, 64]> var_820_cast = reshape(shape = var_819, x = tensor_51_cast);
            tensor<int32, [4]> var_821_perm_0 = const()[name = tensor<string, []>("op_821_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<int32, [4]> var_828 = const()[name = tensor<string, []>("op_828"), val = tensor<int32, [4]>([1, 77, 16, 64])];
            tensor<fp16, [1, 77, 16, 64]> var_829_cast = reshape(shape = var_828, x = tensor_53_cast);
            tensor<int32, [4]> var_830_perm_0 = const()[name = tensor<string, []>("op_830_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<int32, [3]> var_832 = const()[name = tensor<string, []>("op_832"), val = tensor<int32, [3]>([16, -1, 64])];
            tensor<fp16, [1, 16, 77, 64]> transpose_73 = transpose(perm = var_830_perm_0, x = var_829_cast);
            tensor<fp16, [16, 77, 64]> query_states_17_cast = reshape(shape = var_832, x = transpose_73);
            tensor<int32, [3]> var_834 = const()[name = tensor<string, []>("op_834"), val = tensor<int32, [3]>([16, -1, 64])];
            tensor<fp16, [1, 16, 77, 64]> transpose_75 = transpose(perm = var_814_perm_0, x = var_813_cast);
            tensor<fp16, [16, 77, 64]> key_states_35_cast = reshape(shape = var_834, x = transpose_75);
            tensor<int32, [3]> var_836 = const()[name = tensor<string, []>("op_836"), val = tensor<int32, [3]>([16, -1, 64])];
            tensor<fp16, [1, 16, 77, 64]> transpose_74 = transpose(perm = var_821_perm_0, x = var_820_cast);
            tensor<fp16, [16, 77, 64]> value_states_35_cast = reshape(shape = var_836, x = transpose_74);
            tensor<int32, [3]> var_839_perm_0 = const()[name = tensor<string, []>("op_839_perm_0"), val = tensor<int32, [3]>([0, 2, 1])];
            tensor<bool, []> attn_weights_49_transpose_x_0 = const()[name = tensor<string, []>("attn_weights_49_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> attn_weights_49_transpose_y_0 = const()[name = tensor<string, []>("attn_weights_49_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [16, 64, 77]> transpose_72 = transpose(perm = var_839_perm_0, x = key_states_35_cast);
            tensor<fp16, [16, 77, 77]> attn_weights_49_cast = matmul(transpose_x = attn_weights_49_transpose_x_0, transpose_y = attn_weights_49_transpose_y_0, x = query_states_17_cast, y = transpose_72);
            tensor<int32, [4]> var_841 = const()[name = tensor<string, []>("op_841"), val = tensor<int32, [4]>([1, 16, 77, 77])];
            tensor<fp16, [1, 16, 77, 77]> var_842_cast = reshape(shape = var_841, x = attn_weights_49_cast);
            tensor<fp16, [1, 16, 77, 77]> attn_weights_51_cast = add(x = var_842_cast, y = var_44_cast);
            tensor<int32, [3]> var_847 = const()[name = tensor<string, []>("op_847"), val = tensor<int32, [3]>([16, 77, 77])];
            tensor<fp16, [16, 77, 77]> input_133_cast = reshape(shape = var_847, x = attn_weights_51_cast);
            tensor<fp16, [16, 77, 77]> input_135_cast = softmax(axis = var_5, x = input_133_cast);
            tensor<bool, []> attn_output_49_transpose_x_0 = const()[name = tensor<string, []>("attn_output_49_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> attn_output_49_transpose_y_0 = const()[name = tensor<string, []>("attn_output_49_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [16, 77, 64]> attn_output_49_cast = matmul(transpose_x = attn_output_49_transpose_x_0, transpose_y = attn_output_49_transpose_y_0, x = input_135_cast, y = value_states_35_cast);
            tensor<int32, [4]> var_852 = const()[name = tensor<string, []>("op_852"), val = tensor<int32, [4]>([1, 16, 77, 64])];
            tensor<fp16, [1, 16, 77, 64]> attn_output_51_cast = reshape(shape = var_852, x = attn_output_49_cast);
            tensor<int32, [4]> attn_output_53_perm_0 = const()[name = tensor<string, []>("attn_output_53_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<int32, [3]> var_855 = const()[name = tensor<string, []>("op_855"), val = tensor<int32, [3]>([1, 77, 1024])];
            tensor<fp16, [1, 77, 16, 64]> transpose_71 = transpose(perm = attn_output_53_perm_0, x = attn_output_51_cast);
            tensor<fp16, [1, 77, 1024]> input_137_cast = reshape(shape = var_855, x = transpose_71);
            tensor<fp16, [1024, 1024]> text_encoder_text_model_encoder_layers_8_self_attn_out_proj_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_8_self_attn_out_proj_weight_to_fp16"), val = tensor<fp16, [1024, 1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(309207424)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_8_self_attn_out_proj_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_8_self_attn_out_proj_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(311304640)))];
            tensor<fp16, [1, 77, 1024]> hidden_states_51_cast = linear(bias = text_encoder_text_model_encoder_layers_8_self_attn_out_proj_bias_to_fp16, weight = text_encoder_text_model_encoder_layers_8_self_attn_out_proj_weight_to_fp16, x = input_137_cast);
            tensor<fp16, [1, 77, 1024]> input_139_cast = add(x = input_131_cast, y = hidden_states_51_cast);
            tensor<int32, [1]> input_141_axes_0 = const()[name = tensor<string, []>("input_141_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_8_layer_norm2_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_8_layer_norm2_weight_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(311306752)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_8_layer_norm2_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_8_layer_norm2_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(311308864)))];
            tensor<fp16, [1, 77, 1024]> input_141_cast = layer_norm(axes = input_141_axes_0, beta = text_encoder_text_model_encoder_layers_8_layer_norm2_bias_to_fp16, epsilon = var_12_to_fp16, gamma = text_encoder_text_model_encoder_layers_8_layer_norm2_weight_to_fp16, x = input_139_cast);
            tensor<fp16, [4096, 1024]> text_encoder_text_model_encoder_layers_8_mlp_fc1_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_8_mlp_fc1_weight_to_fp16"), val = tensor<fp16, [4096, 1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(311310976)))];
            tensor<fp16, [4096]> text_encoder_text_model_encoder_layers_8_mlp_fc1_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_8_mlp_fc1_bias_to_fp16"), val = tensor<fp16, [4096]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(319699648)))];
            tensor<fp16, [1, 77, 4096]> input_143_cast = linear(bias = text_encoder_text_model_encoder_layers_8_mlp_fc1_bias_to_fp16, weight = text_encoder_text_model_encoder_layers_8_mlp_fc1_weight_to_fp16, x = input_141_cast);
            tensor<string, []> input_145_mode_0 = const()[name = tensor<string, []>("input_145_mode_0"), val = tensor<string, []>("EXACT")];
            tensor<fp16, [1, 77, 4096]> input_145_cast = gelu(mode = input_145_mode_0, x = input_143_cast);
            tensor<fp16, [1024, 4096]> text_encoder_text_model_encoder_layers_8_mlp_fc2_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_8_mlp_fc2_weight_to_fp16"), val = tensor<fp16, [1024, 4096]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(319707904)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_8_mlp_fc2_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_8_mlp_fc2_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(328096576)))];
            tensor<fp16, [1, 77, 1024]> hidden_states_53_cast = linear(bias = text_encoder_text_model_encoder_layers_8_mlp_fc2_bias_to_fp16, weight = text_encoder_text_model_encoder_layers_8_mlp_fc2_weight_to_fp16, x = input_145_cast);
            tensor<fp16, [1, 77, 1024]> input_147_cast = add(x = input_139_cast, y = hidden_states_53_cast);
            tensor<int32, [1]> hidden_states_55_axes_0 = const()[name = tensor<string, []>("hidden_states_55_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_9_layer_norm1_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_9_layer_norm1_weight_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(328098688)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_9_layer_norm1_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_9_layer_norm1_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(328100800)))];
            tensor<fp16, [1, 77, 1024]> hidden_states_55_cast = layer_norm(axes = hidden_states_55_axes_0, beta = text_encoder_text_model_encoder_layers_9_layer_norm1_bias_to_fp16, epsilon = var_12_to_fp16, gamma = text_encoder_text_model_encoder_layers_9_layer_norm1_weight_to_fp16, x = input_147_cast);
            tensor<fp16, [1024, 1024]> text_encoder_text_model_encoder_layers_9_self_attn_q_proj_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_9_self_attn_q_proj_weight_to_fp16"), val = tensor<fp16, [1024, 1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(328102912)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_9_self_attn_q_proj_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_9_self_attn_q_proj_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(330200128)))];
            tensor<fp16, [1, 77, 1024]> var_893_cast = linear(bias = text_encoder_text_model_encoder_layers_9_self_attn_q_proj_bias_to_fp16, weight = text_encoder_text_model_encoder_layers_9_self_attn_q_proj_weight_to_fp16, x = hidden_states_55_cast);
            tensor<fp16, []> var_894_to_fp16 = const()[name = tensor<string, []>("op_894_to_fp16"), val = tensor<fp16, []>(0x1p-3)];
            tensor<fp16, [1, 77, 1024]> tensor_59_cast = mul(x = var_893_cast, y = var_894_to_fp16);
            tensor<fp16, [1024, 1024]> text_encoder_text_model_encoder_layers_9_self_attn_k_proj_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_9_self_attn_k_proj_weight_to_fp16"), val = tensor<fp16, [1024, 1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(330202240)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_9_self_attn_k_proj_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_9_self_attn_k_proj_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(332299456)))];
            tensor<fp16, [1, 77, 1024]> tensor_55_cast = linear(bias = text_encoder_text_model_encoder_layers_9_self_attn_k_proj_bias_to_fp16, weight = text_encoder_text_model_encoder_layers_9_self_attn_k_proj_weight_to_fp16, x = hidden_states_55_cast);
            tensor<int32, [4]> var_899 = const()[name = tensor<string, []>("op_899"), val = tensor<int32, [4]>([1, -1, 16, 64])];
            tensor<fp16, [1, 77, 16, 64]> var_900_cast = reshape(shape = var_899, x = tensor_55_cast);
            tensor<int32, [4]> var_901_perm_0 = const()[name = tensor<string, []>("op_901_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<fp16, [1024, 1024]> text_encoder_text_model_encoder_layers_9_self_attn_v_proj_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_9_self_attn_v_proj_weight_to_fp16"), val = tensor<fp16, [1024, 1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(332301568)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_9_self_attn_v_proj_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_9_self_attn_v_proj_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(334398784)))];
            tensor<fp16, [1, 77, 1024]> tensor_57_cast = linear(bias = text_encoder_text_model_encoder_layers_9_self_attn_v_proj_bias_to_fp16, weight = text_encoder_text_model_encoder_layers_9_self_attn_v_proj_weight_to_fp16, x = hidden_states_55_cast);
            tensor<int32, [4]> var_906 = const()[name = tensor<string, []>("op_906"), val = tensor<int32, [4]>([1, -1, 16, 64])];
            tensor<fp16, [1, 77, 16, 64]> var_907_cast = reshape(shape = var_906, x = tensor_57_cast);
            tensor<int32, [4]> var_908_perm_0 = const()[name = tensor<string, []>("op_908_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<int32, [4]> var_915 = const()[name = tensor<string, []>("op_915"), val = tensor<int32, [4]>([1, 77, 16, 64])];
            tensor<fp16, [1, 77, 16, 64]> var_916_cast = reshape(shape = var_915, x = tensor_59_cast);
            tensor<int32, [4]> var_917_perm_0 = const()[name = tensor<string, []>("op_917_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<int32, [3]> var_919 = const()[name = tensor<string, []>("op_919"), val = tensor<int32, [3]>([16, -1, 64])];
            tensor<fp16, [1, 16, 77, 64]> transpose_68 = transpose(perm = var_917_perm_0, x = var_916_cast);
            tensor<fp16, [16, 77, 64]> query_states_19_cast = reshape(shape = var_919, x = transpose_68);
            tensor<int32, [3]> var_921 = const()[name = tensor<string, []>("op_921"), val = tensor<int32, [3]>([16, -1, 64])];
            tensor<fp16, [1, 16, 77, 64]> transpose_70 = transpose(perm = var_901_perm_0, x = var_900_cast);
            tensor<fp16, [16, 77, 64]> key_states_39_cast = reshape(shape = var_921, x = transpose_70);
            tensor<int32, [3]> var_923 = const()[name = tensor<string, []>("op_923"), val = tensor<int32, [3]>([16, -1, 64])];
            tensor<fp16, [1, 16, 77, 64]> transpose_69 = transpose(perm = var_908_perm_0, x = var_907_cast);
            tensor<fp16, [16, 77, 64]> value_states_39_cast = reshape(shape = var_923, x = transpose_69);
            tensor<int32, [3]> var_926_perm_0 = const()[name = tensor<string, []>("op_926_perm_0"), val = tensor<int32, [3]>([0, 2, 1])];
            tensor<bool, []> attn_weights_55_transpose_x_0 = const()[name = tensor<string, []>("attn_weights_55_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> attn_weights_55_transpose_y_0 = const()[name = tensor<string, []>("attn_weights_55_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [16, 64, 77]> transpose_67 = transpose(perm = var_926_perm_0, x = key_states_39_cast);
            tensor<fp16, [16, 77, 77]> attn_weights_55_cast = matmul(transpose_x = attn_weights_55_transpose_x_0, transpose_y = attn_weights_55_transpose_y_0, x = query_states_19_cast, y = transpose_67);
            tensor<int32, [4]> var_928 = const()[name = tensor<string, []>("op_928"), val = tensor<int32, [4]>([1, 16, 77, 77])];
            tensor<fp16, [1, 16, 77, 77]> var_929_cast = reshape(shape = var_928, x = attn_weights_55_cast);
            tensor<fp16, [1, 16, 77, 77]> attn_weights_57_cast = add(x = var_929_cast, y = var_44_cast);
            tensor<int32, [3]> var_934 = const()[name = tensor<string, []>("op_934"), val = tensor<int32, [3]>([16, 77, 77])];
            tensor<fp16, [16, 77, 77]> input_149_cast = reshape(shape = var_934, x = attn_weights_57_cast);
            tensor<fp16, [16, 77, 77]> input_151_cast = softmax(axis = var_5, x = input_149_cast);
            tensor<bool, []> attn_output_55_transpose_x_0 = const()[name = tensor<string, []>("attn_output_55_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> attn_output_55_transpose_y_0 = const()[name = tensor<string, []>("attn_output_55_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [16, 77, 64]> attn_output_55_cast = matmul(transpose_x = attn_output_55_transpose_x_0, transpose_y = attn_output_55_transpose_y_0, x = input_151_cast, y = value_states_39_cast);
            tensor<int32, [4]> var_939 = const()[name = tensor<string, []>("op_939"), val = tensor<int32, [4]>([1, 16, 77, 64])];
            tensor<fp16, [1, 16, 77, 64]> attn_output_57_cast = reshape(shape = var_939, x = attn_output_55_cast);
            tensor<int32, [4]> attn_output_59_perm_0 = const()[name = tensor<string, []>("attn_output_59_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<int32, [3]> var_942 = const()[name = tensor<string, []>("op_942"), val = tensor<int32, [3]>([1, 77, 1024])];
            tensor<fp16, [1, 77, 16, 64]> transpose_66 = transpose(perm = attn_output_59_perm_0, x = attn_output_57_cast);
            tensor<fp16, [1, 77, 1024]> input_153_cast = reshape(shape = var_942, x = transpose_66);
            tensor<fp16, [1024, 1024]> text_encoder_text_model_encoder_layers_9_self_attn_out_proj_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_9_self_attn_out_proj_weight_to_fp16"), val = tensor<fp16, [1024, 1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(334400896)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_9_self_attn_out_proj_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_9_self_attn_out_proj_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(336498112)))];
            tensor<fp16, [1, 77, 1024]> hidden_states_57_cast = linear(bias = text_encoder_text_model_encoder_layers_9_self_attn_out_proj_bias_to_fp16, weight = text_encoder_text_model_encoder_layers_9_self_attn_out_proj_weight_to_fp16, x = input_153_cast);
            tensor<fp16, [1, 77, 1024]> input_155_cast = add(x = input_147_cast, y = hidden_states_57_cast);
            tensor<int32, [1]> input_157_axes_0 = const()[name = tensor<string, []>("input_157_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_9_layer_norm2_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_9_layer_norm2_weight_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(336500224)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_9_layer_norm2_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_9_layer_norm2_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(336502336)))];
            tensor<fp16, [1, 77, 1024]> input_157_cast = layer_norm(axes = input_157_axes_0, beta = text_encoder_text_model_encoder_layers_9_layer_norm2_bias_to_fp16, epsilon = var_12_to_fp16, gamma = text_encoder_text_model_encoder_layers_9_layer_norm2_weight_to_fp16, x = input_155_cast);
            tensor<fp16, [4096, 1024]> text_encoder_text_model_encoder_layers_9_mlp_fc1_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_9_mlp_fc1_weight_to_fp16"), val = tensor<fp16, [4096, 1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(336504448)))];
            tensor<fp16, [4096]> text_encoder_text_model_encoder_layers_9_mlp_fc1_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_9_mlp_fc1_bias_to_fp16"), val = tensor<fp16, [4096]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(344893120)))];
            tensor<fp16, [1, 77, 4096]> input_159_cast = linear(bias = text_encoder_text_model_encoder_layers_9_mlp_fc1_bias_to_fp16, weight = text_encoder_text_model_encoder_layers_9_mlp_fc1_weight_to_fp16, x = input_157_cast);
            tensor<string, []> input_161_mode_0 = const()[name = tensor<string, []>("input_161_mode_0"), val = tensor<string, []>("EXACT")];
            tensor<fp16, [1, 77, 4096]> input_161_cast = gelu(mode = input_161_mode_0, x = input_159_cast);
            tensor<fp16, [1024, 4096]> text_encoder_text_model_encoder_layers_9_mlp_fc2_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_9_mlp_fc2_weight_to_fp16"), val = tensor<fp16, [1024, 4096]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(344901376)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_9_mlp_fc2_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_9_mlp_fc2_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(353290048)))];
            tensor<fp16, [1, 77, 1024]> hidden_states_59_cast = linear(bias = text_encoder_text_model_encoder_layers_9_mlp_fc2_bias_to_fp16, weight = text_encoder_text_model_encoder_layers_9_mlp_fc2_weight_to_fp16, x = input_161_cast);
            tensor<fp16, [1, 77, 1024]> input_163_cast = add(x = input_155_cast, y = hidden_states_59_cast);
            tensor<int32, [1]> hidden_states_61_axes_0 = const()[name = tensor<string, []>("hidden_states_61_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_10_layer_norm1_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_10_layer_norm1_weight_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(353292160)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_10_layer_norm1_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_10_layer_norm1_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(353294272)))];
            tensor<fp16, [1, 77, 1024]> hidden_states_61_cast = layer_norm(axes = hidden_states_61_axes_0, beta = text_encoder_text_model_encoder_layers_10_layer_norm1_bias_to_fp16, epsilon = var_12_to_fp16, gamma = text_encoder_text_model_encoder_layers_10_layer_norm1_weight_to_fp16, x = input_163_cast);
            tensor<fp16, [1024, 1024]> text_encoder_text_model_encoder_layers_10_self_attn_q_proj_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_10_self_attn_q_proj_weight_to_fp16"), val = tensor<fp16, [1024, 1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(353296384)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_10_self_attn_q_proj_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_10_self_attn_q_proj_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(355393600)))];
            tensor<fp16, [1, 77, 1024]> var_980_cast = linear(bias = text_encoder_text_model_encoder_layers_10_self_attn_q_proj_bias_to_fp16, weight = text_encoder_text_model_encoder_layers_10_self_attn_q_proj_weight_to_fp16, x = hidden_states_61_cast);
            tensor<fp16, []> var_981_to_fp16 = const()[name = tensor<string, []>("op_981_to_fp16"), val = tensor<fp16, []>(0x1p-3)];
            tensor<fp16, [1, 77, 1024]> tensor_65_cast = mul(x = var_980_cast, y = var_981_to_fp16);
            tensor<fp16, [1024, 1024]> text_encoder_text_model_encoder_layers_10_self_attn_k_proj_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_10_self_attn_k_proj_weight_to_fp16"), val = tensor<fp16, [1024, 1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(355395712)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_10_self_attn_k_proj_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_10_self_attn_k_proj_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(357492928)))];
            tensor<fp16, [1, 77, 1024]> tensor_61_cast = linear(bias = text_encoder_text_model_encoder_layers_10_self_attn_k_proj_bias_to_fp16, weight = text_encoder_text_model_encoder_layers_10_self_attn_k_proj_weight_to_fp16, x = hidden_states_61_cast);
            tensor<int32, [4]> var_986 = const()[name = tensor<string, []>("op_986"), val = tensor<int32, [4]>([1, -1, 16, 64])];
            tensor<fp16, [1, 77, 16, 64]> var_987_cast = reshape(shape = var_986, x = tensor_61_cast);
            tensor<int32, [4]> var_988_perm_0 = const()[name = tensor<string, []>("op_988_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<fp16, [1024, 1024]> text_encoder_text_model_encoder_layers_10_self_attn_v_proj_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_10_self_attn_v_proj_weight_to_fp16"), val = tensor<fp16, [1024, 1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(357495040)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_10_self_attn_v_proj_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_10_self_attn_v_proj_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(359592256)))];
            tensor<fp16, [1, 77, 1024]> tensor_63_cast = linear(bias = text_encoder_text_model_encoder_layers_10_self_attn_v_proj_bias_to_fp16, weight = text_encoder_text_model_encoder_layers_10_self_attn_v_proj_weight_to_fp16, x = hidden_states_61_cast);
            tensor<int32, [4]> var_993 = const()[name = tensor<string, []>("op_993"), val = tensor<int32, [4]>([1, -1, 16, 64])];
            tensor<fp16, [1, 77, 16, 64]> var_994_cast = reshape(shape = var_993, x = tensor_63_cast);
            tensor<int32, [4]> var_995_perm_0 = const()[name = tensor<string, []>("op_995_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<int32, [4]> var_1002 = const()[name = tensor<string, []>("op_1002"), val = tensor<int32, [4]>([1, 77, 16, 64])];
            tensor<fp16, [1, 77, 16, 64]> var_1003_cast = reshape(shape = var_1002, x = tensor_65_cast);
            tensor<int32, [4]> var_1004_perm_0 = const()[name = tensor<string, []>("op_1004_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<int32, [3]> var_1006 = const()[name = tensor<string, []>("op_1006"), val = tensor<int32, [3]>([16, -1, 64])];
            tensor<fp16, [1, 16, 77, 64]> transpose_63 = transpose(perm = var_1004_perm_0, x = var_1003_cast);
            tensor<fp16, [16, 77, 64]> query_states_21_cast = reshape(shape = var_1006, x = transpose_63);
            tensor<int32, [3]> var_1008 = const()[name = tensor<string, []>("op_1008"), val = tensor<int32, [3]>([16, -1, 64])];
            tensor<fp16, [1, 16, 77, 64]> transpose_65 = transpose(perm = var_988_perm_0, x = var_987_cast);
            tensor<fp16, [16, 77, 64]> key_states_43_cast = reshape(shape = var_1008, x = transpose_65);
            tensor<int32, [3]> var_1010 = const()[name = tensor<string, []>("op_1010"), val = tensor<int32, [3]>([16, -1, 64])];
            tensor<fp16, [1, 16, 77, 64]> transpose_64 = transpose(perm = var_995_perm_0, x = var_994_cast);
            tensor<fp16, [16, 77, 64]> value_states_43_cast = reshape(shape = var_1010, x = transpose_64);
            tensor<int32, [3]> var_1013_perm_0 = const()[name = tensor<string, []>("op_1013_perm_0"), val = tensor<int32, [3]>([0, 2, 1])];
            tensor<bool, []> attn_weights_61_transpose_x_0 = const()[name = tensor<string, []>("attn_weights_61_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> attn_weights_61_transpose_y_0 = const()[name = tensor<string, []>("attn_weights_61_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [16, 64, 77]> transpose_62 = transpose(perm = var_1013_perm_0, x = key_states_43_cast);
            tensor<fp16, [16, 77, 77]> attn_weights_61_cast = matmul(transpose_x = attn_weights_61_transpose_x_0, transpose_y = attn_weights_61_transpose_y_0, x = query_states_21_cast, y = transpose_62);
            tensor<int32, [4]> var_1015 = const()[name = tensor<string, []>("op_1015"), val = tensor<int32, [4]>([1, 16, 77, 77])];
            tensor<fp16, [1, 16, 77, 77]> var_1016_cast = reshape(shape = var_1015, x = attn_weights_61_cast);
            tensor<fp16, [1, 16, 77, 77]> attn_weights_63_cast = add(x = var_1016_cast, y = var_44_cast);
            tensor<int32, [3]> var_1021 = const()[name = tensor<string, []>("op_1021"), val = tensor<int32, [3]>([16, 77, 77])];
            tensor<fp16, [16, 77, 77]> input_165_cast = reshape(shape = var_1021, x = attn_weights_63_cast);
            tensor<fp16, [16, 77, 77]> input_167_cast = softmax(axis = var_5, x = input_165_cast);
            tensor<bool, []> attn_output_61_transpose_x_0 = const()[name = tensor<string, []>("attn_output_61_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> attn_output_61_transpose_y_0 = const()[name = tensor<string, []>("attn_output_61_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [16, 77, 64]> attn_output_61_cast = matmul(transpose_x = attn_output_61_transpose_x_0, transpose_y = attn_output_61_transpose_y_0, x = input_167_cast, y = value_states_43_cast);
            tensor<int32, [4]> var_1026 = const()[name = tensor<string, []>("op_1026"), val = tensor<int32, [4]>([1, 16, 77, 64])];
            tensor<fp16, [1, 16, 77, 64]> attn_output_63_cast = reshape(shape = var_1026, x = attn_output_61_cast);
            tensor<int32, [4]> attn_output_65_perm_0 = const()[name = tensor<string, []>("attn_output_65_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<int32, [3]> var_1029 = const()[name = tensor<string, []>("op_1029"), val = tensor<int32, [3]>([1, 77, 1024])];
            tensor<fp16, [1, 77, 16, 64]> transpose_61 = transpose(perm = attn_output_65_perm_0, x = attn_output_63_cast);
            tensor<fp16, [1, 77, 1024]> input_169_cast = reshape(shape = var_1029, x = transpose_61);
            tensor<fp16, [1024, 1024]> text_encoder_text_model_encoder_layers_10_self_attn_out_proj_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_10_self_attn_out_proj_weight_to_fp16"), val = tensor<fp16, [1024, 1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(359594368)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_10_self_attn_out_proj_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_10_self_attn_out_proj_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(361691584)))];
            tensor<fp16, [1, 77, 1024]> hidden_states_63_cast = linear(bias = text_encoder_text_model_encoder_layers_10_self_attn_out_proj_bias_to_fp16, weight = text_encoder_text_model_encoder_layers_10_self_attn_out_proj_weight_to_fp16, x = input_169_cast);
            tensor<fp16, [1, 77, 1024]> input_171_cast = add(x = input_163_cast, y = hidden_states_63_cast);
            tensor<int32, [1]> input_173_axes_0 = const()[name = tensor<string, []>("input_173_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_10_layer_norm2_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_10_layer_norm2_weight_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(361693696)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_10_layer_norm2_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_10_layer_norm2_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(361695808)))];
            tensor<fp16, [1, 77, 1024]> input_173_cast = layer_norm(axes = input_173_axes_0, beta = text_encoder_text_model_encoder_layers_10_layer_norm2_bias_to_fp16, epsilon = var_12_to_fp16, gamma = text_encoder_text_model_encoder_layers_10_layer_norm2_weight_to_fp16, x = input_171_cast);
            tensor<fp16, [4096, 1024]> text_encoder_text_model_encoder_layers_10_mlp_fc1_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_10_mlp_fc1_weight_to_fp16"), val = tensor<fp16, [4096, 1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(361697920)))];
            tensor<fp16, [4096]> text_encoder_text_model_encoder_layers_10_mlp_fc1_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_10_mlp_fc1_bias_to_fp16"), val = tensor<fp16, [4096]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(370086592)))];
            tensor<fp16, [1, 77, 4096]> input_175_cast = linear(bias = text_encoder_text_model_encoder_layers_10_mlp_fc1_bias_to_fp16, weight = text_encoder_text_model_encoder_layers_10_mlp_fc1_weight_to_fp16, x = input_173_cast);
            tensor<string, []> input_177_mode_0 = const()[name = tensor<string, []>("input_177_mode_0"), val = tensor<string, []>("EXACT")];
            tensor<fp16, [1, 77, 4096]> input_177_cast = gelu(mode = input_177_mode_0, x = input_175_cast);
            tensor<fp16, [1024, 4096]> text_encoder_text_model_encoder_layers_10_mlp_fc2_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_10_mlp_fc2_weight_to_fp16"), val = tensor<fp16, [1024, 4096]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(370094848)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_10_mlp_fc2_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_10_mlp_fc2_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(378483520)))];
            tensor<fp16, [1, 77, 1024]> hidden_states_65_cast = linear(bias = text_encoder_text_model_encoder_layers_10_mlp_fc2_bias_to_fp16, weight = text_encoder_text_model_encoder_layers_10_mlp_fc2_weight_to_fp16, x = input_177_cast);
            tensor<fp16, [1, 77, 1024]> input_179_cast = add(x = input_171_cast, y = hidden_states_65_cast);
            tensor<int32, [1]> hidden_states_67_axes_0 = const()[name = tensor<string, []>("hidden_states_67_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_11_layer_norm1_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_11_layer_norm1_weight_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(378485632)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_11_layer_norm1_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_11_layer_norm1_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(378487744)))];
            tensor<fp16, [1, 77, 1024]> hidden_states_67_cast = layer_norm(axes = hidden_states_67_axes_0, beta = text_encoder_text_model_encoder_layers_11_layer_norm1_bias_to_fp16, epsilon = var_12_to_fp16, gamma = text_encoder_text_model_encoder_layers_11_layer_norm1_weight_to_fp16, x = input_179_cast);
            tensor<fp16, [1024, 1024]> text_encoder_text_model_encoder_layers_11_self_attn_q_proj_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_11_self_attn_q_proj_weight_to_fp16"), val = tensor<fp16, [1024, 1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(378489856)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_11_self_attn_q_proj_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_11_self_attn_q_proj_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(380587072)))];
            tensor<fp16, [1, 77, 1024]> var_1067_cast = linear(bias = text_encoder_text_model_encoder_layers_11_self_attn_q_proj_bias_to_fp16, weight = text_encoder_text_model_encoder_layers_11_self_attn_q_proj_weight_to_fp16, x = hidden_states_67_cast);
            tensor<fp16, []> var_1068_to_fp16 = const()[name = tensor<string, []>("op_1068_to_fp16"), val = tensor<fp16, []>(0x1p-3)];
            tensor<fp16, [1, 77, 1024]> tensor_71_cast = mul(x = var_1067_cast, y = var_1068_to_fp16);
            tensor<fp16, [1024, 1024]> text_encoder_text_model_encoder_layers_11_self_attn_k_proj_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_11_self_attn_k_proj_weight_to_fp16"), val = tensor<fp16, [1024, 1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(380589184)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_11_self_attn_k_proj_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_11_self_attn_k_proj_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(382686400)))];
            tensor<fp16, [1, 77, 1024]> tensor_67_cast = linear(bias = text_encoder_text_model_encoder_layers_11_self_attn_k_proj_bias_to_fp16, weight = text_encoder_text_model_encoder_layers_11_self_attn_k_proj_weight_to_fp16, x = hidden_states_67_cast);
            tensor<int32, [4]> var_1073 = const()[name = tensor<string, []>("op_1073"), val = tensor<int32, [4]>([1, -1, 16, 64])];
            tensor<fp16, [1, 77, 16, 64]> var_1074_cast = reshape(shape = var_1073, x = tensor_67_cast);
            tensor<int32, [4]> var_1075_perm_0 = const()[name = tensor<string, []>("op_1075_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<fp16, [1024, 1024]> text_encoder_text_model_encoder_layers_11_self_attn_v_proj_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_11_self_attn_v_proj_weight_to_fp16"), val = tensor<fp16, [1024, 1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(382688512)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_11_self_attn_v_proj_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_11_self_attn_v_proj_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(384785728)))];
            tensor<fp16, [1, 77, 1024]> tensor_69_cast = linear(bias = text_encoder_text_model_encoder_layers_11_self_attn_v_proj_bias_to_fp16, weight = text_encoder_text_model_encoder_layers_11_self_attn_v_proj_weight_to_fp16, x = hidden_states_67_cast);
            tensor<int32, [4]> var_1080 = const()[name = tensor<string, []>("op_1080"), val = tensor<int32, [4]>([1, -1, 16, 64])];
            tensor<fp16, [1, 77, 16, 64]> var_1081_cast = reshape(shape = var_1080, x = tensor_69_cast);
            tensor<int32, [4]> var_1082_perm_0 = const()[name = tensor<string, []>("op_1082_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<int32, [4]> var_1089 = const()[name = tensor<string, []>("op_1089"), val = tensor<int32, [4]>([1, 77, 16, 64])];
            tensor<fp16, [1, 77, 16, 64]> var_1090_cast = reshape(shape = var_1089, x = tensor_71_cast);
            tensor<int32, [4]> var_1091_perm_0 = const()[name = tensor<string, []>("op_1091_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<int32, [3]> var_1093 = const()[name = tensor<string, []>("op_1093"), val = tensor<int32, [3]>([16, -1, 64])];
            tensor<fp16, [1, 16, 77, 64]> transpose_58 = transpose(perm = var_1091_perm_0, x = var_1090_cast);
            tensor<fp16, [16, 77, 64]> query_states_23_cast = reshape(shape = var_1093, x = transpose_58);
            tensor<int32, [3]> var_1095 = const()[name = tensor<string, []>("op_1095"), val = tensor<int32, [3]>([16, -1, 64])];
            tensor<fp16, [1, 16, 77, 64]> transpose_60 = transpose(perm = var_1075_perm_0, x = var_1074_cast);
            tensor<fp16, [16, 77, 64]> key_states_47_cast = reshape(shape = var_1095, x = transpose_60);
            tensor<int32, [3]> var_1097 = const()[name = tensor<string, []>("op_1097"), val = tensor<int32, [3]>([16, -1, 64])];
            tensor<fp16, [1, 16, 77, 64]> transpose_59 = transpose(perm = var_1082_perm_0, x = var_1081_cast);
            tensor<fp16, [16, 77, 64]> value_states_47_cast = reshape(shape = var_1097, x = transpose_59);
            tensor<int32, [3]> var_1100_perm_0 = const()[name = tensor<string, []>("op_1100_perm_0"), val = tensor<int32, [3]>([0, 2, 1])];
            tensor<bool, []> attn_weights_67_transpose_x_0 = const()[name = tensor<string, []>("attn_weights_67_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> attn_weights_67_transpose_y_0 = const()[name = tensor<string, []>("attn_weights_67_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [16, 64, 77]> transpose_57 = transpose(perm = var_1100_perm_0, x = key_states_47_cast);
            tensor<fp16, [16, 77, 77]> attn_weights_67_cast = matmul(transpose_x = attn_weights_67_transpose_x_0, transpose_y = attn_weights_67_transpose_y_0, x = query_states_23_cast, y = transpose_57);
            tensor<int32, [4]> var_1102 = const()[name = tensor<string, []>("op_1102"), val = tensor<int32, [4]>([1, 16, 77, 77])];
            tensor<fp16, [1, 16, 77, 77]> var_1103_cast = reshape(shape = var_1102, x = attn_weights_67_cast);
            tensor<fp16, [1, 16, 77, 77]> attn_weights_69_cast = add(x = var_1103_cast, y = var_44_cast);
            tensor<int32, [3]> var_1108 = const()[name = tensor<string, []>("op_1108"), val = tensor<int32, [3]>([16, 77, 77])];
            tensor<fp16, [16, 77, 77]> input_181_cast = reshape(shape = var_1108, x = attn_weights_69_cast);
            tensor<fp16, [16, 77, 77]> input_183_cast = softmax(axis = var_5, x = input_181_cast);
            tensor<bool, []> attn_output_67_transpose_x_0 = const()[name = tensor<string, []>("attn_output_67_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> attn_output_67_transpose_y_0 = const()[name = tensor<string, []>("attn_output_67_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [16, 77, 64]> attn_output_67_cast = matmul(transpose_x = attn_output_67_transpose_x_0, transpose_y = attn_output_67_transpose_y_0, x = input_183_cast, y = value_states_47_cast);
            tensor<int32, [4]> var_1113 = const()[name = tensor<string, []>("op_1113"), val = tensor<int32, [4]>([1, 16, 77, 64])];
            tensor<fp16, [1, 16, 77, 64]> attn_output_69_cast = reshape(shape = var_1113, x = attn_output_67_cast);
            tensor<int32, [4]> attn_output_71_perm_0 = const()[name = tensor<string, []>("attn_output_71_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<int32, [3]> var_1116 = const()[name = tensor<string, []>("op_1116"), val = tensor<int32, [3]>([1, 77, 1024])];
            tensor<fp16, [1, 77, 16, 64]> transpose_56 = transpose(perm = attn_output_71_perm_0, x = attn_output_69_cast);
            tensor<fp16, [1, 77, 1024]> input_185_cast = reshape(shape = var_1116, x = transpose_56);
            tensor<fp16, [1024, 1024]> text_encoder_text_model_encoder_layers_11_self_attn_out_proj_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_11_self_attn_out_proj_weight_to_fp16"), val = tensor<fp16, [1024, 1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(384787840)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_11_self_attn_out_proj_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_11_self_attn_out_proj_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(386885056)))];
            tensor<fp16, [1, 77, 1024]> hidden_states_69_cast = linear(bias = text_encoder_text_model_encoder_layers_11_self_attn_out_proj_bias_to_fp16, weight = text_encoder_text_model_encoder_layers_11_self_attn_out_proj_weight_to_fp16, x = input_185_cast);
            tensor<fp16, [1, 77, 1024]> input_187_cast = add(x = input_179_cast, y = hidden_states_69_cast);
            tensor<int32, [1]> input_189_axes_0 = const()[name = tensor<string, []>("input_189_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_11_layer_norm2_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_11_layer_norm2_weight_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(386887168)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_11_layer_norm2_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_11_layer_norm2_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(386889280)))];
            tensor<fp16, [1, 77, 1024]> input_189_cast = layer_norm(axes = input_189_axes_0, beta = text_encoder_text_model_encoder_layers_11_layer_norm2_bias_to_fp16, epsilon = var_12_to_fp16, gamma = text_encoder_text_model_encoder_layers_11_layer_norm2_weight_to_fp16, x = input_187_cast);
            tensor<fp16, [4096, 1024]> text_encoder_text_model_encoder_layers_11_mlp_fc1_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_11_mlp_fc1_weight_to_fp16"), val = tensor<fp16, [4096, 1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(386891392)))];
            tensor<fp16, [4096]> text_encoder_text_model_encoder_layers_11_mlp_fc1_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_11_mlp_fc1_bias_to_fp16"), val = tensor<fp16, [4096]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(395280064)))];
            tensor<fp16, [1, 77, 4096]> input_191_cast = linear(bias = text_encoder_text_model_encoder_layers_11_mlp_fc1_bias_to_fp16, weight = text_encoder_text_model_encoder_layers_11_mlp_fc1_weight_to_fp16, x = input_189_cast);
            tensor<string, []> input_193_mode_0 = const()[name = tensor<string, []>("input_193_mode_0"), val = tensor<string, []>("EXACT")];
            tensor<fp16, [1, 77, 4096]> input_193_cast = gelu(mode = input_193_mode_0, x = input_191_cast);
            tensor<fp16, [1024, 4096]> text_encoder_text_model_encoder_layers_11_mlp_fc2_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_11_mlp_fc2_weight_to_fp16"), val = tensor<fp16, [1024, 4096]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(395288320)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_11_mlp_fc2_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_11_mlp_fc2_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(403676992)))];
            tensor<fp16, [1, 77, 1024]> hidden_states_71_cast = linear(bias = text_encoder_text_model_encoder_layers_11_mlp_fc2_bias_to_fp16, weight = text_encoder_text_model_encoder_layers_11_mlp_fc2_weight_to_fp16, x = input_193_cast);
            tensor<fp16, [1, 77, 1024]> input_195_cast = add(x = input_187_cast, y = hidden_states_71_cast);
            tensor<int32, [1]> hidden_states_73_axes_0 = const()[name = tensor<string, []>("hidden_states_73_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_12_layer_norm1_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_12_layer_norm1_weight_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(403679104)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_12_layer_norm1_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_12_layer_norm1_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(403681216)))];
            tensor<fp16, [1, 77, 1024]> hidden_states_73_cast = layer_norm(axes = hidden_states_73_axes_0, beta = text_encoder_text_model_encoder_layers_12_layer_norm1_bias_to_fp16, epsilon = var_12_to_fp16, gamma = text_encoder_text_model_encoder_layers_12_layer_norm1_weight_to_fp16, x = input_195_cast);
            tensor<fp16, [1024, 1024]> text_encoder_text_model_encoder_layers_12_self_attn_q_proj_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_12_self_attn_q_proj_weight_to_fp16"), val = tensor<fp16, [1024, 1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(403683328)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_12_self_attn_q_proj_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_12_self_attn_q_proj_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(405780544)))];
            tensor<fp16, [1, 77, 1024]> var_1154_cast = linear(bias = text_encoder_text_model_encoder_layers_12_self_attn_q_proj_bias_to_fp16, weight = text_encoder_text_model_encoder_layers_12_self_attn_q_proj_weight_to_fp16, x = hidden_states_73_cast);
            tensor<fp16, []> var_1155_to_fp16 = const()[name = tensor<string, []>("op_1155_to_fp16"), val = tensor<fp16, []>(0x1p-3)];
            tensor<fp16, [1, 77, 1024]> tensor_77_cast = mul(x = var_1154_cast, y = var_1155_to_fp16);
            tensor<fp16, [1024, 1024]> text_encoder_text_model_encoder_layers_12_self_attn_k_proj_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_12_self_attn_k_proj_weight_to_fp16"), val = tensor<fp16, [1024, 1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(405782656)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_12_self_attn_k_proj_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_12_self_attn_k_proj_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(407879872)))];
            tensor<fp16, [1, 77, 1024]> tensor_73_cast = linear(bias = text_encoder_text_model_encoder_layers_12_self_attn_k_proj_bias_to_fp16, weight = text_encoder_text_model_encoder_layers_12_self_attn_k_proj_weight_to_fp16, x = hidden_states_73_cast);
            tensor<int32, [4]> var_1160 = const()[name = tensor<string, []>("op_1160"), val = tensor<int32, [4]>([1, -1, 16, 64])];
            tensor<fp16, [1, 77, 16, 64]> var_1161_cast = reshape(shape = var_1160, x = tensor_73_cast);
            tensor<int32, [4]> var_1162_perm_0 = const()[name = tensor<string, []>("op_1162_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<fp16, [1024, 1024]> text_encoder_text_model_encoder_layers_12_self_attn_v_proj_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_12_self_attn_v_proj_weight_to_fp16"), val = tensor<fp16, [1024, 1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(407881984)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_12_self_attn_v_proj_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_12_self_attn_v_proj_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(409979200)))];
            tensor<fp16, [1, 77, 1024]> tensor_75_cast = linear(bias = text_encoder_text_model_encoder_layers_12_self_attn_v_proj_bias_to_fp16, weight = text_encoder_text_model_encoder_layers_12_self_attn_v_proj_weight_to_fp16, x = hidden_states_73_cast);
            tensor<int32, [4]> var_1167 = const()[name = tensor<string, []>("op_1167"), val = tensor<int32, [4]>([1, -1, 16, 64])];
            tensor<fp16, [1, 77, 16, 64]> var_1168_cast = reshape(shape = var_1167, x = tensor_75_cast);
            tensor<int32, [4]> var_1169_perm_0 = const()[name = tensor<string, []>("op_1169_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<int32, [4]> var_1176 = const()[name = tensor<string, []>("op_1176"), val = tensor<int32, [4]>([1, 77, 16, 64])];
            tensor<fp16, [1, 77, 16, 64]> var_1177_cast = reshape(shape = var_1176, x = tensor_77_cast);
            tensor<int32, [4]> var_1178_perm_0 = const()[name = tensor<string, []>("op_1178_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<int32, [3]> var_1180 = const()[name = tensor<string, []>("op_1180"), val = tensor<int32, [3]>([16, -1, 64])];
            tensor<fp16, [1, 16, 77, 64]> transpose_53 = transpose(perm = var_1178_perm_0, x = var_1177_cast);
            tensor<fp16, [16, 77, 64]> query_states_25_cast = reshape(shape = var_1180, x = transpose_53);
            tensor<int32, [3]> var_1182 = const()[name = tensor<string, []>("op_1182"), val = tensor<int32, [3]>([16, -1, 64])];
            tensor<fp16, [1, 16, 77, 64]> transpose_55 = transpose(perm = var_1162_perm_0, x = var_1161_cast);
            tensor<fp16, [16, 77, 64]> key_states_51_cast = reshape(shape = var_1182, x = transpose_55);
            tensor<int32, [3]> var_1184 = const()[name = tensor<string, []>("op_1184"), val = tensor<int32, [3]>([16, -1, 64])];
            tensor<fp16, [1, 16, 77, 64]> transpose_54 = transpose(perm = var_1169_perm_0, x = var_1168_cast);
            tensor<fp16, [16, 77, 64]> value_states_51_cast = reshape(shape = var_1184, x = transpose_54);
            tensor<int32, [3]> var_1187_perm_0 = const()[name = tensor<string, []>("op_1187_perm_0"), val = tensor<int32, [3]>([0, 2, 1])];
            tensor<bool, []> attn_weights_73_transpose_x_0 = const()[name = tensor<string, []>("attn_weights_73_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> attn_weights_73_transpose_y_0 = const()[name = tensor<string, []>("attn_weights_73_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [16, 64, 77]> transpose_52 = transpose(perm = var_1187_perm_0, x = key_states_51_cast);
            tensor<fp16, [16, 77, 77]> attn_weights_73_cast = matmul(transpose_x = attn_weights_73_transpose_x_0, transpose_y = attn_weights_73_transpose_y_0, x = query_states_25_cast, y = transpose_52);
            tensor<int32, [4]> var_1189 = const()[name = tensor<string, []>("op_1189"), val = tensor<int32, [4]>([1, 16, 77, 77])];
            tensor<fp16, [1, 16, 77, 77]> var_1190_cast = reshape(shape = var_1189, x = attn_weights_73_cast);
            tensor<fp16, [1, 16, 77, 77]> attn_weights_75_cast = add(x = var_1190_cast, y = var_44_cast);
            tensor<int32, [3]> var_1195 = const()[name = tensor<string, []>("op_1195"), val = tensor<int32, [3]>([16, 77, 77])];
            tensor<fp16, [16, 77, 77]> input_197_cast = reshape(shape = var_1195, x = attn_weights_75_cast);
            tensor<fp16, [16, 77, 77]> input_199_cast = softmax(axis = var_5, x = input_197_cast);
            tensor<bool, []> attn_output_73_transpose_x_0 = const()[name = tensor<string, []>("attn_output_73_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> attn_output_73_transpose_y_0 = const()[name = tensor<string, []>("attn_output_73_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [16, 77, 64]> attn_output_73_cast = matmul(transpose_x = attn_output_73_transpose_x_0, transpose_y = attn_output_73_transpose_y_0, x = input_199_cast, y = value_states_51_cast);
            tensor<int32, [4]> var_1200 = const()[name = tensor<string, []>("op_1200"), val = tensor<int32, [4]>([1, 16, 77, 64])];
            tensor<fp16, [1, 16, 77, 64]> attn_output_75_cast = reshape(shape = var_1200, x = attn_output_73_cast);
            tensor<int32, [4]> attn_output_77_perm_0 = const()[name = tensor<string, []>("attn_output_77_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<int32, [3]> var_1203 = const()[name = tensor<string, []>("op_1203"), val = tensor<int32, [3]>([1, 77, 1024])];
            tensor<fp16, [1, 77, 16, 64]> transpose_51 = transpose(perm = attn_output_77_perm_0, x = attn_output_75_cast);
            tensor<fp16, [1, 77, 1024]> input_201_cast = reshape(shape = var_1203, x = transpose_51);
            tensor<fp16, [1024, 1024]> text_encoder_text_model_encoder_layers_12_self_attn_out_proj_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_12_self_attn_out_proj_weight_to_fp16"), val = tensor<fp16, [1024, 1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(409981312)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_12_self_attn_out_proj_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_12_self_attn_out_proj_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(412078528)))];
            tensor<fp16, [1, 77, 1024]> hidden_states_75_cast = linear(bias = text_encoder_text_model_encoder_layers_12_self_attn_out_proj_bias_to_fp16, weight = text_encoder_text_model_encoder_layers_12_self_attn_out_proj_weight_to_fp16, x = input_201_cast);
            tensor<fp16, [1, 77, 1024]> input_203_cast = add(x = input_195_cast, y = hidden_states_75_cast);
            tensor<int32, [1]> input_205_axes_0 = const()[name = tensor<string, []>("input_205_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_12_layer_norm2_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_12_layer_norm2_weight_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(412080640)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_12_layer_norm2_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_12_layer_norm2_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(412082752)))];
            tensor<fp16, [1, 77, 1024]> input_205_cast = layer_norm(axes = input_205_axes_0, beta = text_encoder_text_model_encoder_layers_12_layer_norm2_bias_to_fp16, epsilon = var_12_to_fp16, gamma = text_encoder_text_model_encoder_layers_12_layer_norm2_weight_to_fp16, x = input_203_cast);
            tensor<fp16, [4096, 1024]> text_encoder_text_model_encoder_layers_12_mlp_fc1_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_12_mlp_fc1_weight_to_fp16"), val = tensor<fp16, [4096, 1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(412084864)))];
            tensor<fp16, [4096]> text_encoder_text_model_encoder_layers_12_mlp_fc1_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_12_mlp_fc1_bias_to_fp16"), val = tensor<fp16, [4096]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(420473536)))];
            tensor<fp16, [1, 77, 4096]> input_207_cast = linear(bias = text_encoder_text_model_encoder_layers_12_mlp_fc1_bias_to_fp16, weight = text_encoder_text_model_encoder_layers_12_mlp_fc1_weight_to_fp16, x = input_205_cast);
            tensor<string, []> input_209_mode_0 = const()[name = tensor<string, []>("input_209_mode_0"), val = tensor<string, []>("EXACT")];
            tensor<fp16, [1, 77, 4096]> input_209_cast = gelu(mode = input_209_mode_0, x = input_207_cast);
            tensor<fp16, [1024, 4096]> text_encoder_text_model_encoder_layers_12_mlp_fc2_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_12_mlp_fc2_weight_to_fp16"), val = tensor<fp16, [1024, 4096]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(420481792)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_12_mlp_fc2_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_12_mlp_fc2_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(428870464)))];
            tensor<fp16, [1, 77, 1024]> hidden_states_77_cast = linear(bias = text_encoder_text_model_encoder_layers_12_mlp_fc2_bias_to_fp16, weight = text_encoder_text_model_encoder_layers_12_mlp_fc2_weight_to_fp16, x = input_209_cast);
            tensor<fp16, [1, 77, 1024]> input_211_cast = add(x = input_203_cast, y = hidden_states_77_cast);
            tensor<int32, [1]> hidden_states_79_axes_0 = const()[name = tensor<string, []>("hidden_states_79_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_13_layer_norm1_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_13_layer_norm1_weight_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(428872576)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_13_layer_norm1_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_13_layer_norm1_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(428874688)))];
            tensor<fp16, [1, 77, 1024]> hidden_states_79_cast = layer_norm(axes = hidden_states_79_axes_0, beta = text_encoder_text_model_encoder_layers_13_layer_norm1_bias_to_fp16, epsilon = var_12_to_fp16, gamma = text_encoder_text_model_encoder_layers_13_layer_norm1_weight_to_fp16, x = input_211_cast);
            tensor<fp16, [1024, 1024]> text_encoder_text_model_encoder_layers_13_self_attn_q_proj_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_13_self_attn_q_proj_weight_to_fp16"), val = tensor<fp16, [1024, 1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(428876800)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_13_self_attn_q_proj_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_13_self_attn_q_proj_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(430974016)))];
            tensor<fp16, [1, 77, 1024]> var_1241_cast = linear(bias = text_encoder_text_model_encoder_layers_13_self_attn_q_proj_bias_to_fp16, weight = text_encoder_text_model_encoder_layers_13_self_attn_q_proj_weight_to_fp16, x = hidden_states_79_cast);
            tensor<fp16, []> var_1242_to_fp16 = const()[name = tensor<string, []>("op_1242_to_fp16"), val = tensor<fp16, []>(0x1p-3)];
            tensor<fp16, [1, 77, 1024]> tensor_83_cast = mul(x = var_1241_cast, y = var_1242_to_fp16);
            tensor<fp16, [1024, 1024]> text_encoder_text_model_encoder_layers_13_self_attn_k_proj_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_13_self_attn_k_proj_weight_to_fp16"), val = tensor<fp16, [1024, 1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(430976128)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_13_self_attn_k_proj_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_13_self_attn_k_proj_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(433073344)))];
            tensor<fp16, [1, 77, 1024]> tensor_79_cast = linear(bias = text_encoder_text_model_encoder_layers_13_self_attn_k_proj_bias_to_fp16, weight = text_encoder_text_model_encoder_layers_13_self_attn_k_proj_weight_to_fp16, x = hidden_states_79_cast);
            tensor<int32, [4]> var_1247 = const()[name = tensor<string, []>("op_1247"), val = tensor<int32, [4]>([1, -1, 16, 64])];
            tensor<fp16, [1, 77, 16, 64]> var_1248_cast = reshape(shape = var_1247, x = tensor_79_cast);
            tensor<int32, [4]> var_1249_perm_0 = const()[name = tensor<string, []>("op_1249_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<fp16, [1024, 1024]> text_encoder_text_model_encoder_layers_13_self_attn_v_proj_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_13_self_attn_v_proj_weight_to_fp16"), val = tensor<fp16, [1024, 1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(433075456)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_13_self_attn_v_proj_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_13_self_attn_v_proj_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(435172672)))];
            tensor<fp16, [1, 77, 1024]> tensor_81_cast = linear(bias = text_encoder_text_model_encoder_layers_13_self_attn_v_proj_bias_to_fp16, weight = text_encoder_text_model_encoder_layers_13_self_attn_v_proj_weight_to_fp16, x = hidden_states_79_cast);
            tensor<int32, [4]> var_1254 = const()[name = tensor<string, []>("op_1254"), val = tensor<int32, [4]>([1, -1, 16, 64])];
            tensor<fp16, [1, 77, 16, 64]> var_1255_cast = reshape(shape = var_1254, x = tensor_81_cast);
            tensor<int32, [4]> var_1256_perm_0 = const()[name = tensor<string, []>("op_1256_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<int32, [4]> var_1263 = const()[name = tensor<string, []>("op_1263"), val = tensor<int32, [4]>([1, 77, 16, 64])];
            tensor<fp16, [1, 77, 16, 64]> var_1264_cast = reshape(shape = var_1263, x = tensor_83_cast);
            tensor<int32, [4]> var_1265_perm_0 = const()[name = tensor<string, []>("op_1265_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<int32, [3]> var_1267 = const()[name = tensor<string, []>("op_1267"), val = tensor<int32, [3]>([16, -1, 64])];
            tensor<fp16, [1, 16, 77, 64]> transpose_48 = transpose(perm = var_1265_perm_0, x = var_1264_cast);
            tensor<fp16, [16, 77, 64]> query_states_27_cast = reshape(shape = var_1267, x = transpose_48);
            tensor<int32, [3]> var_1269 = const()[name = tensor<string, []>("op_1269"), val = tensor<int32, [3]>([16, -1, 64])];
            tensor<fp16, [1, 16, 77, 64]> transpose_50 = transpose(perm = var_1249_perm_0, x = var_1248_cast);
            tensor<fp16, [16, 77, 64]> key_states_55_cast = reshape(shape = var_1269, x = transpose_50);
            tensor<int32, [3]> var_1271 = const()[name = tensor<string, []>("op_1271"), val = tensor<int32, [3]>([16, -1, 64])];
            tensor<fp16, [1, 16, 77, 64]> transpose_49 = transpose(perm = var_1256_perm_0, x = var_1255_cast);
            tensor<fp16, [16, 77, 64]> value_states_55_cast = reshape(shape = var_1271, x = transpose_49);
            tensor<int32, [3]> var_1274_perm_0 = const()[name = tensor<string, []>("op_1274_perm_0"), val = tensor<int32, [3]>([0, 2, 1])];
            tensor<bool, []> attn_weights_79_transpose_x_0 = const()[name = tensor<string, []>("attn_weights_79_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> attn_weights_79_transpose_y_0 = const()[name = tensor<string, []>("attn_weights_79_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [16, 64, 77]> transpose_47 = transpose(perm = var_1274_perm_0, x = key_states_55_cast);
            tensor<fp16, [16, 77, 77]> attn_weights_79_cast = matmul(transpose_x = attn_weights_79_transpose_x_0, transpose_y = attn_weights_79_transpose_y_0, x = query_states_27_cast, y = transpose_47);
            tensor<int32, [4]> var_1276 = const()[name = tensor<string, []>("op_1276"), val = tensor<int32, [4]>([1, 16, 77, 77])];
            tensor<fp16, [1, 16, 77, 77]> var_1277_cast = reshape(shape = var_1276, x = attn_weights_79_cast);
            tensor<fp16, [1, 16, 77, 77]> attn_weights_81_cast = add(x = var_1277_cast, y = var_44_cast);
            tensor<int32, [3]> var_1282 = const()[name = tensor<string, []>("op_1282"), val = tensor<int32, [3]>([16, 77, 77])];
            tensor<fp16, [16, 77, 77]> input_213_cast = reshape(shape = var_1282, x = attn_weights_81_cast);
            tensor<fp16, [16, 77, 77]> input_215_cast = softmax(axis = var_5, x = input_213_cast);
            tensor<bool, []> attn_output_79_transpose_x_0 = const()[name = tensor<string, []>("attn_output_79_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> attn_output_79_transpose_y_0 = const()[name = tensor<string, []>("attn_output_79_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [16, 77, 64]> attn_output_79_cast = matmul(transpose_x = attn_output_79_transpose_x_0, transpose_y = attn_output_79_transpose_y_0, x = input_215_cast, y = value_states_55_cast);
            tensor<int32, [4]> var_1287 = const()[name = tensor<string, []>("op_1287"), val = tensor<int32, [4]>([1, 16, 77, 64])];
            tensor<fp16, [1, 16, 77, 64]> attn_output_81_cast = reshape(shape = var_1287, x = attn_output_79_cast);
            tensor<int32, [4]> attn_output_83_perm_0 = const()[name = tensor<string, []>("attn_output_83_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<int32, [3]> var_1290 = const()[name = tensor<string, []>("op_1290"), val = tensor<int32, [3]>([1, 77, 1024])];
            tensor<fp16, [1, 77, 16, 64]> transpose_46 = transpose(perm = attn_output_83_perm_0, x = attn_output_81_cast);
            tensor<fp16, [1, 77, 1024]> input_217_cast = reshape(shape = var_1290, x = transpose_46);
            tensor<fp16, [1024, 1024]> text_encoder_text_model_encoder_layers_13_self_attn_out_proj_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_13_self_attn_out_proj_weight_to_fp16"), val = tensor<fp16, [1024, 1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(435174784)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_13_self_attn_out_proj_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_13_self_attn_out_proj_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(437272000)))];
            tensor<fp16, [1, 77, 1024]> hidden_states_81_cast = linear(bias = text_encoder_text_model_encoder_layers_13_self_attn_out_proj_bias_to_fp16, weight = text_encoder_text_model_encoder_layers_13_self_attn_out_proj_weight_to_fp16, x = input_217_cast);
            tensor<fp16, [1, 77, 1024]> input_219_cast = add(x = input_211_cast, y = hidden_states_81_cast);
            tensor<int32, [1]> input_221_axes_0 = const()[name = tensor<string, []>("input_221_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_13_layer_norm2_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_13_layer_norm2_weight_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(437274112)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_13_layer_norm2_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_13_layer_norm2_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(437276224)))];
            tensor<fp16, [1, 77, 1024]> input_221_cast = layer_norm(axes = input_221_axes_0, beta = text_encoder_text_model_encoder_layers_13_layer_norm2_bias_to_fp16, epsilon = var_12_to_fp16, gamma = text_encoder_text_model_encoder_layers_13_layer_norm2_weight_to_fp16, x = input_219_cast);
            tensor<fp16, [4096, 1024]> text_encoder_text_model_encoder_layers_13_mlp_fc1_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_13_mlp_fc1_weight_to_fp16"), val = tensor<fp16, [4096, 1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(437278336)))];
            tensor<fp16, [4096]> text_encoder_text_model_encoder_layers_13_mlp_fc1_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_13_mlp_fc1_bias_to_fp16"), val = tensor<fp16, [4096]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(445667008)))];
            tensor<fp16, [1, 77, 4096]> input_223_cast = linear(bias = text_encoder_text_model_encoder_layers_13_mlp_fc1_bias_to_fp16, weight = text_encoder_text_model_encoder_layers_13_mlp_fc1_weight_to_fp16, x = input_221_cast);
            tensor<string, []> input_225_mode_0 = const()[name = tensor<string, []>("input_225_mode_0"), val = tensor<string, []>("EXACT")];
            tensor<fp16, [1, 77, 4096]> input_225_cast = gelu(mode = input_225_mode_0, x = input_223_cast);
            tensor<fp16, [1024, 4096]> text_encoder_text_model_encoder_layers_13_mlp_fc2_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_13_mlp_fc2_weight_to_fp16"), val = tensor<fp16, [1024, 4096]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(445675264)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_13_mlp_fc2_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_13_mlp_fc2_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(454063936)))];
            tensor<fp16, [1, 77, 1024]> hidden_states_83_cast = linear(bias = text_encoder_text_model_encoder_layers_13_mlp_fc2_bias_to_fp16, weight = text_encoder_text_model_encoder_layers_13_mlp_fc2_weight_to_fp16, x = input_225_cast);
            tensor<fp16, [1, 77, 1024]> input_227_cast = add(x = input_219_cast, y = hidden_states_83_cast);
            tensor<int32, [1]> hidden_states_85_axes_0 = const()[name = tensor<string, []>("hidden_states_85_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_14_layer_norm1_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_14_layer_norm1_weight_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(454066048)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_14_layer_norm1_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_14_layer_norm1_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(454068160)))];
            tensor<fp16, [1, 77, 1024]> hidden_states_85_cast = layer_norm(axes = hidden_states_85_axes_0, beta = text_encoder_text_model_encoder_layers_14_layer_norm1_bias_to_fp16, epsilon = var_12_to_fp16, gamma = text_encoder_text_model_encoder_layers_14_layer_norm1_weight_to_fp16, x = input_227_cast);
            tensor<fp16, [1024, 1024]> text_encoder_text_model_encoder_layers_14_self_attn_q_proj_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_14_self_attn_q_proj_weight_to_fp16"), val = tensor<fp16, [1024, 1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(454070272)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_14_self_attn_q_proj_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_14_self_attn_q_proj_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(456167488)))];
            tensor<fp16, [1, 77, 1024]> var_1328_cast = linear(bias = text_encoder_text_model_encoder_layers_14_self_attn_q_proj_bias_to_fp16, weight = text_encoder_text_model_encoder_layers_14_self_attn_q_proj_weight_to_fp16, x = hidden_states_85_cast);
            tensor<fp16, []> var_1329_to_fp16 = const()[name = tensor<string, []>("op_1329_to_fp16"), val = tensor<fp16, []>(0x1p-3)];
            tensor<fp16, [1, 77, 1024]> tensor_89_cast = mul(x = var_1328_cast, y = var_1329_to_fp16);
            tensor<fp16, [1024, 1024]> text_encoder_text_model_encoder_layers_14_self_attn_k_proj_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_14_self_attn_k_proj_weight_to_fp16"), val = tensor<fp16, [1024, 1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(456169600)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_14_self_attn_k_proj_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_14_self_attn_k_proj_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(458266816)))];
            tensor<fp16, [1, 77, 1024]> tensor_85_cast = linear(bias = text_encoder_text_model_encoder_layers_14_self_attn_k_proj_bias_to_fp16, weight = text_encoder_text_model_encoder_layers_14_self_attn_k_proj_weight_to_fp16, x = hidden_states_85_cast);
            tensor<int32, [4]> var_1334 = const()[name = tensor<string, []>("op_1334"), val = tensor<int32, [4]>([1, -1, 16, 64])];
            tensor<fp16, [1, 77, 16, 64]> var_1335_cast = reshape(shape = var_1334, x = tensor_85_cast);
            tensor<int32, [4]> var_1336_perm_0 = const()[name = tensor<string, []>("op_1336_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<fp16, [1024, 1024]> text_encoder_text_model_encoder_layers_14_self_attn_v_proj_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_14_self_attn_v_proj_weight_to_fp16"), val = tensor<fp16, [1024, 1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(458268928)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_14_self_attn_v_proj_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_14_self_attn_v_proj_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(460366144)))];
            tensor<fp16, [1, 77, 1024]> tensor_87_cast = linear(bias = text_encoder_text_model_encoder_layers_14_self_attn_v_proj_bias_to_fp16, weight = text_encoder_text_model_encoder_layers_14_self_attn_v_proj_weight_to_fp16, x = hidden_states_85_cast);
            tensor<int32, [4]> var_1341 = const()[name = tensor<string, []>("op_1341"), val = tensor<int32, [4]>([1, -1, 16, 64])];
            tensor<fp16, [1, 77, 16, 64]> var_1342_cast = reshape(shape = var_1341, x = tensor_87_cast);
            tensor<int32, [4]> var_1343_perm_0 = const()[name = tensor<string, []>("op_1343_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<int32, [4]> var_1350 = const()[name = tensor<string, []>("op_1350"), val = tensor<int32, [4]>([1, 77, 16, 64])];
            tensor<fp16, [1, 77, 16, 64]> var_1351_cast = reshape(shape = var_1350, x = tensor_89_cast);
            tensor<int32, [4]> var_1352_perm_0 = const()[name = tensor<string, []>("op_1352_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<int32, [3]> var_1354 = const()[name = tensor<string, []>("op_1354"), val = tensor<int32, [3]>([16, -1, 64])];
            tensor<fp16, [1, 16, 77, 64]> transpose_43 = transpose(perm = var_1352_perm_0, x = var_1351_cast);
            tensor<fp16, [16, 77, 64]> query_states_29_cast = reshape(shape = var_1354, x = transpose_43);
            tensor<int32, [3]> var_1356 = const()[name = tensor<string, []>("op_1356"), val = tensor<int32, [3]>([16, -1, 64])];
            tensor<fp16, [1, 16, 77, 64]> transpose_45 = transpose(perm = var_1336_perm_0, x = var_1335_cast);
            tensor<fp16, [16, 77, 64]> key_states_59_cast = reshape(shape = var_1356, x = transpose_45);
            tensor<int32, [3]> var_1358 = const()[name = tensor<string, []>("op_1358"), val = tensor<int32, [3]>([16, -1, 64])];
            tensor<fp16, [1, 16, 77, 64]> transpose_44 = transpose(perm = var_1343_perm_0, x = var_1342_cast);
            tensor<fp16, [16, 77, 64]> value_states_59_cast = reshape(shape = var_1358, x = transpose_44);
            tensor<int32, [3]> var_1361_perm_0 = const()[name = tensor<string, []>("op_1361_perm_0"), val = tensor<int32, [3]>([0, 2, 1])];
            tensor<bool, []> attn_weights_85_transpose_x_0 = const()[name = tensor<string, []>("attn_weights_85_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> attn_weights_85_transpose_y_0 = const()[name = tensor<string, []>("attn_weights_85_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [16, 64, 77]> transpose_42 = transpose(perm = var_1361_perm_0, x = key_states_59_cast);
            tensor<fp16, [16, 77, 77]> attn_weights_85_cast = matmul(transpose_x = attn_weights_85_transpose_x_0, transpose_y = attn_weights_85_transpose_y_0, x = query_states_29_cast, y = transpose_42);
            tensor<int32, [4]> var_1363 = const()[name = tensor<string, []>("op_1363"), val = tensor<int32, [4]>([1, 16, 77, 77])];
            tensor<fp16, [1, 16, 77, 77]> var_1364_cast = reshape(shape = var_1363, x = attn_weights_85_cast);
            tensor<fp16, [1, 16, 77, 77]> attn_weights_87_cast = add(x = var_1364_cast, y = var_44_cast);
            tensor<int32, [3]> var_1369 = const()[name = tensor<string, []>("op_1369"), val = tensor<int32, [3]>([16, 77, 77])];
            tensor<fp16, [16, 77, 77]> input_229_cast = reshape(shape = var_1369, x = attn_weights_87_cast);
            tensor<fp16, [16, 77, 77]> input_231_cast = softmax(axis = var_5, x = input_229_cast);
            tensor<bool, []> attn_output_85_transpose_x_0 = const()[name = tensor<string, []>("attn_output_85_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> attn_output_85_transpose_y_0 = const()[name = tensor<string, []>("attn_output_85_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [16, 77, 64]> attn_output_85_cast = matmul(transpose_x = attn_output_85_transpose_x_0, transpose_y = attn_output_85_transpose_y_0, x = input_231_cast, y = value_states_59_cast);
            tensor<int32, [4]> var_1374 = const()[name = tensor<string, []>("op_1374"), val = tensor<int32, [4]>([1, 16, 77, 64])];
            tensor<fp16, [1, 16, 77, 64]> attn_output_87_cast = reshape(shape = var_1374, x = attn_output_85_cast);
            tensor<int32, [4]> attn_output_89_perm_0 = const()[name = tensor<string, []>("attn_output_89_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<int32, [3]> var_1377 = const()[name = tensor<string, []>("op_1377"), val = tensor<int32, [3]>([1, 77, 1024])];
            tensor<fp16, [1, 77, 16, 64]> transpose_41 = transpose(perm = attn_output_89_perm_0, x = attn_output_87_cast);
            tensor<fp16, [1, 77, 1024]> input_233_cast = reshape(shape = var_1377, x = transpose_41);
            tensor<fp16, [1024, 1024]> text_encoder_text_model_encoder_layers_14_self_attn_out_proj_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_14_self_attn_out_proj_weight_to_fp16"), val = tensor<fp16, [1024, 1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(460368256)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_14_self_attn_out_proj_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_14_self_attn_out_proj_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(462465472)))];
            tensor<fp16, [1, 77, 1024]> hidden_states_87_cast = linear(bias = text_encoder_text_model_encoder_layers_14_self_attn_out_proj_bias_to_fp16, weight = text_encoder_text_model_encoder_layers_14_self_attn_out_proj_weight_to_fp16, x = input_233_cast);
            tensor<fp16, [1, 77, 1024]> input_235_cast = add(x = input_227_cast, y = hidden_states_87_cast);
            tensor<int32, [1]> input_237_axes_0 = const()[name = tensor<string, []>("input_237_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_14_layer_norm2_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_14_layer_norm2_weight_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(462467584)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_14_layer_norm2_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_14_layer_norm2_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(462469696)))];
            tensor<fp16, [1, 77, 1024]> input_237_cast = layer_norm(axes = input_237_axes_0, beta = text_encoder_text_model_encoder_layers_14_layer_norm2_bias_to_fp16, epsilon = var_12_to_fp16, gamma = text_encoder_text_model_encoder_layers_14_layer_norm2_weight_to_fp16, x = input_235_cast);
            tensor<fp16, [4096, 1024]> text_encoder_text_model_encoder_layers_14_mlp_fc1_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_14_mlp_fc1_weight_to_fp16"), val = tensor<fp16, [4096, 1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(462471808)))];
            tensor<fp16, [4096]> text_encoder_text_model_encoder_layers_14_mlp_fc1_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_14_mlp_fc1_bias_to_fp16"), val = tensor<fp16, [4096]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(470860480)))];
            tensor<fp16, [1, 77, 4096]> input_239_cast = linear(bias = text_encoder_text_model_encoder_layers_14_mlp_fc1_bias_to_fp16, weight = text_encoder_text_model_encoder_layers_14_mlp_fc1_weight_to_fp16, x = input_237_cast);
            tensor<string, []> input_241_mode_0 = const()[name = tensor<string, []>("input_241_mode_0"), val = tensor<string, []>("EXACT")];
            tensor<fp16, [1, 77, 4096]> input_241_cast = gelu(mode = input_241_mode_0, x = input_239_cast);
            tensor<fp16, [1024, 4096]> text_encoder_text_model_encoder_layers_14_mlp_fc2_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_14_mlp_fc2_weight_to_fp16"), val = tensor<fp16, [1024, 4096]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(470868736)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_14_mlp_fc2_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_14_mlp_fc2_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(479257408)))];
            tensor<fp16, [1, 77, 1024]> hidden_states_89_cast = linear(bias = text_encoder_text_model_encoder_layers_14_mlp_fc2_bias_to_fp16, weight = text_encoder_text_model_encoder_layers_14_mlp_fc2_weight_to_fp16, x = input_241_cast);
            tensor<fp16, [1, 77, 1024]> input_243_cast = add(x = input_235_cast, y = hidden_states_89_cast);
            tensor<int32, [1]> hidden_states_91_axes_0 = const()[name = tensor<string, []>("hidden_states_91_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_15_layer_norm1_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_15_layer_norm1_weight_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(479259520)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_15_layer_norm1_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_15_layer_norm1_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(479261632)))];
            tensor<fp16, [1, 77, 1024]> hidden_states_91_cast = layer_norm(axes = hidden_states_91_axes_0, beta = text_encoder_text_model_encoder_layers_15_layer_norm1_bias_to_fp16, epsilon = var_12_to_fp16, gamma = text_encoder_text_model_encoder_layers_15_layer_norm1_weight_to_fp16, x = input_243_cast);
            tensor<fp16, [1024, 1024]> text_encoder_text_model_encoder_layers_15_self_attn_q_proj_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_15_self_attn_q_proj_weight_to_fp16"), val = tensor<fp16, [1024, 1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(479263744)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_15_self_attn_q_proj_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_15_self_attn_q_proj_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(481360960)))];
            tensor<fp16, [1, 77, 1024]> var_1415_cast = linear(bias = text_encoder_text_model_encoder_layers_15_self_attn_q_proj_bias_to_fp16, weight = text_encoder_text_model_encoder_layers_15_self_attn_q_proj_weight_to_fp16, x = hidden_states_91_cast);
            tensor<fp16, []> var_1416_to_fp16 = const()[name = tensor<string, []>("op_1416_to_fp16"), val = tensor<fp16, []>(0x1p-3)];
            tensor<fp16, [1, 77, 1024]> tensor_95_cast = mul(x = var_1415_cast, y = var_1416_to_fp16);
            tensor<fp16, [1024, 1024]> text_encoder_text_model_encoder_layers_15_self_attn_k_proj_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_15_self_attn_k_proj_weight_to_fp16"), val = tensor<fp16, [1024, 1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(481363072)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_15_self_attn_k_proj_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_15_self_attn_k_proj_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(483460288)))];
            tensor<fp16, [1, 77, 1024]> tensor_91_cast = linear(bias = text_encoder_text_model_encoder_layers_15_self_attn_k_proj_bias_to_fp16, weight = text_encoder_text_model_encoder_layers_15_self_attn_k_proj_weight_to_fp16, x = hidden_states_91_cast);
            tensor<int32, [4]> var_1421 = const()[name = tensor<string, []>("op_1421"), val = tensor<int32, [4]>([1, -1, 16, 64])];
            tensor<fp16, [1, 77, 16, 64]> var_1422_cast = reshape(shape = var_1421, x = tensor_91_cast);
            tensor<int32, [4]> var_1423_perm_0 = const()[name = tensor<string, []>("op_1423_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<fp16, [1024, 1024]> text_encoder_text_model_encoder_layers_15_self_attn_v_proj_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_15_self_attn_v_proj_weight_to_fp16"), val = tensor<fp16, [1024, 1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(483462400)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_15_self_attn_v_proj_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_15_self_attn_v_proj_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(485559616)))];
            tensor<fp16, [1, 77, 1024]> tensor_93_cast = linear(bias = text_encoder_text_model_encoder_layers_15_self_attn_v_proj_bias_to_fp16, weight = text_encoder_text_model_encoder_layers_15_self_attn_v_proj_weight_to_fp16, x = hidden_states_91_cast);
            tensor<int32, [4]> var_1428 = const()[name = tensor<string, []>("op_1428"), val = tensor<int32, [4]>([1, -1, 16, 64])];
            tensor<fp16, [1, 77, 16, 64]> var_1429_cast = reshape(shape = var_1428, x = tensor_93_cast);
            tensor<int32, [4]> var_1430_perm_0 = const()[name = tensor<string, []>("op_1430_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<int32, [4]> var_1437 = const()[name = tensor<string, []>("op_1437"), val = tensor<int32, [4]>([1, 77, 16, 64])];
            tensor<fp16, [1, 77, 16, 64]> var_1438_cast = reshape(shape = var_1437, x = tensor_95_cast);
            tensor<int32, [4]> var_1439_perm_0 = const()[name = tensor<string, []>("op_1439_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<int32, [3]> var_1441 = const()[name = tensor<string, []>("op_1441"), val = tensor<int32, [3]>([16, -1, 64])];
            tensor<fp16, [1, 16, 77, 64]> transpose_38 = transpose(perm = var_1439_perm_0, x = var_1438_cast);
            tensor<fp16, [16, 77, 64]> query_states_31_cast = reshape(shape = var_1441, x = transpose_38);
            tensor<int32, [3]> var_1443 = const()[name = tensor<string, []>("op_1443"), val = tensor<int32, [3]>([16, -1, 64])];
            tensor<fp16, [1, 16, 77, 64]> transpose_40 = transpose(perm = var_1423_perm_0, x = var_1422_cast);
            tensor<fp16, [16, 77, 64]> key_states_63_cast = reshape(shape = var_1443, x = transpose_40);
            tensor<int32, [3]> var_1445 = const()[name = tensor<string, []>("op_1445"), val = tensor<int32, [3]>([16, -1, 64])];
            tensor<fp16, [1, 16, 77, 64]> transpose_39 = transpose(perm = var_1430_perm_0, x = var_1429_cast);
            tensor<fp16, [16, 77, 64]> value_states_63_cast = reshape(shape = var_1445, x = transpose_39);
            tensor<int32, [3]> var_1448_perm_0 = const()[name = tensor<string, []>("op_1448_perm_0"), val = tensor<int32, [3]>([0, 2, 1])];
            tensor<bool, []> attn_weights_91_transpose_x_0 = const()[name = tensor<string, []>("attn_weights_91_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> attn_weights_91_transpose_y_0 = const()[name = tensor<string, []>("attn_weights_91_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [16, 64, 77]> transpose_37 = transpose(perm = var_1448_perm_0, x = key_states_63_cast);
            tensor<fp16, [16, 77, 77]> attn_weights_91_cast = matmul(transpose_x = attn_weights_91_transpose_x_0, transpose_y = attn_weights_91_transpose_y_0, x = query_states_31_cast, y = transpose_37);
            tensor<int32, [4]> var_1450 = const()[name = tensor<string, []>("op_1450"), val = tensor<int32, [4]>([1, 16, 77, 77])];
            tensor<fp16, [1, 16, 77, 77]> var_1451_cast = reshape(shape = var_1450, x = attn_weights_91_cast);
            tensor<fp16, [1, 16, 77, 77]> attn_weights_93_cast = add(x = var_1451_cast, y = var_44_cast);
            tensor<int32, [3]> var_1456 = const()[name = tensor<string, []>("op_1456"), val = tensor<int32, [3]>([16, 77, 77])];
            tensor<fp16, [16, 77, 77]> input_245_cast = reshape(shape = var_1456, x = attn_weights_93_cast);
            tensor<fp16, [16, 77, 77]> input_247_cast = softmax(axis = var_5, x = input_245_cast);
            tensor<bool, []> attn_output_91_transpose_x_0 = const()[name = tensor<string, []>("attn_output_91_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> attn_output_91_transpose_y_0 = const()[name = tensor<string, []>("attn_output_91_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [16, 77, 64]> attn_output_91_cast = matmul(transpose_x = attn_output_91_transpose_x_0, transpose_y = attn_output_91_transpose_y_0, x = input_247_cast, y = value_states_63_cast);
            tensor<int32, [4]> var_1461 = const()[name = tensor<string, []>("op_1461"), val = tensor<int32, [4]>([1, 16, 77, 64])];
            tensor<fp16, [1, 16, 77, 64]> attn_output_93_cast = reshape(shape = var_1461, x = attn_output_91_cast);
            tensor<int32, [4]> attn_output_95_perm_0 = const()[name = tensor<string, []>("attn_output_95_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<int32, [3]> var_1464 = const()[name = tensor<string, []>("op_1464"), val = tensor<int32, [3]>([1, 77, 1024])];
            tensor<fp16, [1, 77, 16, 64]> transpose_36 = transpose(perm = attn_output_95_perm_0, x = attn_output_93_cast);
            tensor<fp16, [1, 77, 1024]> input_249_cast = reshape(shape = var_1464, x = transpose_36);
            tensor<fp16, [1024, 1024]> text_encoder_text_model_encoder_layers_15_self_attn_out_proj_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_15_self_attn_out_proj_weight_to_fp16"), val = tensor<fp16, [1024, 1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(485561728)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_15_self_attn_out_proj_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_15_self_attn_out_proj_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(487658944)))];
            tensor<fp16, [1, 77, 1024]> hidden_states_93_cast = linear(bias = text_encoder_text_model_encoder_layers_15_self_attn_out_proj_bias_to_fp16, weight = text_encoder_text_model_encoder_layers_15_self_attn_out_proj_weight_to_fp16, x = input_249_cast);
            tensor<fp16, [1, 77, 1024]> input_251_cast = add(x = input_243_cast, y = hidden_states_93_cast);
            tensor<int32, [1]> input_253_axes_0 = const()[name = tensor<string, []>("input_253_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_15_layer_norm2_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_15_layer_norm2_weight_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(487661056)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_15_layer_norm2_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_15_layer_norm2_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(487663168)))];
            tensor<fp16, [1, 77, 1024]> input_253_cast = layer_norm(axes = input_253_axes_0, beta = text_encoder_text_model_encoder_layers_15_layer_norm2_bias_to_fp16, epsilon = var_12_to_fp16, gamma = text_encoder_text_model_encoder_layers_15_layer_norm2_weight_to_fp16, x = input_251_cast);
            tensor<fp16, [4096, 1024]> text_encoder_text_model_encoder_layers_15_mlp_fc1_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_15_mlp_fc1_weight_to_fp16"), val = tensor<fp16, [4096, 1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(487665280)))];
            tensor<fp16, [4096]> text_encoder_text_model_encoder_layers_15_mlp_fc1_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_15_mlp_fc1_bias_to_fp16"), val = tensor<fp16, [4096]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(496053952)))];
            tensor<fp16, [1, 77, 4096]> input_255_cast = linear(bias = text_encoder_text_model_encoder_layers_15_mlp_fc1_bias_to_fp16, weight = text_encoder_text_model_encoder_layers_15_mlp_fc1_weight_to_fp16, x = input_253_cast);
            tensor<string, []> input_257_mode_0 = const()[name = tensor<string, []>("input_257_mode_0"), val = tensor<string, []>("EXACT")];
            tensor<fp16, [1, 77, 4096]> input_257_cast = gelu(mode = input_257_mode_0, x = input_255_cast);
            tensor<fp16, [1024, 4096]> text_encoder_text_model_encoder_layers_15_mlp_fc2_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_15_mlp_fc2_weight_to_fp16"), val = tensor<fp16, [1024, 4096]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(496062208)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_15_mlp_fc2_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_15_mlp_fc2_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(504450880)))];
            tensor<fp16, [1, 77, 1024]> hidden_states_95_cast = linear(bias = text_encoder_text_model_encoder_layers_15_mlp_fc2_bias_to_fp16, weight = text_encoder_text_model_encoder_layers_15_mlp_fc2_weight_to_fp16, x = input_257_cast);
            tensor<fp16, [1, 77, 1024]> input_259_cast = add(x = input_251_cast, y = hidden_states_95_cast);
            tensor<int32, [1]> hidden_states_97_axes_0 = const()[name = tensor<string, []>("hidden_states_97_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_16_layer_norm1_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_16_layer_norm1_weight_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(504452992)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_16_layer_norm1_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_16_layer_norm1_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(504455104)))];
            tensor<fp16, [1, 77, 1024]> hidden_states_97_cast = layer_norm(axes = hidden_states_97_axes_0, beta = text_encoder_text_model_encoder_layers_16_layer_norm1_bias_to_fp16, epsilon = var_12_to_fp16, gamma = text_encoder_text_model_encoder_layers_16_layer_norm1_weight_to_fp16, x = input_259_cast);
            tensor<fp16, [1024, 1024]> text_encoder_text_model_encoder_layers_16_self_attn_q_proj_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_16_self_attn_q_proj_weight_to_fp16"), val = tensor<fp16, [1024, 1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(504457216)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_16_self_attn_q_proj_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_16_self_attn_q_proj_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(506554432)))];
            tensor<fp16, [1, 77, 1024]> var_1502_cast = linear(bias = text_encoder_text_model_encoder_layers_16_self_attn_q_proj_bias_to_fp16, weight = text_encoder_text_model_encoder_layers_16_self_attn_q_proj_weight_to_fp16, x = hidden_states_97_cast);
            tensor<fp16, []> var_1503_to_fp16 = const()[name = tensor<string, []>("op_1503_to_fp16"), val = tensor<fp16, []>(0x1p-3)];
            tensor<fp16, [1, 77, 1024]> tensor_101_cast = mul(x = var_1502_cast, y = var_1503_to_fp16);
            tensor<fp16, [1024, 1024]> text_encoder_text_model_encoder_layers_16_self_attn_k_proj_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_16_self_attn_k_proj_weight_to_fp16"), val = tensor<fp16, [1024, 1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(506556544)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_16_self_attn_k_proj_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_16_self_attn_k_proj_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(508653760)))];
            tensor<fp16, [1, 77, 1024]> tensor_97_cast = linear(bias = text_encoder_text_model_encoder_layers_16_self_attn_k_proj_bias_to_fp16, weight = text_encoder_text_model_encoder_layers_16_self_attn_k_proj_weight_to_fp16, x = hidden_states_97_cast);
            tensor<int32, [4]> var_1508 = const()[name = tensor<string, []>("op_1508"), val = tensor<int32, [4]>([1, -1, 16, 64])];
            tensor<fp16, [1, 77, 16, 64]> var_1509_cast = reshape(shape = var_1508, x = tensor_97_cast);
            tensor<int32, [4]> var_1510_perm_0 = const()[name = tensor<string, []>("op_1510_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<fp16, [1024, 1024]> text_encoder_text_model_encoder_layers_16_self_attn_v_proj_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_16_self_attn_v_proj_weight_to_fp16"), val = tensor<fp16, [1024, 1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(508655872)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_16_self_attn_v_proj_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_16_self_attn_v_proj_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(510753088)))];
            tensor<fp16, [1, 77, 1024]> tensor_99_cast = linear(bias = text_encoder_text_model_encoder_layers_16_self_attn_v_proj_bias_to_fp16, weight = text_encoder_text_model_encoder_layers_16_self_attn_v_proj_weight_to_fp16, x = hidden_states_97_cast);
            tensor<int32, [4]> var_1515 = const()[name = tensor<string, []>("op_1515"), val = tensor<int32, [4]>([1, -1, 16, 64])];
            tensor<fp16, [1, 77, 16, 64]> var_1516_cast = reshape(shape = var_1515, x = tensor_99_cast);
            tensor<int32, [4]> var_1517_perm_0 = const()[name = tensor<string, []>("op_1517_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<int32, [4]> var_1524 = const()[name = tensor<string, []>("op_1524"), val = tensor<int32, [4]>([1, 77, 16, 64])];
            tensor<fp16, [1, 77, 16, 64]> var_1525_cast = reshape(shape = var_1524, x = tensor_101_cast);
            tensor<int32, [4]> var_1526_perm_0 = const()[name = tensor<string, []>("op_1526_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<int32, [3]> var_1528 = const()[name = tensor<string, []>("op_1528"), val = tensor<int32, [3]>([16, -1, 64])];
            tensor<fp16, [1, 16, 77, 64]> transpose_33 = transpose(perm = var_1526_perm_0, x = var_1525_cast);
            tensor<fp16, [16, 77, 64]> query_states_33_cast = reshape(shape = var_1528, x = transpose_33);
            tensor<int32, [3]> var_1530 = const()[name = tensor<string, []>("op_1530"), val = tensor<int32, [3]>([16, -1, 64])];
            tensor<fp16, [1, 16, 77, 64]> transpose_35 = transpose(perm = var_1510_perm_0, x = var_1509_cast);
            tensor<fp16, [16, 77, 64]> key_states_67_cast = reshape(shape = var_1530, x = transpose_35);
            tensor<int32, [3]> var_1532 = const()[name = tensor<string, []>("op_1532"), val = tensor<int32, [3]>([16, -1, 64])];
            tensor<fp16, [1, 16, 77, 64]> transpose_34 = transpose(perm = var_1517_perm_0, x = var_1516_cast);
            tensor<fp16, [16, 77, 64]> value_states_67_cast = reshape(shape = var_1532, x = transpose_34);
            tensor<int32, [3]> var_1535_perm_0 = const()[name = tensor<string, []>("op_1535_perm_0"), val = tensor<int32, [3]>([0, 2, 1])];
            tensor<bool, []> attn_weights_97_transpose_x_0 = const()[name = tensor<string, []>("attn_weights_97_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> attn_weights_97_transpose_y_0 = const()[name = tensor<string, []>("attn_weights_97_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [16, 64, 77]> transpose_32 = transpose(perm = var_1535_perm_0, x = key_states_67_cast);
            tensor<fp16, [16, 77, 77]> attn_weights_97_cast = matmul(transpose_x = attn_weights_97_transpose_x_0, transpose_y = attn_weights_97_transpose_y_0, x = query_states_33_cast, y = transpose_32);
            tensor<int32, [4]> var_1537 = const()[name = tensor<string, []>("op_1537"), val = tensor<int32, [4]>([1, 16, 77, 77])];
            tensor<fp16, [1, 16, 77, 77]> var_1538_cast = reshape(shape = var_1537, x = attn_weights_97_cast);
            tensor<fp16, [1, 16, 77, 77]> attn_weights_99_cast = add(x = var_1538_cast, y = var_44_cast);
            tensor<int32, [3]> var_1543 = const()[name = tensor<string, []>("op_1543"), val = tensor<int32, [3]>([16, 77, 77])];
            tensor<fp16, [16, 77, 77]> input_261_cast = reshape(shape = var_1543, x = attn_weights_99_cast);
            tensor<fp16, [16, 77, 77]> input_263_cast = softmax(axis = var_5, x = input_261_cast);
            tensor<bool, []> attn_output_97_transpose_x_0 = const()[name = tensor<string, []>("attn_output_97_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> attn_output_97_transpose_y_0 = const()[name = tensor<string, []>("attn_output_97_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [16, 77, 64]> attn_output_97_cast = matmul(transpose_x = attn_output_97_transpose_x_0, transpose_y = attn_output_97_transpose_y_0, x = input_263_cast, y = value_states_67_cast);
            tensor<int32, [4]> var_1548 = const()[name = tensor<string, []>("op_1548"), val = tensor<int32, [4]>([1, 16, 77, 64])];
            tensor<fp16, [1, 16, 77, 64]> attn_output_99_cast = reshape(shape = var_1548, x = attn_output_97_cast);
            tensor<int32, [4]> attn_output_101_perm_0 = const()[name = tensor<string, []>("attn_output_101_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<int32, [3]> var_1551 = const()[name = tensor<string, []>("op_1551"), val = tensor<int32, [3]>([1, 77, 1024])];
            tensor<fp16, [1, 77, 16, 64]> transpose_31 = transpose(perm = attn_output_101_perm_0, x = attn_output_99_cast);
            tensor<fp16, [1, 77, 1024]> input_265_cast = reshape(shape = var_1551, x = transpose_31);
            tensor<fp16, [1024, 1024]> text_encoder_text_model_encoder_layers_16_self_attn_out_proj_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_16_self_attn_out_proj_weight_to_fp16"), val = tensor<fp16, [1024, 1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(510755200)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_16_self_attn_out_proj_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_16_self_attn_out_proj_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(512852416)))];
            tensor<fp16, [1, 77, 1024]> hidden_states_99_cast = linear(bias = text_encoder_text_model_encoder_layers_16_self_attn_out_proj_bias_to_fp16, weight = text_encoder_text_model_encoder_layers_16_self_attn_out_proj_weight_to_fp16, x = input_265_cast);
            tensor<fp16, [1, 77, 1024]> input_267_cast = add(x = input_259_cast, y = hidden_states_99_cast);
            tensor<int32, [1]> input_269_axes_0 = const()[name = tensor<string, []>("input_269_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_16_layer_norm2_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_16_layer_norm2_weight_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(512854528)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_16_layer_norm2_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_16_layer_norm2_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(512856640)))];
            tensor<fp16, [1, 77, 1024]> input_269_cast = layer_norm(axes = input_269_axes_0, beta = text_encoder_text_model_encoder_layers_16_layer_norm2_bias_to_fp16, epsilon = var_12_to_fp16, gamma = text_encoder_text_model_encoder_layers_16_layer_norm2_weight_to_fp16, x = input_267_cast);
            tensor<fp16, [4096, 1024]> text_encoder_text_model_encoder_layers_16_mlp_fc1_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_16_mlp_fc1_weight_to_fp16"), val = tensor<fp16, [4096, 1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(512858752)))];
            tensor<fp16, [4096]> text_encoder_text_model_encoder_layers_16_mlp_fc1_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_16_mlp_fc1_bias_to_fp16"), val = tensor<fp16, [4096]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(521247424)))];
            tensor<fp16, [1, 77, 4096]> input_271_cast = linear(bias = text_encoder_text_model_encoder_layers_16_mlp_fc1_bias_to_fp16, weight = text_encoder_text_model_encoder_layers_16_mlp_fc1_weight_to_fp16, x = input_269_cast);
            tensor<string, []> input_273_mode_0 = const()[name = tensor<string, []>("input_273_mode_0"), val = tensor<string, []>("EXACT")];
            tensor<fp16, [1, 77, 4096]> input_273_cast = gelu(mode = input_273_mode_0, x = input_271_cast);
            tensor<fp16, [1024, 4096]> text_encoder_text_model_encoder_layers_16_mlp_fc2_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_16_mlp_fc2_weight_to_fp16"), val = tensor<fp16, [1024, 4096]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(521255680)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_16_mlp_fc2_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_16_mlp_fc2_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(529644352)))];
            tensor<fp16, [1, 77, 1024]> hidden_states_101_cast = linear(bias = text_encoder_text_model_encoder_layers_16_mlp_fc2_bias_to_fp16, weight = text_encoder_text_model_encoder_layers_16_mlp_fc2_weight_to_fp16, x = input_273_cast);
            tensor<fp16, [1, 77, 1024]> input_275_cast = add(x = input_267_cast, y = hidden_states_101_cast);
            tensor<int32, [1]> hidden_states_103_axes_0 = const()[name = tensor<string, []>("hidden_states_103_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_17_layer_norm1_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_17_layer_norm1_weight_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(529646464)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_17_layer_norm1_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_17_layer_norm1_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(529648576)))];
            tensor<fp16, [1, 77, 1024]> hidden_states_103_cast = layer_norm(axes = hidden_states_103_axes_0, beta = text_encoder_text_model_encoder_layers_17_layer_norm1_bias_to_fp16, epsilon = var_12_to_fp16, gamma = text_encoder_text_model_encoder_layers_17_layer_norm1_weight_to_fp16, x = input_275_cast);
            tensor<fp16, [1024, 1024]> text_encoder_text_model_encoder_layers_17_self_attn_q_proj_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_17_self_attn_q_proj_weight_to_fp16"), val = tensor<fp16, [1024, 1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(529650688)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_17_self_attn_q_proj_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_17_self_attn_q_proj_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(531747904)))];
            tensor<fp16, [1, 77, 1024]> var_1589_cast = linear(bias = text_encoder_text_model_encoder_layers_17_self_attn_q_proj_bias_to_fp16, weight = text_encoder_text_model_encoder_layers_17_self_attn_q_proj_weight_to_fp16, x = hidden_states_103_cast);
            tensor<fp16, []> var_1590_to_fp16 = const()[name = tensor<string, []>("op_1590_to_fp16"), val = tensor<fp16, []>(0x1p-3)];
            tensor<fp16, [1, 77, 1024]> tensor_107_cast = mul(x = var_1589_cast, y = var_1590_to_fp16);
            tensor<fp16, [1024, 1024]> text_encoder_text_model_encoder_layers_17_self_attn_k_proj_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_17_self_attn_k_proj_weight_to_fp16"), val = tensor<fp16, [1024, 1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(531750016)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_17_self_attn_k_proj_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_17_self_attn_k_proj_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(533847232)))];
            tensor<fp16, [1, 77, 1024]> tensor_103_cast = linear(bias = text_encoder_text_model_encoder_layers_17_self_attn_k_proj_bias_to_fp16, weight = text_encoder_text_model_encoder_layers_17_self_attn_k_proj_weight_to_fp16, x = hidden_states_103_cast);
            tensor<int32, [4]> var_1595 = const()[name = tensor<string, []>("op_1595"), val = tensor<int32, [4]>([1, -1, 16, 64])];
            tensor<fp16, [1, 77, 16, 64]> var_1596_cast = reshape(shape = var_1595, x = tensor_103_cast);
            tensor<int32, [4]> var_1597_perm_0 = const()[name = tensor<string, []>("op_1597_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<fp16, [1024, 1024]> text_encoder_text_model_encoder_layers_17_self_attn_v_proj_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_17_self_attn_v_proj_weight_to_fp16"), val = tensor<fp16, [1024, 1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(533849344)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_17_self_attn_v_proj_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_17_self_attn_v_proj_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(535946560)))];
            tensor<fp16, [1, 77, 1024]> tensor_105_cast = linear(bias = text_encoder_text_model_encoder_layers_17_self_attn_v_proj_bias_to_fp16, weight = text_encoder_text_model_encoder_layers_17_self_attn_v_proj_weight_to_fp16, x = hidden_states_103_cast);
            tensor<int32, [4]> var_1602 = const()[name = tensor<string, []>("op_1602"), val = tensor<int32, [4]>([1, -1, 16, 64])];
            tensor<fp16, [1, 77, 16, 64]> var_1603_cast = reshape(shape = var_1602, x = tensor_105_cast);
            tensor<int32, [4]> var_1604_perm_0 = const()[name = tensor<string, []>("op_1604_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<int32, [4]> var_1611 = const()[name = tensor<string, []>("op_1611"), val = tensor<int32, [4]>([1, 77, 16, 64])];
            tensor<fp16, [1, 77, 16, 64]> var_1612_cast = reshape(shape = var_1611, x = tensor_107_cast);
            tensor<int32, [4]> var_1613_perm_0 = const()[name = tensor<string, []>("op_1613_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<int32, [3]> var_1615 = const()[name = tensor<string, []>("op_1615"), val = tensor<int32, [3]>([16, -1, 64])];
            tensor<fp16, [1, 16, 77, 64]> transpose_28 = transpose(perm = var_1613_perm_0, x = var_1612_cast);
            tensor<fp16, [16, 77, 64]> query_states_35_cast = reshape(shape = var_1615, x = transpose_28);
            tensor<int32, [3]> var_1617 = const()[name = tensor<string, []>("op_1617"), val = tensor<int32, [3]>([16, -1, 64])];
            tensor<fp16, [1, 16, 77, 64]> transpose_30 = transpose(perm = var_1597_perm_0, x = var_1596_cast);
            tensor<fp16, [16, 77, 64]> key_states_71_cast = reshape(shape = var_1617, x = transpose_30);
            tensor<int32, [3]> var_1619 = const()[name = tensor<string, []>("op_1619"), val = tensor<int32, [3]>([16, -1, 64])];
            tensor<fp16, [1, 16, 77, 64]> transpose_29 = transpose(perm = var_1604_perm_0, x = var_1603_cast);
            tensor<fp16, [16, 77, 64]> value_states_71_cast = reshape(shape = var_1619, x = transpose_29);
            tensor<int32, [3]> var_1622_perm_0 = const()[name = tensor<string, []>("op_1622_perm_0"), val = tensor<int32, [3]>([0, 2, 1])];
            tensor<bool, []> attn_weights_103_transpose_x_0 = const()[name = tensor<string, []>("attn_weights_103_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> attn_weights_103_transpose_y_0 = const()[name = tensor<string, []>("attn_weights_103_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [16, 64, 77]> transpose_27 = transpose(perm = var_1622_perm_0, x = key_states_71_cast);
            tensor<fp16, [16, 77, 77]> attn_weights_103_cast = matmul(transpose_x = attn_weights_103_transpose_x_0, transpose_y = attn_weights_103_transpose_y_0, x = query_states_35_cast, y = transpose_27);
            tensor<int32, [4]> var_1624 = const()[name = tensor<string, []>("op_1624"), val = tensor<int32, [4]>([1, 16, 77, 77])];
            tensor<fp16, [1, 16, 77, 77]> var_1625_cast = reshape(shape = var_1624, x = attn_weights_103_cast);
            tensor<fp16, [1, 16, 77, 77]> attn_weights_105_cast = add(x = var_1625_cast, y = var_44_cast);
            tensor<int32, [3]> var_1630 = const()[name = tensor<string, []>("op_1630"), val = tensor<int32, [3]>([16, 77, 77])];
            tensor<fp16, [16, 77, 77]> input_277_cast = reshape(shape = var_1630, x = attn_weights_105_cast);
            tensor<fp16, [16, 77, 77]> input_279_cast = softmax(axis = var_5, x = input_277_cast);
            tensor<bool, []> attn_output_103_transpose_x_0 = const()[name = tensor<string, []>("attn_output_103_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> attn_output_103_transpose_y_0 = const()[name = tensor<string, []>("attn_output_103_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [16, 77, 64]> attn_output_103_cast = matmul(transpose_x = attn_output_103_transpose_x_0, transpose_y = attn_output_103_transpose_y_0, x = input_279_cast, y = value_states_71_cast);
            tensor<int32, [4]> var_1635 = const()[name = tensor<string, []>("op_1635"), val = tensor<int32, [4]>([1, 16, 77, 64])];
            tensor<fp16, [1, 16, 77, 64]> attn_output_105_cast = reshape(shape = var_1635, x = attn_output_103_cast);
            tensor<int32, [4]> attn_output_107_perm_0 = const()[name = tensor<string, []>("attn_output_107_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<int32, [3]> var_1638 = const()[name = tensor<string, []>("op_1638"), val = tensor<int32, [3]>([1, 77, 1024])];
            tensor<fp16, [1, 77, 16, 64]> transpose_26 = transpose(perm = attn_output_107_perm_0, x = attn_output_105_cast);
            tensor<fp16, [1, 77, 1024]> input_281_cast = reshape(shape = var_1638, x = transpose_26);
            tensor<fp16, [1024, 1024]> text_encoder_text_model_encoder_layers_17_self_attn_out_proj_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_17_self_attn_out_proj_weight_to_fp16"), val = tensor<fp16, [1024, 1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(535948672)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_17_self_attn_out_proj_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_17_self_attn_out_proj_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(538045888)))];
            tensor<fp16, [1, 77, 1024]> hidden_states_105_cast = linear(bias = text_encoder_text_model_encoder_layers_17_self_attn_out_proj_bias_to_fp16, weight = text_encoder_text_model_encoder_layers_17_self_attn_out_proj_weight_to_fp16, x = input_281_cast);
            tensor<fp16, [1, 77, 1024]> input_283_cast = add(x = input_275_cast, y = hidden_states_105_cast);
            tensor<int32, [1]> input_285_axes_0 = const()[name = tensor<string, []>("input_285_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_17_layer_norm2_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_17_layer_norm2_weight_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(538048000)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_17_layer_norm2_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_17_layer_norm2_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(538050112)))];
            tensor<fp16, [1, 77, 1024]> input_285_cast = layer_norm(axes = input_285_axes_0, beta = text_encoder_text_model_encoder_layers_17_layer_norm2_bias_to_fp16, epsilon = var_12_to_fp16, gamma = text_encoder_text_model_encoder_layers_17_layer_norm2_weight_to_fp16, x = input_283_cast);
            tensor<fp16, [4096, 1024]> text_encoder_text_model_encoder_layers_17_mlp_fc1_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_17_mlp_fc1_weight_to_fp16"), val = tensor<fp16, [4096, 1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(538052224)))];
            tensor<fp16, [4096]> text_encoder_text_model_encoder_layers_17_mlp_fc1_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_17_mlp_fc1_bias_to_fp16"), val = tensor<fp16, [4096]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(546440896)))];
            tensor<fp16, [1, 77, 4096]> input_287_cast = linear(bias = text_encoder_text_model_encoder_layers_17_mlp_fc1_bias_to_fp16, weight = text_encoder_text_model_encoder_layers_17_mlp_fc1_weight_to_fp16, x = input_285_cast);
            tensor<string, []> input_289_mode_0 = const()[name = tensor<string, []>("input_289_mode_0"), val = tensor<string, []>("EXACT")];
            tensor<fp16, [1, 77, 4096]> input_289_cast = gelu(mode = input_289_mode_0, x = input_287_cast);
            tensor<fp16, [1024, 4096]> text_encoder_text_model_encoder_layers_17_mlp_fc2_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_17_mlp_fc2_weight_to_fp16"), val = tensor<fp16, [1024, 4096]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(546449152)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_17_mlp_fc2_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_17_mlp_fc2_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(554837824)))];
            tensor<fp16, [1, 77, 1024]> hidden_states_107_cast = linear(bias = text_encoder_text_model_encoder_layers_17_mlp_fc2_bias_to_fp16, weight = text_encoder_text_model_encoder_layers_17_mlp_fc2_weight_to_fp16, x = input_289_cast);
            tensor<fp16, [1, 77, 1024]> input_291_cast = add(x = input_283_cast, y = hidden_states_107_cast);
            tensor<int32, [1]> hidden_states_109_axes_0 = const()[name = tensor<string, []>("hidden_states_109_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_18_layer_norm1_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_18_layer_norm1_weight_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(554839936)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_18_layer_norm1_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_18_layer_norm1_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(554842048)))];
            tensor<fp16, [1, 77, 1024]> hidden_states_109_cast = layer_norm(axes = hidden_states_109_axes_0, beta = text_encoder_text_model_encoder_layers_18_layer_norm1_bias_to_fp16, epsilon = var_12_to_fp16, gamma = text_encoder_text_model_encoder_layers_18_layer_norm1_weight_to_fp16, x = input_291_cast);
            tensor<fp16, [1024, 1024]> text_encoder_text_model_encoder_layers_18_self_attn_q_proj_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_18_self_attn_q_proj_weight_to_fp16"), val = tensor<fp16, [1024, 1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(554844160)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_18_self_attn_q_proj_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_18_self_attn_q_proj_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(556941376)))];
            tensor<fp16, [1, 77, 1024]> var_1676_cast = linear(bias = text_encoder_text_model_encoder_layers_18_self_attn_q_proj_bias_to_fp16, weight = text_encoder_text_model_encoder_layers_18_self_attn_q_proj_weight_to_fp16, x = hidden_states_109_cast);
            tensor<fp16, []> var_1677_to_fp16 = const()[name = tensor<string, []>("op_1677_to_fp16"), val = tensor<fp16, []>(0x1p-3)];
            tensor<fp16, [1, 77, 1024]> tensor_113_cast = mul(x = var_1676_cast, y = var_1677_to_fp16);
            tensor<fp16, [1024, 1024]> text_encoder_text_model_encoder_layers_18_self_attn_k_proj_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_18_self_attn_k_proj_weight_to_fp16"), val = tensor<fp16, [1024, 1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(556943488)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_18_self_attn_k_proj_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_18_self_attn_k_proj_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(559040704)))];
            tensor<fp16, [1, 77, 1024]> tensor_109_cast = linear(bias = text_encoder_text_model_encoder_layers_18_self_attn_k_proj_bias_to_fp16, weight = text_encoder_text_model_encoder_layers_18_self_attn_k_proj_weight_to_fp16, x = hidden_states_109_cast);
            tensor<int32, [4]> var_1682 = const()[name = tensor<string, []>("op_1682"), val = tensor<int32, [4]>([1, -1, 16, 64])];
            tensor<fp16, [1, 77, 16, 64]> var_1683_cast = reshape(shape = var_1682, x = tensor_109_cast);
            tensor<int32, [4]> var_1684_perm_0 = const()[name = tensor<string, []>("op_1684_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<fp16, [1024, 1024]> text_encoder_text_model_encoder_layers_18_self_attn_v_proj_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_18_self_attn_v_proj_weight_to_fp16"), val = tensor<fp16, [1024, 1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(559042816)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_18_self_attn_v_proj_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_18_self_attn_v_proj_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(561140032)))];
            tensor<fp16, [1, 77, 1024]> tensor_111_cast = linear(bias = text_encoder_text_model_encoder_layers_18_self_attn_v_proj_bias_to_fp16, weight = text_encoder_text_model_encoder_layers_18_self_attn_v_proj_weight_to_fp16, x = hidden_states_109_cast);
            tensor<int32, [4]> var_1689 = const()[name = tensor<string, []>("op_1689"), val = tensor<int32, [4]>([1, -1, 16, 64])];
            tensor<fp16, [1, 77, 16, 64]> var_1690_cast = reshape(shape = var_1689, x = tensor_111_cast);
            tensor<int32, [4]> var_1691_perm_0 = const()[name = tensor<string, []>("op_1691_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<int32, [4]> var_1698 = const()[name = tensor<string, []>("op_1698"), val = tensor<int32, [4]>([1, 77, 16, 64])];
            tensor<fp16, [1, 77, 16, 64]> var_1699_cast = reshape(shape = var_1698, x = tensor_113_cast);
            tensor<int32, [4]> var_1700_perm_0 = const()[name = tensor<string, []>("op_1700_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<int32, [3]> var_1702 = const()[name = tensor<string, []>("op_1702"), val = tensor<int32, [3]>([16, -1, 64])];
            tensor<fp16, [1, 16, 77, 64]> transpose_23 = transpose(perm = var_1700_perm_0, x = var_1699_cast);
            tensor<fp16, [16, 77, 64]> query_states_37_cast = reshape(shape = var_1702, x = transpose_23);
            tensor<int32, [3]> var_1704 = const()[name = tensor<string, []>("op_1704"), val = tensor<int32, [3]>([16, -1, 64])];
            tensor<fp16, [1, 16, 77, 64]> transpose_25 = transpose(perm = var_1684_perm_0, x = var_1683_cast);
            tensor<fp16, [16, 77, 64]> key_states_75_cast = reshape(shape = var_1704, x = transpose_25);
            tensor<int32, [3]> var_1706 = const()[name = tensor<string, []>("op_1706"), val = tensor<int32, [3]>([16, -1, 64])];
            tensor<fp16, [1, 16, 77, 64]> transpose_24 = transpose(perm = var_1691_perm_0, x = var_1690_cast);
            tensor<fp16, [16, 77, 64]> value_states_75_cast = reshape(shape = var_1706, x = transpose_24);
            tensor<int32, [3]> var_1709_perm_0 = const()[name = tensor<string, []>("op_1709_perm_0"), val = tensor<int32, [3]>([0, 2, 1])];
            tensor<bool, []> attn_weights_109_transpose_x_0 = const()[name = tensor<string, []>("attn_weights_109_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> attn_weights_109_transpose_y_0 = const()[name = tensor<string, []>("attn_weights_109_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [16, 64, 77]> transpose_22 = transpose(perm = var_1709_perm_0, x = key_states_75_cast);
            tensor<fp16, [16, 77, 77]> attn_weights_109_cast = matmul(transpose_x = attn_weights_109_transpose_x_0, transpose_y = attn_weights_109_transpose_y_0, x = query_states_37_cast, y = transpose_22);
            tensor<int32, [4]> var_1711 = const()[name = tensor<string, []>("op_1711"), val = tensor<int32, [4]>([1, 16, 77, 77])];
            tensor<fp16, [1, 16, 77, 77]> var_1712_cast = reshape(shape = var_1711, x = attn_weights_109_cast);
            tensor<fp16, [1, 16, 77, 77]> attn_weights_111_cast = add(x = var_1712_cast, y = var_44_cast);
            tensor<int32, [3]> var_1717 = const()[name = tensor<string, []>("op_1717"), val = tensor<int32, [3]>([16, 77, 77])];
            tensor<fp16, [16, 77, 77]> input_293_cast = reshape(shape = var_1717, x = attn_weights_111_cast);
            tensor<fp16, [16, 77, 77]> input_295_cast = softmax(axis = var_5, x = input_293_cast);
            tensor<bool, []> attn_output_109_transpose_x_0 = const()[name = tensor<string, []>("attn_output_109_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> attn_output_109_transpose_y_0 = const()[name = tensor<string, []>("attn_output_109_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [16, 77, 64]> attn_output_109_cast = matmul(transpose_x = attn_output_109_transpose_x_0, transpose_y = attn_output_109_transpose_y_0, x = input_295_cast, y = value_states_75_cast);
            tensor<int32, [4]> var_1722 = const()[name = tensor<string, []>("op_1722"), val = tensor<int32, [4]>([1, 16, 77, 64])];
            tensor<fp16, [1, 16, 77, 64]> attn_output_111_cast = reshape(shape = var_1722, x = attn_output_109_cast);
            tensor<int32, [4]> attn_output_113_perm_0 = const()[name = tensor<string, []>("attn_output_113_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<int32, [3]> var_1725 = const()[name = tensor<string, []>("op_1725"), val = tensor<int32, [3]>([1, 77, 1024])];
            tensor<fp16, [1, 77, 16, 64]> transpose_21 = transpose(perm = attn_output_113_perm_0, x = attn_output_111_cast);
            tensor<fp16, [1, 77, 1024]> input_297_cast = reshape(shape = var_1725, x = transpose_21);
            tensor<fp16, [1024, 1024]> text_encoder_text_model_encoder_layers_18_self_attn_out_proj_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_18_self_attn_out_proj_weight_to_fp16"), val = tensor<fp16, [1024, 1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(561142144)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_18_self_attn_out_proj_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_18_self_attn_out_proj_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(563239360)))];
            tensor<fp16, [1, 77, 1024]> hidden_states_111_cast = linear(bias = text_encoder_text_model_encoder_layers_18_self_attn_out_proj_bias_to_fp16, weight = text_encoder_text_model_encoder_layers_18_self_attn_out_proj_weight_to_fp16, x = input_297_cast);
            tensor<fp16, [1, 77, 1024]> input_299_cast = add(x = input_291_cast, y = hidden_states_111_cast);
            tensor<int32, [1]> input_301_axes_0 = const()[name = tensor<string, []>("input_301_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_18_layer_norm2_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_18_layer_norm2_weight_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(563241472)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_18_layer_norm2_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_18_layer_norm2_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(563243584)))];
            tensor<fp16, [1, 77, 1024]> input_301_cast = layer_norm(axes = input_301_axes_0, beta = text_encoder_text_model_encoder_layers_18_layer_norm2_bias_to_fp16, epsilon = var_12_to_fp16, gamma = text_encoder_text_model_encoder_layers_18_layer_norm2_weight_to_fp16, x = input_299_cast);
            tensor<fp16, [4096, 1024]> text_encoder_text_model_encoder_layers_18_mlp_fc1_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_18_mlp_fc1_weight_to_fp16"), val = tensor<fp16, [4096, 1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(563245696)))];
            tensor<fp16, [4096]> text_encoder_text_model_encoder_layers_18_mlp_fc1_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_18_mlp_fc1_bias_to_fp16"), val = tensor<fp16, [4096]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(571634368)))];
            tensor<fp16, [1, 77, 4096]> input_303_cast = linear(bias = text_encoder_text_model_encoder_layers_18_mlp_fc1_bias_to_fp16, weight = text_encoder_text_model_encoder_layers_18_mlp_fc1_weight_to_fp16, x = input_301_cast);
            tensor<string, []> input_305_mode_0 = const()[name = tensor<string, []>("input_305_mode_0"), val = tensor<string, []>("EXACT")];
            tensor<fp16, [1, 77, 4096]> input_305_cast = gelu(mode = input_305_mode_0, x = input_303_cast);
            tensor<fp16, [1024, 4096]> text_encoder_text_model_encoder_layers_18_mlp_fc2_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_18_mlp_fc2_weight_to_fp16"), val = tensor<fp16, [1024, 4096]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(571642624)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_18_mlp_fc2_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_18_mlp_fc2_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(580031296)))];
            tensor<fp16, [1, 77, 1024]> hidden_states_113_cast = linear(bias = text_encoder_text_model_encoder_layers_18_mlp_fc2_bias_to_fp16, weight = text_encoder_text_model_encoder_layers_18_mlp_fc2_weight_to_fp16, x = input_305_cast);
            tensor<fp16, [1, 77, 1024]> input_307_cast = add(x = input_299_cast, y = hidden_states_113_cast);
            tensor<int32, [1]> hidden_states_115_axes_0 = const()[name = tensor<string, []>("hidden_states_115_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_19_layer_norm1_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_19_layer_norm1_weight_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(580033408)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_19_layer_norm1_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_19_layer_norm1_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(580035520)))];
            tensor<fp16, [1, 77, 1024]> hidden_states_115_cast = layer_norm(axes = hidden_states_115_axes_0, beta = text_encoder_text_model_encoder_layers_19_layer_norm1_bias_to_fp16, epsilon = var_12_to_fp16, gamma = text_encoder_text_model_encoder_layers_19_layer_norm1_weight_to_fp16, x = input_307_cast);
            tensor<fp16, [1024, 1024]> text_encoder_text_model_encoder_layers_19_self_attn_q_proj_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_19_self_attn_q_proj_weight_to_fp16"), val = tensor<fp16, [1024, 1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(580037632)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_19_self_attn_q_proj_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_19_self_attn_q_proj_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(582134848)))];
            tensor<fp16, [1, 77, 1024]> var_1763_cast = linear(bias = text_encoder_text_model_encoder_layers_19_self_attn_q_proj_bias_to_fp16, weight = text_encoder_text_model_encoder_layers_19_self_attn_q_proj_weight_to_fp16, x = hidden_states_115_cast);
            tensor<fp16, []> var_1764_to_fp16 = const()[name = tensor<string, []>("op_1764_to_fp16"), val = tensor<fp16, []>(0x1p-3)];
            tensor<fp16, [1, 77, 1024]> tensor_119_cast = mul(x = var_1763_cast, y = var_1764_to_fp16);
            tensor<fp16, [1024, 1024]> text_encoder_text_model_encoder_layers_19_self_attn_k_proj_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_19_self_attn_k_proj_weight_to_fp16"), val = tensor<fp16, [1024, 1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(582136960)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_19_self_attn_k_proj_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_19_self_attn_k_proj_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(584234176)))];
            tensor<fp16, [1, 77, 1024]> tensor_115_cast = linear(bias = text_encoder_text_model_encoder_layers_19_self_attn_k_proj_bias_to_fp16, weight = text_encoder_text_model_encoder_layers_19_self_attn_k_proj_weight_to_fp16, x = hidden_states_115_cast);
            tensor<int32, [4]> var_1769 = const()[name = tensor<string, []>("op_1769"), val = tensor<int32, [4]>([1, -1, 16, 64])];
            tensor<fp16, [1, 77, 16, 64]> var_1770_cast = reshape(shape = var_1769, x = tensor_115_cast);
            tensor<int32, [4]> var_1771_perm_0 = const()[name = tensor<string, []>("op_1771_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<fp16, [1024, 1024]> text_encoder_text_model_encoder_layers_19_self_attn_v_proj_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_19_self_attn_v_proj_weight_to_fp16"), val = tensor<fp16, [1024, 1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(584236288)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_19_self_attn_v_proj_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_19_self_attn_v_proj_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(586333504)))];
            tensor<fp16, [1, 77, 1024]> tensor_117_cast = linear(bias = text_encoder_text_model_encoder_layers_19_self_attn_v_proj_bias_to_fp16, weight = text_encoder_text_model_encoder_layers_19_self_attn_v_proj_weight_to_fp16, x = hidden_states_115_cast);
            tensor<int32, [4]> var_1776 = const()[name = tensor<string, []>("op_1776"), val = tensor<int32, [4]>([1, -1, 16, 64])];
            tensor<fp16, [1, 77, 16, 64]> var_1777_cast = reshape(shape = var_1776, x = tensor_117_cast);
            tensor<int32, [4]> var_1778_perm_0 = const()[name = tensor<string, []>("op_1778_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<int32, [4]> var_1785 = const()[name = tensor<string, []>("op_1785"), val = tensor<int32, [4]>([1, 77, 16, 64])];
            tensor<fp16, [1, 77, 16, 64]> var_1786_cast = reshape(shape = var_1785, x = tensor_119_cast);
            tensor<int32, [4]> var_1787_perm_0 = const()[name = tensor<string, []>("op_1787_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<int32, [3]> var_1789 = const()[name = tensor<string, []>("op_1789"), val = tensor<int32, [3]>([16, -1, 64])];
            tensor<fp16, [1, 16, 77, 64]> transpose_18 = transpose(perm = var_1787_perm_0, x = var_1786_cast);
            tensor<fp16, [16, 77, 64]> query_states_39_cast = reshape(shape = var_1789, x = transpose_18);
            tensor<int32, [3]> var_1791 = const()[name = tensor<string, []>("op_1791"), val = tensor<int32, [3]>([16, -1, 64])];
            tensor<fp16, [1, 16, 77, 64]> transpose_20 = transpose(perm = var_1771_perm_0, x = var_1770_cast);
            tensor<fp16, [16, 77, 64]> key_states_79_cast = reshape(shape = var_1791, x = transpose_20);
            tensor<int32, [3]> var_1793 = const()[name = tensor<string, []>("op_1793"), val = tensor<int32, [3]>([16, -1, 64])];
            tensor<fp16, [1, 16, 77, 64]> transpose_19 = transpose(perm = var_1778_perm_0, x = var_1777_cast);
            tensor<fp16, [16, 77, 64]> value_states_79_cast = reshape(shape = var_1793, x = transpose_19);
            tensor<int32, [3]> var_1796_perm_0 = const()[name = tensor<string, []>("op_1796_perm_0"), val = tensor<int32, [3]>([0, 2, 1])];
            tensor<bool, []> attn_weights_115_transpose_x_0 = const()[name = tensor<string, []>("attn_weights_115_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> attn_weights_115_transpose_y_0 = const()[name = tensor<string, []>("attn_weights_115_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [16, 64, 77]> transpose_17 = transpose(perm = var_1796_perm_0, x = key_states_79_cast);
            tensor<fp16, [16, 77, 77]> attn_weights_115_cast = matmul(transpose_x = attn_weights_115_transpose_x_0, transpose_y = attn_weights_115_transpose_y_0, x = query_states_39_cast, y = transpose_17);
            tensor<int32, [4]> var_1798 = const()[name = tensor<string, []>("op_1798"), val = tensor<int32, [4]>([1, 16, 77, 77])];
            tensor<fp16, [1, 16, 77, 77]> var_1799_cast = reshape(shape = var_1798, x = attn_weights_115_cast);
            tensor<fp16, [1, 16, 77, 77]> attn_weights_117_cast = add(x = var_1799_cast, y = var_44_cast);
            tensor<int32, [3]> var_1804 = const()[name = tensor<string, []>("op_1804"), val = tensor<int32, [3]>([16, 77, 77])];
            tensor<fp16, [16, 77, 77]> input_309_cast = reshape(shape = var_1804, x = attn_weights_117_cast);
            tensor<fp16, [16, 77, 77]> input_311_cast = softmax(axis = var_5, x = input_309_cast);
            tensor<bool, []> attn_output_115_transpose_x_0 = const()[name = tensor<string, []>("attn_output_115_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> attn_output_115_transpose_y_0 = const()[name = tensor<string, []>("attn_output_115_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [16, 77, 64]> attn_output_115_cast = matmul(transpose_x = attn_output_115_transpose_x_0, transpose_y = attn_output_115_transpose_y_0, x = input_311_cast, y = value_states_79_cast);
            tensor<int32, [4]> var_1809 = const()[name = tensor<string, []>("op_1809"), val = tensor<int32, [4]>([1, 16, 77, 64])];
            tensor<fp16, [1, 16, 77, 64]> attn_output_117_cast = reshape(shape = var_1809, x = attn_output_115_cast);
            tensor<int32, [4]> attn_output_119_perm_0 = const()[name = tensor<string, []>("attn_output_119_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<int32, [3]> var_1812 = const()[name = tensor<string, []>("op_1812"), val = tensor<int32, [3]>([1, 77, 1024])];
            tensor<fp16, [1, 77, 16, 64]> transpose_16 = transpose(perm = attn_output_119_perm_0, x = attn_output_117_cast);
            tensor<fp16, [1, 77, 1024]> input_313_cast = reshape(shape = var_1812, x = transpose_16);
            tensor<fp16, [1024, 1024]> text_encoder_text_model_encoder_layers_19_self_attn_out_proj_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_19_self_attn_out_proj_weight_to_fp16"), val = tensor<fp16, [1024, 1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(586335616)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_19_self_attn_out_proj_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_19_self_attn_out_proj_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(588432832)))];
            tensor<fp16, [1, 77, 1024]> hidden_states_117_cast = linear(bias = text_encoder_text_model_encoder_layers_19_self_attn_out_proj_bias_to_fp16, weight = text_encoder_text_model_encoder_layers_19_self_attn_out_proj_weight_to_fp16, x = input_313_cast);
            tensor<fp16, [1, 77, 1024]> input_315_cast = add(x = input_307_cast, y = hidden_states_117_cast);
            tensor<int32, [1]> input_317_axes_0 = const()[name = tensor<string, []>("input_317_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_19_layer_norm2_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_19_layer_norm2_weight_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(588434944)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_19_layer_norm2_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_19_layer_norm2_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(588437056)))];
            tensor<fp16, [1, 77, 1024]> input_317_cast = layer_norm(axes = input_317_axes_0, beta = text_encoder_text_model_encoder_layers_19_layer_norm2_bias_to_fp16, epsilon = var_12_to_fp16, gamma = text_encoder_text_model_encoder_layers_19_layer_norm2_weight_to_fp16, x = input_315_cast);
            tensor<fp16, [4096, 1024]> text_encoder_text_model_encoder_layers_19_mlp_fc1_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_19_mlp_fc1_weight_to_fp16"), val = tensor<fp16, [4096, 1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(588439168)))];
            tensor<fp16, [4096]> text_encoder_text_model_encoder_layers_19_mlp_fc1_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_19_mlp_fc1_bias_to_fp16"), val = tensor<fp16, [4096]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(596827840)))];
            tensor<fp16, [1, 77, 4096]> input_319_cast = linear(bias = text_encoder_text_model_encoder_layers_19_mlp_fc1_bias_to_fp16, weight = text_encoder_text_model_encoder_layers_19_mlp_fc1_weight_to_fp16, x = input_317_cast);
            tensor<string, []> input_321_mode_0 = const()[name = tensor<string, []>("input_321_mode_0"), val = tensor<string, []>("EXACT")];
            tensor<fp16, [1, 77, 4096]> input_321_cast = gelu(mode = input_321_mode_0, x = input_319_cast);
            tensor<fp16, [1024, 4096]> text_encoder_text_model_encoder_layers_19_mlp_fc2_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_19_mlp_fc2_weight_to_fp16"), val = tensor<fp16, [1024, 4096]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(596836096)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_19_mlp_fc2_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_19_mlp_fc2_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(605224768)))];
            tensor<fp16, [1, 77, 1024]> hidden_states_119_cast = linear(bias = text_encoder_text_model_encoder_layers_19_mlp_fc2_bias_to_fp16, weight = text_encoder_text_model_encoder_layers_19_mlp_fc2_weight_to_fp16, x = input_321_cast);
            tensor<fp16, [1, 77, 1024]> input_323_cast = add(x = input_315_cast, y = hidden_states_119_cast);
            tensor<int32, [1]> hidden_states_121_axes_0 = const()[name = tensor<string, []>("hidden_states_121_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_20_layer_norm1_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_20_layer_norm1_weight_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(605226880)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_20_layer_norm1_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_20_layer_norm1_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(605228992)))];
            tensor<fp16, [1, 77, 1024]> hidden_states_121_cast = layer_norm(axes = hidden_states_121_axes_0, beta = text_encoder_text_model_encoder_layers_20_layer_norm1_bias_to_fp16, epsilon = var_12_to_fp16, gamma = text_encoder_text_model_encoder_layers_20_layer_norm1_weight_to_fp16, x = input_323_cast);
            tensor<fp16, [1024, 1024]> text_encoder_text_model_encoder_layers_20_self_attn_q_proj_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_20_self_attn_q_proj_weight_to_fp16"), val = tensor<fp16, [1024, 1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(605231104)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_20_self_attn_q_proj_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_20_self_attn_q_proj_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(607328320)))];
            tensor<fp16, [1, 77, 1024]> var_1850_cast = linear(bias = text_encoder_text_model_encoder_layers_20_self_attn_q_proj_bias_to_fp16, weight = text_encoder_text_model_encoder_layers_20_self_attn_q_proj_weight_to_fp16, x = hidden_states_121_cast);
            tensor<fp16, []> var_1851_to_fp16 = const()[name = tensor<string, []>("op_1851_to_fp16"), val = tensor<fp16, []>(0x1p-3)];
            tensor<fp16, [1, 77, 1024]> tensor_125_cast = mul(x = var_1850_cast, y = var_1851_to_fp16);
            tensor<fp16, [1024, 1024]> text_encoder_text_model_encoder_layers_20_self_attn_k_proj_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_20_self_attn_k_proj_weight_to_fp16"), val = tensor<fp16, [1024, 1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(607330432)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_20_self_attn_k_proj_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_20_self_attn_k_proj_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(609427648)))];
            tensor<fp16, [1, 77, 1024]> tensor_121_cast = linear(bias = text_encoder_text_model_encoder_layers_20_self_attn_k_proj_bias_to_fp16, weight = text_encoder_text_model_encoder_layers_20_self_attn_k_proj_weight_to_fp16, x = hidden_states_121_cast);
            tensor<int32, [4]> var_1856 = const()[name = tensor<string, []>("op_1856"), val = tensor<int32, [4]>([1, -1, 16, 64])];
            tensor<fp16, [1, 77, 16, 64]> var_1857_cast = reshape(shape = var_1856, x = tensor_121_cast);
            tensor<int32, [4]> var_1858_perm_0 = const()[name = tensor<string, []>("op_1858_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<fp16, [1024, 1024]> text_encoder_text_model_encoder_layers_20_self_attn_v_proj_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_20_self_attn_v_proj_weight_to_fp16"), val = tensor<fp16, [1024, 1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(609429760)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_20_self_attn_v_proj_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_20_self_attn_v_proj_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(611526976)))];
            tensor<fp16, [1, 77, 1024]> tensor_123_cast = linear(bias = text_encoder_text_model_encoder_layers_20_self_attn_v_proj_bias_to_fp16, weight = text_encoder_text_model_encoder_layers_20_self_attn_v_proj_weight_to_fp16, x = hidden_states_121_cast);
            tensor<int32, [4]> var_1863 = const()[name = tensor<string, []>("op_1863"), val = tensor<int32, [4]>([1, -1, 16, 64])];
            tensor<fp16, [1, 77, 16, 64]> var_1864_cast = reshape(shape = var_1863, x = tensor_123_cast);
            tensor<int32, [4]> var_1865_perm_0 = const()[name = tensor<string, []>("op_1865_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<int32, [4]> var_1872 = const()[name = tensor<string, []>("op_1872"), val = tensor<int32, [4]>([1, 77, 16, 64])];
            tensor<fp16, [1, 77, 16, 64]> var_1873_cast = reshape(shape = var_1872, x = tensor_125_cast);
            tensor<int32, [4]> var_1874_perm_0 = const()[name = tensor<string, []>("op_1874_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<int32, [3]> var_1876 = const()[name = tensor<string, []>("op_1876"), val = tensor<int32, [3]>([16, -1, 64])];
            tensor<fp16, [1, 16, 77, 64]> transpose_13 = transpose(perm = var_1874_perm_0, x = var_1873_cast);
            tensor<fp16, [16, 77, 64]> query_states_41_cast = reshape(shape = var_1876, x = transpose_13);
            tensor<int32, [3]> var_1878 = const()[name = tensor<string, []>("op_1878"), val = tensor<int32, [3]>([16, -1, 64])];
            tensor<fp16, [1, 16, 77, 64]> transpose_15 = transpose(perm = var_1858_perm_0, x = var_1857_cast);
            tensor<fp16, [16, 77, 64]> key_states_83_cast = reshape(shape = var_1878, x = transpose_15);
            tensor<int32, [3]> var_1880 = const()[name = tensor<string, []>("op_1880"), val = tensor<int32, [3]>([16, -1, 64])];
            tensor<fp16, [1, 16, 77, 64]> transpose_14 = transpose(perm = var_1865_perm_0, x = var_1864_cast);
            tensor<fp16, [16, 77, 64]> value_states_83_cast = reshape(shape = var_1880, x = transpose_14);
            tensor<int32, [3]> var_1883_perm_0 = const()[name = tensor<string, []>("op_1883_perm_0"), val = tensor<int32, [3]>([0, 2, 1])];
            tensor<bool, []> attn_weights_121_transpose_x_0 = const()[name = tensor<string, []>("attn_weights_121_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> attn_weights_121_transpose_y_0 = const()[name = tensor<string, []>("attn_weights_121_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [16, 64, 77]> transpose_12 = transpose(perm = var_1883_perm_0, x = key_states_83_cast);
            tensor<fp16, [16, 77, 77]> attn_weights_121_cast = matmul(transpose_x = attn_weights_121_transpose_x_0, transpose_y = attn_weights_121_transpose_y_0, x = query_states_41_cast, y = transpose_12);
            tensor<int32, [4]> var_1885 = const()[name = tensor<string, []>("op_1885"), val = tensor<int32, [4]>([1, 16, 77, 77])];
            tensor<fp16, [1, 16, 77, 77]> var_1886_cast = reshape(shape = var_1885, x = attn_weights_121_cast);
            tensor<fp16, [1, 16, 77, 77]> attn_weights_123_cast = add(x = var_1886_cast, y = var_44_cast);
            tensor<int32, [3]> var_1891 = const()[name = tensor<string, []>("op_1891"), val = tensor<int32, [3]>([16, 77, 77])];
            tensor<fp16, [16, 77, 77]> input_325_cast = reshape(shape = var_1891, x = attn_weights_123_cast);
            tensor<fp16, [16, 77, 77]> input_327_cast = softmax(axis = var_5, x = input_325_cast);
            tensor<bool, []> attn_output_121_transpose_x_0 = const()[name = tensor<string, []>("attn_output_121_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> attn_output_121_transpose_y_0 = const()[name = tensor<string, []>("attn_output_121_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [16, 77, 64]> attn_output_121_cast = matmul(transpose_x = attn_output_121_transpose_x_0, transpose_y = attn_output_121_transpose_y_0, x = input_327_cast, y = value_states_83_cast);
            tensor<int32, [4]> var_1896 = const()[name = tensor<string, []>("op_1896"), val = tensor<int32, [4]>([1, 16, 77, 64])];
            tensor<fp16, [1, 16, 77, 64]> attn_output_123_cast = reshape(shape = var_1896, x = attn_output_121_cast);
            tensor<int32, [4]> attn_output_125_perm_0 = const()[name = tensor<string, []>("attn_output_125_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<int32, [3]> var_1899 = const()[name = tensor<string, []>("op_1899"), val = tensor<int32, [3]>([1, 77, 1024])];
            tensor<fp16, [1, 77, 16, 64]> transpose_11 = transpose(perm = attn_output_125_perm_0, x = attn_output_123_cast);
            tensor<fp16, [1, 77, 1024]> input_329_cast = reshape(shape = var_1899, x = transpose_11);
            tensor<fp16, [1024, 1024]> text_encoder_text_model_encoder_layers_20_self_attn_out_proj_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_20_self_attn_out_proj_weight_to_fp16"), val = tensor<fp16, [1024, 1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(611529088)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_20_self_attn_out_proj_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_20_self_attn_out_proj_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(613626304)))];
            tensor<fp16, [1, 77, 1024]> hidden_states_123_cast = linear(bias = text_encoder_text_model_encoder_layers_20_self_attn_out_proj_bias_to_fp16, weight = text_encoder_text_model_encoder_layers_20_self_attn_out_proj_weight_to_fp16, x = input_329_cast);
            tensor<fp16, [1, 77, 1024]> input_331_cast = add(x = input_323_cast, y = hidden_states_123_cast);
            tensor<int32, [1]> input_333_axes_0 = const()[name = tensor<string, []>("input_333_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_20_layer_norm2_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_20_layer_norm2_weight_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(613628416)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_20_layer_norm2_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_20_layer_norm2_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(613630528)))];
            tensor<fp16, [1, 77, 1024]> input_333_cast = layer_norm(axes = input_333_axes_0, beta = text_encoder_text_model_encoder_layers_20_layer_norm2_bias_to_fp16, epsilon = var_12_to_fp16, gamma = text_encoder_text_model_encoder_layers_20_layer_norm2_weight_to_fp16, x = input_331_cast);
            tensor<fp16, [4096, 1024]> text_encoder_text_model_encoder_layers_20_mlp_fc1_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_20_mlp_fc1_weight_to_fp16"), val = tensor<fp16, [4096, 1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(613632640)))];
            tensor<fp16, [4096]> text_encoder_text_model_encoder_layers_20_mlp_fc1_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_20_mlp_fc1_bias_to_fp16"), val = tensor<fp16, [4096]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(622021312)))];
            tensor<fp16, [1, 77, 4096]> input_335_cast = linear(bias = text_encoder_text_model_encoder_layers_20_mlp_fc1_bias_to_fp16, weight = text_encoder_text_model_encoder_layers_20_mlp_fc1_weight_to_fp16, x = input_333_cast);
            tensor<string, []> input_337_mode_0 = const()[name = tensor<string, []>("input_337_mode_0"), val = tensor<string, []>("EXACT")];
            tensor<fp16, [1, 77, 4096]> input_337_cast = gelu(mode = input_337_mode_0, x = input_335_cast);
            tensor<fp16, [1024, 4096]> text_encoder_text_model_encoder_layers_20_mlp_fc2_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_20_mlp_fc2_weight_to_fp16"), val = tensor<fp16, [1024, 4096]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(622029568)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_20_mlp_fc2_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_20_mlp_fc2_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(630418240)))];
            tensor<fp16, [1, 77, 1024]> hidden_states_125_cast = linear(bias = text_encoder_text_model_encoder_layers_20_mlp_fc2_bias_to_fp16, weight = text_encoder_text_model_encoder_layers_20_mlp_fc2_weight_to_fp16, x = input_337_cast);
            tensor<fp16, [1, 77, 1024]> input_339_cast = add(x = input_331_cast, y = hidden_states_125_cast);
            tensor<int32, [1]> hidden_states_127_axes_0 = const()[name = tensor<string, []>("hidden_states_127_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_21_layer_norm1_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_21_layer_norm1_weight_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(630420352)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_21_layer_norm1_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_21_layer_norm1_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(630422464)))];
            tensor<fp16, [1, 77, 1024]> hidden_states_127_cast = layer_norm(axes = hidden_states_127_axes_0, beta = text_encoder_text_model_encoder_layers_21_layer_norm1_bias_to_fp16, epsilon = var_12_to_fp16, gamma = text_encoder_text_model_encoder_layers_21_layer_norm1_weight_to_fp16, x = input_339_cast);
            tensor<fp16, [1024, 1024]> text_encoder_text_model_encoder_layers_21_self_attn_q_proj_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_21_self_attn_q_proj_weight_to_fp16"), val = tensor<fp16, [1024, 1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(630424576)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_21_self_attn_q_proj_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_21_self_attn_q_proj_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(632521792)))];
            tensor<fp16, [1, 77, 1024]> var_1937_cast = linear(bias = text_encoder_text_model_encoder_layers_21_self_attn_q_proj_bias_to_fp16, weight = text_encoder_text_model_encoder_layers_21_self_attn_q_proj_weight_to_fp16, x = hidden_states_127_cast);
            tensor<fp16, []> var_1938_to_fp16 = const()[name = tensor<string, []>("op_1938_to_fp16"), val = tensor<fp16, []>(0x1p-3)];
            tensor<fp16, [1, 77, 1024]> tensor_131_cast = mul(x = var_1937_cast, y = var_1938_to_fp16);
            tensor<fp16, [1024, 1024]> text_encoder_text_model_encoder_layers_21_self_attn_k_proj_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_21_self_attn_k_proj_weight_to_fp16"), val = tensor<fp16, [1024, 1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(632523904)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_21_self_attn_k_proj_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_21_self_attn_k_proj_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(634621120)))];
            tensor<fp16, [1, 77, 1024]> tensor_127_cast = linear(bias = text_encoder_text_model_encoder_layers_21_self_attn_k_proj_bias_to_fp16, weight = text_encoder_text_model_encoder_layers_21_self_attn_k_proj_weight_to_fp16, x = hidden_states_127_cast);
            tensor<int32, [4]> var_1943 = const()[name = tensor<string, []>("op_1943"), val = tensor<int32, [4]>([1, -1, 16, 64])];
            tensor<fp16, [1, 77, 16, 64]> var_1944_cast = reshape(shape = var_1943, x = tensor_127_cast);
            tensor<int32, [4]> var_1945_perm_0 = const()[name = tensor<string, []>("op_1945_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<fp16, [1024, 1024]> text_encoder_text_model_encoder_layers_21_self_attn_v_proj_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_21_self_attn_v_proj_weight_to_fp16"), val = tensor<fp16, [1024, 1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(634623232)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_21_self_attn_v_proj_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_21_self_attn_v_proj_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(636720448)))];
            tensor<fp16, [1, 77, 1024]> tensor_129_cast = linear(bias = text_encoder_text_model_encoder_layers_21_self_attn_v_proj_bias_to_fp16, weight = text_encoder_text_model_encoder_layers_21_self_attn_v_proj_weight_to_fp16, x = hidden_states_127_cast);
            tensor<int32, [4]> var_1950 = const()[name = tensor<string, []>("op_1950"), val = tensor<int32, [4]>([1, -1, 16, 64])];
            tensor<fp16, [1, 77, 16, 64]> var_1951_cast = reshape(shape = var_1950, x = tensor_129_cast);
            tensor<int32, [4]> var_1952_perm_0 = const()[name = tensor<string, []>("op_1952_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<int32, [4]> var_1959 = const()[name = tensor<string, []>("op_1959"), val = tensor<int32, [4]>([1, 77, 16, 64])];
            tensor<fp16, [1, 77, 16, 64]> var_1960_cast = reshape(shape = var_1959, x = tensor_131_cast);
            tensor<int32, [4]> var_1961_perm_0 = const()[name = tensor<string, []>("op_1961_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<int32, [3]> var_1963 = const()[name = tensor<string, []>("op_1963"), val = tensor<int32, [3]>([16, -1, 64])];
            tensor<fp16, [1, 16, 77, 64]> transpose_8 = transpose(perm = var_1961_perm_0, x = var_1960_cast);
            tensor<fp16, [16, 77, 64]> query_states_43_cast = reshape(shape = var_1963, x = transpose_8);
            tensor<int32, [3]> var_1965 = const()[name = tensor<string, []>("op_1965"), val = tensor<int32, [3]>([16, -1, 64])];
            tensor<fp16, [1, 16, 77, 64]> transpose_10 = transpose(perm = var_1945_perm_0, x = var_1944_cast);
            tensor<fp16, [16, 77, 64]> key_states_87_cast = reshape(shape = var_1965, x = transpose_10);
            tensor<int32, [3]> var_1967 = const()[name = tensor<string, []>("op_1967"), val = tensor<int32, [3]>([16, -1, 64])];
            tensor<fp16, [1, 16, 77, 64]> transpose_9 = transpose(perm = var_1952_perm_0, x = var_1951_cast);
            tensor<fp16, [16, 77, 64]> value_states_87_cast = reshape(shape = var_1967, x = transpose_9);
            tensor<int32, [3]> var_1970_perm_0 = const()[name = tensor<string, []>("op_1970_perm_0"), val = tensor<int32, [3]>([0, 2, 1])];
            tensor<bool, []> attn_weights_127_transpose_x_0 = const()[name = tensor<string, []>("attn_weights_127_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> attn_weights_127_transpose_y_0 = const()[name = tensor<string, []>("attn_weights_127_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [16, 64, 77]> transpose_7 = transpose(perm = var_1970_perm_0, x = key_states_87_cast);
            tensor<fp16, [16, 77, 77]> attn_weights_127_cast = matmul(transpose_x = attn_weights_127_transpose_x_0, transpose_y = attn_weights_127_transpose_y_0, x = query_states_43_cast, y = transpose_7);
            tensor<int32, [4]> var_1972 = const()[name = tensor<string, []>("op_1972"), val = tensor<int32, [4]>([1, 16, 77, 77])];
            tensor<fp16, [1, 16, 77, 77]> var_1973_cast = reshape(shape = var_1972, x = attn_weights_127_cast);
            tensor<fp16, [1, 16, 77, 77]> attn_weights_129_cast = add(x = var_1973_cast, y = var_44_cast);
            tensor<int32, [3]> var_1978 = const()[name = tensor<string, []>("op_1978"), val = tensor<int32, [3]>([16, 77, 77])];
            tensor<fp16, [16, 77, 77]> input_341_cast = reshape(shape = var_1978, x = attn_weights_129_cast);
            tensor<fp16, [16, 77, 77]> input_343_cast = softmax(axis = var_5, x = input_341_cast);
            tensor<bool, []> attn_output_127_transpose_x_0 = const()[name = tensor<string, []>("attn_output_127_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> attn_output_127_transpose_y_0 = const()[name = tensor<string, []>("attn_output_127_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [16, 77, 64]> attn_output_127_cast = matmul(transpose_x = attn_output_127_transpose_x_0, transpose_y = attn_output_127_transpose_y_0, x = input_343_cast, y = value_states_87_cast);
            tensor<int32, [4]> var_1983 = const()[name = tensor<string, []>("op_1983"), val = tensor<int32, [4]>([1, 16, 77, 64])];
            tensor<fp16, [1, 16, 77, 64]> attn_output_129_cast = reshape(shape = var_1983, x = attn_output_127_cast);
            tensor<int32, [4]> attn_output_131_perm_0 = const()[name = tensor<string, []>("attn_output_131_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<int32, [3]> var_1986 = const()[name = tensor<string, []>("op_1986"), val = tensor<int32, [3]>([1, 77, 1024])];
            tensor<fp16, [1, 77, 16, 64]> transpose_6 = transpose(perm = attn_output_131_perm_0, x = attn_output_129_cast);
            tensor<fp16, [1, 77, 1024]> input_345_cast = reshape(shape = var_1986, x = transpose_6);
            tensor<fp16, [1024, 1024]> text_encoder_text_model_encoder_layers_21_self_attn_out_proj_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_21_self_attn_out_proj_weight_to_fp16"), val = tensor<fp16, [1024, 1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(636722560)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_21_self_attn_out_proj_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_21_self_attn_out_proj_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(638819776)))];
            tensor<fp16, [1, 77, 1024]> hidden_states_129_cast = linear(bias = text_encoder_text_model_encoder_layers_21_self_attn_out_proj_bias_to_fp16, weight = text_encoder_text_model_encoder_layers_21_self_attn_out_proj_weight_to_fp16, x = input_345_cast);
            tensor<fp16, [1, 77, 1024]> input_347_cast = add(x = input_339_cast, y = hidden_states_129_cast);
            tensor<int32, [1]> input_349_axes_0 = const()[name = tensor<string, []>("input_349_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_21_layer_norm2_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_21_layer_norm2_weight_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(638821888)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_21_layer_norm2_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_21_layer_norm2_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(638824000)))];
            tensor<fp16, [1, 77, 1024]> input_349_cast = layer_norm(axes = input_349_axes_0, beta = text_encoder_text_model_encoder_layers_21_layer_norm2_bias_to_fp16, epsilon = var_12_to_fp16, gamma = text_encoder_text_model_encoder_layers_21_layer_norm2_weight_to_fp16, x = input_347_cast);
            tensor<fp16, [4096, 1024]> text_encoder_text_model_encoder_layers_21_mlp_fc1_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_21_mlp_fc1_weight_to_fp16"), val = tensor<fp16, [4096, 1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(638826112)))];
            tensor<fp16, [4096]> text_encoder_text_model_encoder_layers_21_mlp_fc1_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_21_mlp_fc1_bias_to_fp16"), val = tensor<fp16, [4096]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(647214784)))];
            tensor<fp16, [1, 77, 4096]> input_351_cast = linear(bias = text_encoder_text_model_encoder_layers_21_mlp_fc1_bias_to_fp16, weight = text_encoder_text_model_encoder_layers_21_mlp_fc1_weight_to_fp16, x = input_349_cast);
            tensor<string, []> input_353_mode_0 = const()[name = tensor<string, []>("input_353_mode_0"), val = tensor<string, []>("EXACT")];
            tensor<fp16, [1, 77, 4096]> input_353_cast = gelu(mode = input_353_mode_0, x = input_351_cast);
            tensor<fp16, [1024, 4096]> text_encoder_text_model_encoder_layers_21_mlp_fc2_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_21_mlp_fc2_weight_to_fp16"), val = tensor<fp16, [1024, 4096]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(647223040)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_21_mlp_fc2_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_21_mlp_fc2_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(655611712)))];
            tensor<fp16, [1, 77, 1024]> hidden_states_131_cast = linear(bias = text_encoder_text_model_encoder_layers_21_mlp_fc2_bias_to_fp16, weight = text_encoder_text_model_encoder_layers_21_mlp_fc2_weight_to_fp16, x = input_353_cast);
            tensor<fp16, [1, 77, 1024]> input_355_cast = add(x = input_347_cast, y = hidden_states_131_cast);
            tensor<int32, [1]> hidden_states_133_axes_0 = const()[name = tensor<string, []>("hidden_states_133_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_22_layer_norm1_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_22_layer_norm1_weight_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(655613824)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_22_layer_norm1_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_22_layer_norm1_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(655615936)))];
            tensor<fp16, [1, 77, 1024]> hidden_states_133_cast = layer_norm(axes = hidden_states_133_axes_0, beta = text_encoder_text_model_encoder_layers_22_layer_norm1_bias_to_fp16, epsilon = var_12_to_fp16, gamma = text_encoder_text_model_encoder_layers_22_layer_norm1_weight_to_fp16, x = input_355_cast);
            tensor<fp16, [1024, 1024]> text_encoder_text_model_encoder_layers_22_self_attn_q_proj_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_22_self_attn_q_proj_weight_to_fp16"), val = tensor<fp16, [1024, 1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(655618048)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_22_self_attn_q_proj_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_22_self_attn_q_proj_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(657715264)))];
            tensor<fp16, [1, 77, 1024]> var_2024_cast = linear(bias = text_encoder_text_model_encoder_layers_22_self_attn_q_proj_bias_to_fp16, weight = text_encoder_text_model_encoder_layers_22_self_attn_q_proj_weight_to_fp16, x = hidden_states_133_cast);
            tensor<fp16, []> var_2025_to_fp16 = const()[name = tensor<string, []>("op_2025_to_fp16"), val = tensor<fp16, []>(0x1p-3)];
            tensor<fp16, [1, 77, 1024]> tensor_cast = mul(x = var_2024_cast, y = var_2025_to_fp16);
            tensor<fp16, [1024, 1024]> text_encoder_text_model_encoder_layers_22_self_attn_k_proj_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_22_self_attn_k_proj_weight_to_fp16"), val = tensor<fp16, [1024, 1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(657717376)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_22_self_attn_k_proj_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_22_self_attn_k_proj_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(659814592)))];
            tensor<fp16, [1, 77, 1024]> tensor_133_cast = linear(bias = text_encoder_text_model_encoder_layers_22_self_attn_k_proj_bias_to_fp16, weight = text_encoder_text_model_encoder_layers_22_self_attn_k_proj_weight_to_fp16, x = hidden_states_133_cast);
            tensor<int32, [4]> var_2030 = const()[name = tensor<string, []>("op_2030"), val = tensor<int32, [4]>([1, -1, 16, 64])];
            tensor<fp16, [1, 77, 16, 64]> var_2031_cast = reshape(shape = var_2030, x = tensor_133_cast);
            tensor<int32, [4]> var_2032_perm_0 = const()[name = tensor<string, []>("op_2032_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<fp16, [1024, 1024]> text_encoder_text_model_encoder_layers_22_self_attn_v_proj_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_22_self_attn_v_proj_weight_to_fp16"), val = tensor<fp16, [1024, 1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(659816704)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_22_self_attn_v_proj_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_22_self_attn_v_proj_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(661913920)))];
            tensor<fp16, [1, 77, 1024]> tensor_135_cast = linear(bias = text_encoder_text_model_encoder_layers_22_self_attn_v_proj_bias_to_fp16, weight = text_encoder_text_model_encoder_layers_22_self_attn_v_proj_weight_to_fp16, x = hidden_states_133_cast);
            tensor<int32, [4]> var_2037 = const()[name = tensor<string, []>("op_2037"), val = tensor<int32, [4]>([1, -1, 16, 64])];
            tensor<fp16, [1, 77, 16, 64]> var_2038_cast = reshape(shape = var_2037, x = tensor_135_cast);
            tensor<int32, [4]> var_2039_perm_0 = const()[name = tensor<string, []>("op_2039_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<int32, [4]> var_2046 = const()[name = tensor<string, []>("op_2046"), val = tensor<int32, [4]>([1, 77, 16, 64])];
            tensor<fp16, [1, 77, 16, 64]> var_2047_cast = reshape(shape = var_2046, x = tensor_cast);
            tensor<int32, [4]> var_2048_perm_0 = const()[name = tensor<string, []>("op_2048_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<int32, [3]> var_2050 = const()[name = tensor<string, []>("op_2050"), val = tensor<int32, [3]>([16, -1, 64])];
            tensor<fp16, [1, 16, 77, 64]> transpose_3 = transpose(perm = var_2048_perm_0, x = var_2047_cast);
            tensor<fp16, [16, 77, 64]> query_states_cast = reshape(shape = var_2050, x = transpose_3);
            tensor<int32, [3]> var_2052 = const()[name = tensor<string, []>("op_2052"), val = tensor<int32, [3]>([16, -1, 64])];
            tensor<fp16, [1, 16, 77, 64]> transpose_5 = transpose(perm = var_2032_perm_0, x = var_2031_cast);
            tensor<fp16, [16, 77, 64]> key_states_cast = reshape(shape = var_2052, x = transpose_5);
            tensor<int32, [3]> var_2054 = const()[name = tensor<string, []>("op_2054"), val = tensor<int32, [3]>([16, -1, 64])];
            tensor<fp16, [1, 16, 77, 64]> transpose_4 = transpose(perm = var_2039_perm_0, x = var_2038_cast);
            tensor<fp16, [16, 77, 64]> value_states_cast = reshape(shape = var_2054, x = transpose_4);
            tensor<int32, [3]> var_2057_perm_0 = const()[name = tensor<string, []>("op_2057_perm_0"), val = tensor<int32, [3]>([0, 2, 1])];
            tensor<bool, []> attn_weights_133_transpose_x_0 = const()[name = tensor<string, []>("attn_weights_133_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> attn_weights_133_transpose_y_0 = const()[name = tensor<string, []>("attn_weights_133_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [16, 64, 77]> transpose_2 = transpose(perm = var_2057_perm_0, x = key_states_cast);
            tensor<fp16, [16, 77, 77]> attn_weights_133_cast = matmul(transpose_x = attn_weights_133_transpose_x_0, transpose_y = attn_weights_133_transpose_y_0, x = query_states_cast, y = transpose_2);
            tensor<int32, [4]> var_2059 = const()[name = tensor<string, []>("op_2059"), val = tensor<int32, [4]>([1, 16, 77, 77])];
            tensor<fp16, [1, 16, 77, 77]> var_2060_cast = reshape(shape = var_2059, x = attn_weights_133_cast);
            tensor<fp16, [1, 16, 77, 77]> attn_weights_135_cast = add(x = var_2060_cast, y = var_44_cast);
            tensor<int32, [3]> var_2065 = const()[name = tensor<string, []>("op_2065"), val = tensor<int32, [3]>([16, 77, 77])];
            tensor<fp16, [16, 77, 77]> input_357_cast = reshape(shape = var_2065, x = attn_weights_135_cast);
            tensor<fp16, [16, 77, 77]> input_359_cast = softmax(axis = var_5, x = input_357_cast);
            tensor<bool, []> attn_output_133_transpose_x_0 = const()[name = tensor<string, []>("attn_output_133_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> attn_output_133_transpose_y_0 = const()[name = tensor<string, []>("attn_output_133_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [16, 77, 64]> attn_output_133_cast = matmul(transpose_x = attn_output_133_transpose_x_0, transpose_y = attn_output_133_transpose_y_0, x = input_359_cast, y = value_states_cast);
            tensor<int32, [4]> var_2070 = const()[name = tensor<string, []>("op_2070"), val = tensor<int32, [4]>([1, 16, 77, 64])];
            tensor<fp16, [1, 16, 77, 64]> attn_output_135_cast = reshape(shape = var_2070, x = attn_output_133_cast);
            tensor<int32, [4]> attn_output_perm_0 = const()[name = tensor<string, []>("attn_output_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<int32, [3]> var_2073 = const()[name = tensor<string, []>("op_2073"), val = tensor<int32, [3]>([1, 77, 1024])];
            tensor<fp16, [1, 77, 16, 64]> transpose_1 = transpose(perm = attn_output_perm_0, x = attn_output_135_cast);
            tensor<fp16, [1, 77, 1024]> input_361_cast = reshape(shape = var_2073, x = transpose_1);
            tensor<fp16, [1024, 1024]> text_encoder_text_model_encoder_layers_22_self_attn_out_proj_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_22_self_attn_out_proj_weight_to_fp16"), val = tensor<fp16, [1024, 1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(661916032)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_22_self_attn_out_proj_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_22_self_attn_out_proj_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(664013248)))];
            tensor<fp16, [1, 77, 1024]> hidden_states_135_cast = linear(bias = text_encoder_text_model_encoder_layers_22_self_attn_out_proj_bias_to_fp16, weight = text_encoder_text_model_encoder_layers_22_self_attn_out_proj_weight_to_fp16, x = input_361_cast);
            tensor<fp16, [1, 77, 1024]> input_363_cast = add(x = input_355_cast, y = hidden_states_135_cast);
            tensor<int32, [1]> input_365_axes_0 = const()[name = tensor<string, []>("input_365_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_22_layer_norm2_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_22_layer_norm2_weight_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(664015360)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_22_layer_norm2_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_22_layer_norm2_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(664017472)))];
            tensor<fp16, [1, 77, 1024]> input_365_cast = layer_norm(axes = input_365_axes_0, beta = text_encoder_text_model_encoder_layers_22_layer_norm2_bias_to_fp16, epsilon = var_12_to_fp16, gamma = text_encoder_text_model_encoder_layers_22_layer_norm2_weight_to_fp16, x = input_363_cast);
            tensor<fp16, [4096, 1024]> text_encoder_text_model_encoder_layers_22_mlp_fc1_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_22_mlp_fc1_weight_to_fp16"), val = tensor<fp16, [4096, 1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(664019584)))];
            tensor<fp16, [4096]> text_encoder_text_model_encoder_layers_22_mlp_fc1_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_22_mlp_fc1_bias_to_fp16"), val = tensor<fp16, [4096]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(672408256)))];
            tensor<fp16, [1, 77, 4096]> input_367_cast = linear(bias = text_encoder_text_model_encoder_layers_22_mlp_fc1_bias_to_fp16, weight = text_encoder_text_model_encoder_layers_22_mlp_fc1_weight_to_fp16, x = input_365_cast);
            tensor<string, []> input_369_mode_0 = const()[name = tensor<string, []>("input_369_mode_0"), val = tensor<string, []>("EXACT")];
            tensor<fp16, [1, 77, 4096]> input_369_cast = gelu(mode = input_369_mode_0, x = input_367_cast);
            tensor<fp16, [1024, 4096]> text_encoder_text_model_encoder_layers_22_mlp_fc2_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_22_mlp_fc2_weight_to_fp16"), val = tensor<fp16, [1024, 4096]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(672416512)))];
            tensor<fp16, [1024]> text_encoder_text_model_encoder_layers_22_mlp_fc2_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_encoder_layers_22_mlp_fc2_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(680805184)))];
            tensor<fp16, [1, 77, 1024]> hidden_states_cast = linear(bias = text_encoder_text_model_encoder_layers_22_mlp_fc2_bias_to_fp16, weight = text_encoder_text_model_encoder_layers_22_mlp_fc2_weight_to_fp16, x = input_369_cast);
            tensor<fp16, [1, 77, 1024]> input_cast = add(x = input_363_cast, y = hidden_states_cast);
            tensor<int32, [1]> last_hidden_state_axes_0 = const()[name = tensor<string, []>("last_hidden_state_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [1024]> text_encoder_text_model_final_layer_norm_weight_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_final_layer_norm_weight_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(680807296)))];
            tensor<fp16, [1024]> text_encoder_text_model_final_layer_norm_bias_to_fp16 = const()[name = tensor<string, []>("text_encoder_text_model_final_layer_norm_bias_to_fp16"), val = tensor<fp16, [1024]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(680809408)))];
            tensor<fp16, [1, 77, 1024]> last_hidden_state_cast = layer_norm(axes = last_hidden_state_axes_0, beta = text_encoder_text_model_final_layer_norm_bias_to_fp16, epsilon = var_12_to_fp16, gamma = text_encoder_text_model_final_layer_norm_weight_to_fp16, x = input_cast);
            tensor<string, []> last_hidden_state_cast_to_fp32_dtype_0 = const()[name = tensor<string, []>("last_hidden_state_cast_to_fp32_dtype_0"), val = tensor<string, []>("fp32")];
            tensor<int32, [1]> var_2098 = const()[name = tensor<string, []>("op_2098"), val = tensor<int32, [1]>([0])];
            tensor<int32, [1]> var_2100 = reduce_argmax(axis = var_5, keep_dims = var_6, x = cast_954);
            tensor<int32, []> stack_0_axis_0 = const()[name = tensor<string, []>("stack_0_axis_0"), val = tensor<int32, []>(1)];
            tensor<int32, [1, 2]> stack_0 = stack(axis = stack_0_axis_0, values = (var_2098, var_2100));
            tensor<int32, []> var_2102_transpose_batch_dims_0 = const()[name = tensor<string, []>("op_2102_transpose_batch_dims_0"), val = tensor<int32, []>(0)];
            tensor<fp16, [1, 1024]> var_2102_transpose_cast = gather_nd(batch_dims = var_2102_transpose_batch_dims_0, indices = stack_0, x = last_hidden_state_cast);
            tensor<string, []> var_2102_cast_to_fp32_dtype_0 = const()[name = tensor<string, []>("op_2102_cast_to_fp32_dtype_0"), val = tensor<string, []>("fp32")];
            tensor<fp32, [1, 1024]> pooled_outputs = cast(dtype = var_2102_cast_to_fp32_dtype_0, x = var_2102_transpose_cast);
            tensor<fp32, [1, 77, 1024]> last_hidden_state = cast(dtype = last_hidden_state_cast_to_fp32_dtype_0, x = last_hidden_state_cast);
        } -> (last_hidden_state, pooled_outputs);
}